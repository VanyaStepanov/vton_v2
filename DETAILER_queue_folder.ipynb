{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "Qh3dRdojPCy1",
        "3WXWS5m9Ozyt",
        "SdvcT9PEO5ye",
        "0nznhr0CO8xT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CONFIG"
      ],
      "metadata": {
        "id": "Qh3dRdojPCy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7pOn3vu5dQd"
      },
      "outputs": [],
      "source": [
        "# === CONFIG ===\n",
        "\n",
        "# Queued targets that REQUIRE the detailer (already pre-filtered by your generator)\n",
        "DETAILER_QUEUE_FOLDER = \"/content/drive/MyDrive/SS_OUTPUT_FOLDER/v1-5\"  # @param {type:\"string\"}\n",
        "\n",
        "# Where to save (1) the source garment and (2) the inpainted results\n",
        "TARGET_DIR = \"/content/drive/MyDrive/DETAILER_DONE/vtnon_v1_5\"               # @param {type:\"string\"}\n",
        "\n",
        "# Root that contains your SKU trees (used to locate the source)\n",
        "WORKING_DIR = \"/content/drive/MyDrive/SikSilk\"                  # @param {type:\"string\"}\n",
        "\n",
        "# Root for (subcategory-wide) garment masks to constrain the detector\n",
        "MASKS_ROOT = \"/content/drive/MyDrive/SKSLK_MODELS\"              # @param {type:\"string\"}\n",
        "\n",
        "# Model/runtime knobs\n",
        "DEVICE_STR = \"cuda\"\n",
        "INPAINT_GENEROUS_PAD = 150                                      # @param {type:\"integer\"}\n",
        "INPAINT_TINY_PAD = 6                                            # @param {type:\"integer\"}\n",
        "INPAINT_SEED = 2025                                             # @param {type:\"integer\"}\n",
        "VISUALIZE = True                                                # @param {type:\"boolean\"}\n",
        "\n",
        "# File patterns\n",
        "VALID_EXTS = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".PNG\", \".JPG\", \".JPEG\", \".WEBP\")\n",
        "\n",
        "# Allowed detail tokens (normalized)\n",
        "ALLOWED_DETAIL_TYPES = [\"crest\", \"logo\", \"patch\", \"waist text\", \"sleeve text\"]\n",
        "\n",
        "# Allowed garment tokens (for prompting DINO)\n",
        "ALLOWED_GARMENT_TYPES = [\n",
        "    \"hoodie\",\"jeans\",\"joggers\",\"shorts\",\"sweater\",\"swimwear\",\"t-shirt\",\"shirts\",\n",
        "    \"track top\",\"trousers\",\"twinset\",\"polo\",\"vests\",\"shirts\"\n",
        "]\n",
        "TOP_GARMENTS = [\"t-shirt\", \"shirt\", \"sweater\", \"hoodie\", \"track top\", \"vest\"]\n",
        "BOTTOM_GARMENTS = [\"shorts\", \"jogger-trousers\", \"trousers\", \"jeans\", \"swimwear\"]\n",
        "TWINSET_TYPES = [\"twinset\"]\n",
        "\n",
        "# Angle parsing / source lookup helpers\n",
        "BASE_NAMES = [\"fr_rght\", \"fr_lft\", \"fr_cl\",\n",
        "              #\"bc_rght\", \"bc_lft\", \"bc_cl\", \"bc\",\n",
        "              \"fr\", \"lft\", \"rght\"]\n",
        "ACCEPTABLE_SUFFIXES = [\"cut\"]\n",
        "\n",
        "# Skip if already have any inpainted output in TARGET_DIR for this SKU+angle\n",
        "SKIP_IF_ALREADY_INPAINTED = True # @param {type:\"boolean\"}\n",
        "\n",
        "USE_BF16_INFERENCE = True  # global toggle\n",
        "\n",
        "\n",
        "# Create target dir if missing\n",
        "import os, pathlib\n",
        "pathlib.Path(TARGET_DIR).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INSTALLS (restart & reinstall again after this)"
      ],
      "metadata": {
        "id": "3WXWS5m9Ozyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "oqCgnsdjBfzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sam2"
      ],
      "metadata": {
        "id": "0ZUgwThxBmUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Utilities/FashionDINO\n",
        "# Install core libraries\n",
        "!pip install ninja\n",
        "\n",
        "# Clone GroundingDINO and install its Python requirements\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "!pip install -r GroundingDINO/requirements.txt\n",
        "\n",
        "# Add GroundingDINO repo to PYTHONPATH so we can import without installing\n",
        "%env PYTHONPATH /content/drive/MyDrive/Utilities/FashionDINO/GroundingDINO:$PYTHONPATH\n",
        "\n",
        "!cd GroundingDINO/ && python setup.py build_ext --inplace"
      ],
      "metadata": {
        "id": "MHz7WW6oBpDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install open_clip_torch ninja wheel transformers accelerate \\\n",
        "                 sentencepiece protobuf huggingface_hub opencv-python\n",
        "!pip install -U --no-deps --force-reinstall \"git+https://github.com/huggingface/diffusers.git@main\"\n",
        "#%pip -q install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install --upgrade open_clip_torch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CjRycBjyBsdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install piexif"
      ],
      "metadata": {
        "id": "pm9LoEbd5fn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone --depth 1 https://github.com/song-wensong/insert-anything.git"
      ],
      "metadata": {
        "id": "kufDQpabB4h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://huggingface.co/mit-han-lab/nunchaku/resolve/main/nunchaku-0.2.0+torch2.6-cp312-cp312-linux_x86_64.whl\n",
        "!pip install torch==2.6 torchvision==0.21 torchaudio==2.6\n",
        "!pip install ninja wheel diffusers transformers accelerate sentencepiece protobuf huggingface_hub\n",
        "!git clone https://huggingface.co/aha2023/insert-anything-lora-for-nunchaku"
      ],
      "metadata": {
        "id": "kkLr9zB3CJEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SETUP"
      ],
      "metadata": {
        "id": "SdvcT9PEO5ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, torch, numpy as np, cv2, base64, gc, json\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "from PIL import Image, ImageOps\n",
        "import torchvision.transforms as T\n",
        "import piexif\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"✅ Torch device:\", device)\n",
        "\n",
        "# make GroundingDINO importable\n",
        "sys.path.append(\"/content/GroundingDINO\")\n",
        "\n",
        "# EXIF-aware loader\n",
        "def open_upright(path) -> Image.Image:\n",
        "    with Image.open(path) as im:\n",
        "        return ImageOps.exif_transpose(im).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "HNmBx946B-JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Utilities/FashionDINO/GroundingDINO\n",
        "CONFIG_PATH = \"/content/drive/MyDrive/Utilities/FashionDINO/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
        "CKPT_PATH = \"/content/drive/MyDrive/Utilities/FashionDINO/GroundingDINO/groundingdino/models/groundingdino_swint_ogc.pth\"\n",
        "\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    !wget -q -O $CKPT_PATH https://huggingface.co/IDEA-Research/GroundingDINO/resolve/main/groundingdino_swint_ogc.pth\n",
        "\n",
        "from groundingdino.models import build_model\n",
        "from groundingdino.util.slconfig import SLConfig\n",
        "from groundingdino.util.utils import clean_state_dict\n",
        "from groundingdino.util.misc import nested_tensor_from_tensor_list\n",
        "\n",
        "def load_dino(config, ckpt, device):\n",
        "    args  = SLConfig.fromfile(config)\n",
        "    model = build_model(args)\n",
        "    sd    = torch.load(ckpt, map_location=\"cpu\")\n",
        "    model.load_state_dict(clean_state_dict(sd[\"model\"]), strict=False)\n",
        "    model.to(device).eval()\n",
        "    print(\"✅ Grounding-DINO loaded\")\n",
        "    return model\n",
        "\n",
        "dino_model = load_dino(CONFIG_PATH, CKPT_PATH, device)"
      ],
      "metadata": {
        "id": "azEqfSb-5p5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SAM2 part\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor"
      ],
      "metadata": {
        "id": "vuJxHufYTNKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam_predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\")\n",
        "print(\"✅ SAM2‑No-LoRA ready!\")"
      ],
      "metadata": {
        "id": "jCTA2cBPTQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Insert_anything on nunchaku\n",
        "%cd /content/insert-anything\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from diffusers import FluxFillPipeline, FluxPriorReduxPipeline\n",
        "from utils.utils import get_bbox_from_mask, expand_bbox, pad_to_square, box2squre, expand_image_mask\n",
        "from nunchaku.models.transformers.transformer_flux import NunchakuFluxTransformer2dModel\n",
        "from datetime import datetime\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(f\"cuda\")\n",
        "dtype = torch.bfloat16\n",
        "size = (1024, 1024)\n",
        "\n",
        "\n",
        "\n",
        "# Load the pre-trained model and LoRA-for-nunchaku weights\n",
        "# Please replace the paths with your own paths\n",
        "transformer = NunchakuFluxTransformer2dModel.from_pretrained(\"mit-han-lab/svdq-int4-flux.1-fill-dev\")\n",
        "\n",
        "pipe = FluxFillPipeline.from_pretrained(\n",
        "    \"black-forest-labs/FLUX.1-Fill-dev\",\n",
        "    transformer=transformer,\n",
        "    torch_dtype=dtype\n",
        ")\n",
        "\n",
        "transformer.update_lora_params(\"/content/drive/MyDrive/insert-anything-lora/insert-anything_extracted_lora_rank_256-bf16.safetensors\")\n",
        "# Adjust the LoRA strength\n",
        "transformer.set_lora_strength(1)\n",
        "\n",
        "redux = FluxPriorReduxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-Redux-dev\").to(dtype=dtype)\n",
        "\n",
        "\n",
        "\n",
        "# The purpose of this code is to reduce the GPU memory usage to 26GB, but it will increase the inference time accordingly.\n",
        "pipe.to(\"cuda\")\n",
        "redux.to(\"cuda\")\n",
        "os.environ[\"NNCF_GROUP_SIZE\"] = \"-1\"      # disable token merging\n"
      ],
      "metadata": {
        "id": "f4e99gLxT3TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILS"
      ],
      "metadata": {
        "id": "0nznhr0CO8xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "q5N9LysfFp9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_upright(path) -> Image.Image:\n",
        "    with Image.open(path) as im:\n",
        "        return ImageOps.exif_transpose(im).convert(\"RGB\")\n",
        "\n",
        "def open_source_with_black_bg(path: str) -> Image.Image:\n",
        "    im = Image.open(path)\n",
        "    im = ImageOps.exif_transpose(im)\n",
        "    name_low = os.path.basename(path).lower()\n",
        "    if \"_cut\" in name_low and im.mode in (\"RGBA\",\"LA\"):\n",
        "        rgb = im.convert(\"RGB\")\n",
        "        alpha = im.getchannel(\"A\")\n",
        "        black = Image.new(\"RGB\", im.size, (0,0,0))\n",
        "        return Image.composite(rgb, black, alpha)\n",
        "    return im.convert(\"RGB\")\n",
        "\n",
        "\n",
        "# NEW — root of subcategory-wide garment masks\n",
        "MASKS_ROOT = '/content/drive/MyDrive/SKSLK_MODELS'\n",
        "MASK_EXTS = ('.png', '.jpg', '.jpeg', '.webp', '.PNG', '.JPG', '.JPEG', '.WEBP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps, ImageDraw\n",
        "\n",
        "# --- Helper: get <Category>/<Subcategory> from the *source* path ------------\n",
        "_SKU_DIR_RE = re.compile(r\"SS-\\d{3,7}\", re.IGNORECASE)\n",
        "\n",
        "def _category_subcategory_from_source(src_path: str) -> tuple[str, str] | None:\n",
        "    \"\"\"\n",
        "    Resolve (Category, Subcategory) from the garment *source* path.\n",
        "    Preferred: relative to WORKING_DIR → parts[0], parts[1].\n",
        "    Fallback: find the SKU folder in the path and take the two parents.\n",
        "    Returns None if not resolvable.\n",
        "    \"\"\"\n",
        "    p = Path(src_path).resolve()\n",
        "    wr = Path(WORKING_DIR).resolve()\n",
        "\n",
        "    # Preferred: relative to WORKING_DIR\n",
        "    try:\n",
        "        rel = p.relative_to(wr)\n",
        "        parts = rel.parts\n",
        "        # Expect: Category/Subcategory/SKU/<file>\n",
        "        if len(parts) >= 3:\n",
        "            return parts[0], parts[1]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Fallback: locate the SKU dir and take its two parents as Cat/Subcat\n",
        "    parts = p.parts\n",
        "    sku_idx = None\n",
        "    for i, part in enumerate(parts):\n",
        "        if _SKU_DIR_RE.fullmatch(part or \"\"):\n",
        "            sku_idx = i\n",
        "            break\n",
        "    if sku_idx is not None and sku_idx >= 2:\n",
        "        return parts[sku_idx - 2], parts[sku_idx - 1]\n",
        "\n",
        "    # Last resort: try after an explicit 'SikSilk' anchor\n",
        "    if \"SikSilk\" in parts:\n",
        "        j = parts.index(\"SikSilk\")\n",
        "        if len(parts) >= j + 3:\n",
        "            return parts[j + 1], parts[j + 2]\n",
        "\n",
        "    return None\n",
        "\n",
        "# --- New: derive mask basename from *angle*, not from filename heuristics ----\n",
        "def _mask_basename_from_angle(angle_code: str | None) -> str | None:\n",
        "    \"\"\"\n",
        "    Map 'fr' -> 'fr_mask', 'fr_lft' -> 'fr_lft_mask', 'bc_cl' -> 'bc_cl_mask', etc.\n",
        "    If angle_code is missing, return None (→ no mask).\n",
        "    \"\"\"\n",
        "    if not angle_code:\n",
        "        return None\n",
        "    angle = angle_code.strip().lower()\n",
        "    return f\"{angle}_mask\"\n",
        "\n",
        "# --- Exact-only mask finder ---------------------------------------------------\n",
        "\n",
        "def find_mask_for_generated_exact(gen_path: str, source_path: str) -> Path | None:\n",
        "    \"\"\"\n",
        "    EXACT lookup (no fuzzy fallbacks):\n",
        "      angle  = parsed from queued filename/path (e.g., SS-12345_fr_cl.* -> 'fr_cl')\n",
        "      (cat, subcat) = derived from source_path\n",
        "      priority: <angle>_mask_agnostic.<ext>  →  <angle>_mask.<ext>\n",
        "      searched in: MASKS_ROOT / cat / subcat\n",
        "    \"\"\"\n",
        "    # 1) angle from queued filename\n",
        "    _, angle = extract_sku_and_angle_from_path(gen_path)\n",
        "    if not angle:\n",
        "        print(\"⚠️  No angle parsed — proceeding without a mask.\")\n",
        "        return None\n",
        "    angle = angle.strip().lower()\n",
        "\n",
        "    # 2) category/subcategory from source path\n",
        "    cat_sub = _category_subcategory_from_source(source_path)\n",
        "    if not cat_sub:\n",
        "        print(\"⚠️  Could not resolve Category/Subcategory from source path — no mask.\")\n",
        "        return None\n",
        "    category, subcategory = cat_sub\n",
        "\n",
        "    mask_dir = Path(MASKS_ROOT) / category / subcategory\n",
        "\n",
        "    # 3) Try agnostic first, then regular; exact names only\n",
        "    candidates = [f\"{angle}_mask_agnostic\", f\"{angle}_mask\"]\n",
        "\n",
        "    for name in candidates:\n",
        "        for ext in MASK_EXTS:\n",
        "            cand = mask_dir / f\"{name}{ext}\"\n",
        "            if cand.exists():\n",
        "                which = \"agnostic\" if name.endswith(\"_agnostic\") else \"regular\"\n",
        "                print(f\"✅ Found {which} mask: {cand}\")\n",
        "                return cand\n",
        "\n",
        "    print(f\"⚠️  No exact mask found in {mask_dir} for angle '{angle}' \"\n",
        "          f\"(tried {candidates} with MASK_EXTS). Proceeding without mask.\")\n",
        "    return None\n",
        "\n",
        "def load_binary_mask_for_generated(gen_path: str, source_path: str, gen_img: Image.Image) -> np.ndarray | None:\n",
        "    mp = find_mask_for_generated_exact(gen_path, source_path)\n",
        "    if mp is None:\n",
        "        return None\n",
        "    with Image.open(mp) as m:\n",
        "        m = ImageOps.exif_transpose(m)\n",
        "        return align_mask_to_image(m, gen_img)\n",
        "\n",
        "# --- Align (unchanged) --------------------------------------------------------\n",
        "def align_mask_to_image(mask_img: Image.Image, target_img: Image.Image) -> np.ndarray:\n",
        "    mw, mh = mask_img.size\n",
        "    tw, th = target_img.size\n",
        "    if mh == th and mw > 0 and (tw % mw) == 0 and 1 < (tw // mw) <= 3:\n",
        "        k = tw // mw\n",
        "        tiled = Image.new('L', (tw, th), 0)\n",
        "        src = mask_img.convert('L')\n",
        "        for i in range(k):\n",
        "            tiled.paste(src, (i * mw, 0))\n",
        "        M = np.array(tiled, dtype=np.uint8)\n",
        "    else:\n",
        "        if mw == 0 or mh == 0:\n",
        "            return np.zeros((th, tw), np.uint8)\n",
        "        scale = max(mw / tw, mh / th)\n",
        "        new_w = int(round(mw / scale)); new_h = int(round(mh / scale))\n",
        "        m_resized = mask_img.convert('L').resize((new_w, new_h), Image.NEAREST)\n",
        "        M = np.zeros((th, tw), np.uint8)\n",
        "        x0 = (tw - new_w) // 2; y0 = (th - new_h) // 2\n",
        "        M[y0:y0+new_h, x0:x0+new_w] = np.array(m_resized, dtype=np.uint8)\n",
        "    return ((M > 127).astype(np.uint8) * 255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---- visuals\n",
        "def _draw_bbox(img: Image.Image, bb_xyxy, color=\"lime\", width=4):\n",
        "    out = img.copy()\n",
        "    if bb_xyxy is None: return out\n",
        "    draw = ImageDraw.Draw(out)\n",
        "    draw.rectangle(bb_xyxy, outline=color, width=width)\n",
        "    return out\n",
        "\n",
        "def _show_images(pairs, cols=3, figsize=(16,12)):\n",
        "    rows = int(np.ceil(len(pairs) / cols))\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "    axes = axes.flatten() if rows*cols>1 else [axes]\n",
        "    for ax,(title,img) in zip(axes, pairs):\n",
        "        ax.imshow(img); ax.set_title(title, fontsize=10); ax.axis(\"off\")\n",
        "    for ax in axes[len(pairs):]: ax.axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def resize_and_pad(image, target_size=1024):\n",
        "    w, h = image.size\n",
        "    scale = target_size / max(1, max(w, h))\n",
        "    new_w, new_h = int(round(w * scale)), int(round(h * scale))\n",
        "    image_resized = image.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "    pad_w = (target_size - new_w) // 2\n",
        "    pad_h = (target_size - new_h) // 2\n",
        "    padding = (pad_w, pad_h, target_size - new_w - pad_w, target_size - new_h - pad_h)\n",
        "\n",
        "    # ✅ Match fill type to mode\n",
        "    mode = image_resized.mode\n",
        "    if mode in (\"L\", \"1\", \"I\", \"F\"):\n",
        "        fill_color = 0                      # int for single-channel\n",
        "    elif mode == \"RGBA\":\n",
        "        fill_color = (0, 0, 0, 0)           # transparent for RGBA\n",
        "    else:\n",
        "        fill_color = (0, 0, 0)              # RGB tuple for RGB/others\n",
        "\n",
        "    return ImageOps.expand(image_resized, padding, fill=fill_color)\n",
        "\n",
        "def box_1024_to_original(box_xyxy_1024, original_w, original_h):\n",
        "    x1_1024, y1_1024, x2_1024, y2_1024 = [float(v) for v in box_xyxy_1024]\n",
        "    target_size = 1024\n",
        "    w, h = original_w, original_h\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(round(w*scale)), int(round(h*scale))\n",
        "    pad_w = (target_size - new_w)//2\n",
        "    pad_h = (target_size - new_h)//2\n",
        "    x1 = (x1_1024 - pad_w) / scale; x2 = (x2_1024 - pad_w) / scale\n",
        "    y1 = (y1_1024 - pad_h) / scale; y2 = (y2_1024 - pad_h) / scale\n",
        "    x1 = min(max(int(round(x1)),0), w); x2 = min(max(int(round(x2)),0), w)\n",
        "    y1 = min(max(int(round(y1)),0), h); y2 = min(max(int(round(y2)),0), h)\n",
        "    return [x1,y1,x2,y2]\n"
      ],
      "metadata": {
        "id": "VGxk8vnk5wU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_binary_mask(img_rgb: Image.Image, mask_np: np.ndarray | None, outside_color=(5,5,5)) -> Image.Image:\n",
        "    if mask_np is None: return img_rgb\n",
        "    mask_L = Image.fromarray(mask_np.astype(np.uint8))\n",
        "    mode = img_rgb.mode\n",
        "    if mode not in (\"RGB\",\"RGBA\",\"L\"): img_rgb = img_rgb.convert(\"RGB\"); mode=\"RGB\"\n",
        "    if mode == \"RGB\":\n",
        "        if isinstance(outside_color, int): outside_color = (outside_color,)*3\n",
        "        bg = Image.new(\"RGB\", img_rgb.size, outside_color)\n",
        "    elif mode == \"RGBA\":\n",
        "        if isinstance(outside_color, int): outside_color = (outside_color,)*3 + (255,)\n",
        "        elif len(outside_color)==3: outside_color = (*outside_color,255)\n",
        "        bg = Image.new(\"RGBA\", img_rgb.size, outside_color)\n",
        "    else:\n",
        "        if isinstance(outside_color, tuple): outside_color = int(np.mean(outside_color))\n",
        "        bg = Image.new(\"L\", img_rgb.size, int(outside_color))\n",
        "    return Image.composite(img_rgb, bg, mask_L)\n",
        "\n",
        "def get_sam_mask(image_np, bbox):\n",
        "    sam_predictor.set_image(image_np)\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16 if USE_BF16_INFERENCE else torch.float32):\n",
        "      masks, scores, _ = sam_predictor.predict(box=bbox)\n",
        "\n",
        "    return masks[scores.argmax()]\n",
        "\n",
        "def get_sam_contour_mask(image_pil: Image.Image, bbox_xyxy):\n",
        "    image_np = np.array(image_pil)\n",
        "    x1,y1,x2,y2 = map(int, bbox_xyxy)\n",
        "    mask = get_sam_mask(image_np, [x1,y1,x2,y2])\n",
        "    return (mask>0).astype(np.uint8)*255\n",
        "\n",
        "\n",
        "\n",
        "# Dynamic, perimeter-based mask gating for detect_detail (logo-friendly)\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw\n",
        "# Spatially guided detect_detail:\n",
        "# - perimeter-based mask polarity (as before)\n",
        "# - strict+tolerant mask gates\n",
        "# - spatial prior from source garment (normalized center+area)\n",
        "# - combined score = w_dino * dino_score + w_spatial * spatial_affinity + w_inside * inside_frac\n",
        "\n",
        "\n",
        "# ---- helpers ---------------------------------------------------------------\n",
        "# Top-7 spatial re-ranking for detail detection\n",
        "# - Keeps perimeter-based mask polarity & light gates\n",
        "# - Takes DINO's highest-scoring proposals, filters with mask gates, then\n",
        "#   re-ranks TOP_K (default 7) using spatial prior from the SOURCE garment\n",
        "# - Normalizes DINO scores within those K and slightly down-weights rank-1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- helpers you already use elsewhere ----------\n",
        "def make_spatial_prior_from_box(bb_xyxy, img_size):\n",
        "    \"\"\"Build prior from SOURCE detail box on its garment crop. Normalized to [0,1].\"\"\"\n",
        "    if bb_xyxy is None:\n",
        "        return None\n",
        "    W, H = img_size\n",
        "    x1, y1, x2, y2 = [float(v) for v in bb_xyxy]\n",
        "    x1 = max(0.0, min(W, x1)); y1 = max(0.0, min(H, y1))\n",
        "    x2 = max(0.0, min(W, x2)); y2 = max(0.0, min(H, y2))\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return None\n",
        "    cx = ((x1 + x2) / 2.0) / max(1.0, W)\n",
        "    cy = ((y1 + y2) / 2.0) / max(1.0, H)\n",
        "    area = ((x2 - x1) * (y2 - y1)) / max(1.0, (W * H))\n",
        "    return {\"cx\": float(cx), \"cy\": float(cy), \"area\": float(area)}\n",
        "\n",
        "def _spatial_affinity(cx_n, cy_n, area_n, prior, mirror_ok=True,\n",
        "                      sigma_center=0.16, sigma_area=0.50):\n",
        "    \"\"\"Gaussian affinity in [0,1] for center & (log)area; mirror-aware.\"\"\"\n",
        "    def _aff(cx_p):\n",
        "        dc2 = (cx_n - cx_p)**2 + (cy_n - prior[\"cy\"])**2\n",
        "        s_center = np.exp(- dc2 / (2.0 * (sigma_center**2)))\n",
        "        a = max(1e-6, area_n); ap = max(1e-6, prior[\"area\"])\n",
        "        dlog = np.log(a / ap)\n",
        "        s_area = np.exp(- (dlog**2) / (2.0 * (sigma_area**2)))\n",
        "        return float(s_center * s_area)\n",
        "    base = _aff(prior[\"cx\"])\n",
        "    if mirror_ok:\n",
        "        return max(base, _aff(1.0 - prior[\"cx\"]))\n",
        "    return base\n",
        "\n",
        "# ---------- main: top-7 re-ranking ----------\n",
        "\n",
        "\n",
        "def _ensure_mask_for_image(mask_input, image_pil, *, crop_box_on_full=None):\n",
        "    \"\"\"\n",
        "    Align a mask to image_pil.\n",
        "\n",
        "    mask_input:\n",
        "      • np.ndarray aligned to image_pil (H×W)  OR\n",
        "      • (mask_full_np, \"FULL\") + crop_box_on_full=(lx,ty,rx,by) from crop_to_square\n",
        "\n",
        "    Returns: uint8 mask (0/255) aligned to image_pil.size, with the same padding\n",
        "    behavior as crop_to_square (i.e., if the crop went outside, we pad zeros).\n",
        "    \"\"\"\n",
        "    if mask_input is None:\n",
        "        return None\n",
        "\n",
        "    # Case 1: already aligned to this image\n",
        "    if not (isinstance(mask_input, tuple) and len(mask_input) == 2 and isinstance(mask_input[0], np.ndarray) and mask_input[1] == \"FULL\"):\n",
        "        m = mask_input\n",
        "        if m.ndim == 3:\n",
        "            m = m[...,0] if m.shape[2] > 1 else m.squeeze(-1)\n",
        "        if m.dtype != np.uint8:\n",
        "            m = (m > 0).astype(np.uint8) * 255\n",
        "        if (m.shape[1], m.shape[0]) != image_pil.size:\n",
        "            m = cv2.resize(m, image_pil.size, interpolation=cv2.INTER_NEAREST)\n",
        "        return m\n",
        "\n",
        "    # Case 2: FULL mask + crop box from crop_to_square\n",
        "    mask_full, _ = mask_input\n",
        "    assert crop_box_on_full is not None, \"crop_box_on_full is required for FULL mask.\"\n",
        "\n",
        "    Hf, Wf = mask_full.shape[:2]\n",
        "    lx, ty, rx, by = crop_box_on_full  # exactly what crop_to_square returned\n",
        "\n",
        "    # Target canvas (the square side used by crop_to_square)\n",
        "    tgt_w = int(round(rx - lx))\n",
        "    tgt_h = int(round(by - ty))\n",
        "\n",
        "    # Source window (clamped to the full image bounds)\n",
        "    sx1 = int(np.floor(max(0, lx)))\n",
        "    sy1 = int(np.floor(max(0, ty)))\n",
        "    sx2 = int(np.ceil(min(Wf, rx)))\n",
        "    sy2 = int(np.ceil(min(Hf, by)))\n",
        "\n",
        "    # Offsets where the source window lands on the target canvas\n",
        "    dx = int(np.floor(max(0, -lx)))   # same as crop_to_square's dx\n",
        "    dy = int(np.floor(max(0, -ty)))   # same as crop_to_square's dy\n",
        "\n",
        "    # Build canvas and paste the clipped region at (dx,dy)\n",
        "    canvas = np.zeros((tgt_h, tgt_w), dtype=np.uint8)\n",
        "    if sx2 > sx1 and sy2 > sy1:\n",
        "        patch = mask_full[sy1:sy2, sx1:sx2]\n",
        "        if patch.ndim == 3:\n",
        "            patch = patch[...,0] if patch.shape[2] > 1 else patch.squeeze(-1)\n",
        "        ph, pw = patch.shape[:2]\n",
        "        canvas[dy:dy+ph, dx:dx+pw] = (patch > 0).astype(np.uint8) * 255\n",
        "\n",
        "    # If image_pil size differs by a pixel due to rounding, align by resize\n",
        "    if (canvas.shape[1], canvas.shape[0]) != image_pil.size:\n",
        "        canvas = cv2.resize(canvas, image_pil.size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def _build_inside_mask_1024(mask_aligned_np, image_pil, *,\n",
        "                            border_sample_px=2, erode_px=1, dilate_px=2,\n",
        "                            debug=False):\n",
        "    \"\"\"\n",
        "    Build 1024×1024 INSIDE mask with perimeter-based polarity, using the\n",
        "    SAME resize_and_pad as the image to guarantee geometric alignment.\n",
        "    \"\"\"\n",
        "    if mask_aligned_np is None:\n",
        "        return None\n",
        "\n",
        "    # 1) pad the mask to 1024 with the SAME routine as the image\n",
        "    mL = Image.fromarray(mask_aligned_np, mode=\"L\")\n",
        "    m1024L = resize_and_pad(mL, target_size=1024).convert(\"L\")\n",
        "    m1024 = (np.array(m1024L) > 0)\n",
        "\n",
        "    # 2) Perimeter-majority: which value dominates the border?\n",
        "    h, w = m1024.shape\n",
        "    b = max(1, int(border_sample_px))\n",
        "    perim = np.concatenate([m1024[0:b,:].ravel(), m1024[h-b:h,:].ravel(),\n",
        "                            m1024[:,0:b].ravel(), m1024[:,w-b:w].ravel()])\n",
        "    ones = int(perim.sum()); zeros = int(perim.size - perim.sum())\n",
        "    background_is_true = (ones >= zeros)   # majority on border = background\n",
        "    inside = (~m1024) if background_is_true else m1024\n",
        "\n",
        "    # 3) Moprhology for robust gating\n",
        "    if erode_px > 0:\n",
        "        k_e = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_px*2+1, erode_px*2+1))\n",
        "        inside = cv2.erode(inside.astype(np.uint8), k_e, 1).astype(bool)\n",
        "    if dilate_px > 0:\n",
        "        k_d = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_px*2+1, dilate_px*2+1))\n",
        "        inside = cv2.dilate(inside.astype(np.uint8), k_d, 1).astype(bool)\n",
        "\n",
        "    if debug:\n",
        "        bg_txt = \"white/True\" if background_is_true else \"black/False\"\n",
        "        cov = float(inside.mean())\n",
        "        print(f\"[mask1024] perimeter True={ones} False={zeros} → background={bg_txt}; inside_cov={cov:.3f}\")\n",
        "\n",
        "    return inside\n",
        "\n",
        "def detect_detail_topk7(image_pil: Image.Image,\n",
        "                        detail_type: str,\n",
        "                        *,\n",
        "                        source_prior: dict | None,\n",
        "                        restrict_mask,                 # EITHER aligned np.ndarray OR (mask_full_np, \"FULL\")\n",
        "                        crop_box_on_full=None,         # required if restrict_mask is (\"FULL\")\n",
        "                        threshold: float = 0.05,\n",
        "                        TOP_K: int = 7,\n",
        "                        mirror_ok: bool = True,\n",
        "                        # light mask gates\n",
        "                        min_inside_frac: float = 0.30,\n",
        "                        center_must_be_inside: bool = True,\n",
        "                        erode_px: int = 1,\n",
        "                        dilate_px: int = 2,\n",
        "                        border_sample_px: int = 2,\n",
        "                        # scoring weights\n",
        "                        w_spatial: float = 0.65,\n",
        "                        w_dino: float = 0.35,\n",
        "                        rank_weights: list[float] = None,\n",
        "                        debug: bool = False,\n",
        "                        viz: bool = False,\n",
        "                        viz_overlay_mask: bool = True):\n",
        "    \"\"\"\n",
        "    Robust top-7 re-ranking that *guarantees* mask/image alignment:\n",
        "      - Pass restrict_mask as either:\n",
        "          • aligned mask np.ndarray (same H×W as image_pil), OR\n",
        "          • (mask_full_np, \"FULL\") + crop_box_on_full=(x1,y1,x2,y2) used to make image_pil.\n",
        "    \"\"\"\n",
        "    if rank_weights is None:\n",
        "        rank_weights = [0.92, 1.00, 0.98, 0.97, 0.96, 0.955, 0.95]\n",
        "\n",
        "    W0, H0 = image_pil.size\n",
        "    prompt = (detail_type or \"\").strip() + \" .\"\n",
        "\n",
        "    # --- 0) Align the mask to the image crop BEFORE any padding -------------\n",
        "    mask_aligned = _ensure_mask_for_image(restrict_mask, image_pil, crop_box_on_full=crop_box_on_full)\n",
        "\n",
        "    # quick sanity check on coverage (to catch obvious misalignment)\n",
        "    if mask_aligned is not None:\n",
        "        cov = float((mask_aligned > 0).mean())\n",
        "        if debug:\n",
        "            print(f\"[mask-aligned] coverage={cov:.3f} (on crop {W0}×{H0})\")\n",
        "        # If coverage is suspiciously tiny or ~all, warn (but still proceed)\n",
        "        if cov < 0.01 or cov > 0.98:\n",
        "            print(\"⚠️  mask coverage looks suspicious for this crop; check crop_box vs. mask origin.\")\n",
        "\n",
        "    # --- 1) Build the 1024 image & mask (same resize_and_pad) ---------------\n",
        "    view = apply_binary_mask(image_pil, mask_aligned) if mask_aligned is not None else image_pil\n",
        "    padded = resize_and_pad(view)  # 1024×1024\n",
        "\n",
        "    mask_inside_1024 = _build_inside_mask_1024(mask_aligned, image_pil,\n",
        "                                               border_sample_px=border_sample_px,\n",
        "                                               erode_px=erode_px,\n",
        "                                               dilate_px=dilate_px,\n",
        "                                               debug=debug)\n",
        "\n",
        "    # --- 2) DINO forward -----------------------------------------------------\n",
        "    tens = T.ToTensor()(padded)\n",
        "    nt   = nested_tensor_from_tensor_list([tens.to(device)])\n",
        "    with torch.no_grad():\n",
        "        out = dino_model(nt, captions=[prompt])\n",
        "\n",
        "    logits = out[\"pred_logits\"][0].sigmoid().cpu()\n",
        "    scores = logits.max(1).values\n",
        "    boxes  = out[\"pred_boxes\"][0].cpu()\n",
        "    if boxes.ndim == 1: boxes = boxes.view(-1, 4)\n",
        "    elif boxes.size(-1) != 4: boxes = boxes.reshape(-1, 4)\n",
        "\n",
        "    if boxes.shape[0] == 0:\n",
        "        return (None, None)\n",
        "\n",
        "    # --- 3) rank by raw DINO, apply light mask gates, keep top-K ------------\n",
        "    idx_sorted = torch.argsort(scores, descending=True).tolist()\n",
        "\n",
        "    def _xyxy_1024(row):\n",
        "        cx,cy,w,h = row.tolist()\n",
        "        x1 = (cx - w/2.0)*1024.0; y1 = (cy - h/2.0)*1024.0\n",
        "        x2 = (cx + w/2.0)*1024.0; y2 = (cy + h/2.0)*1024.0\n",
        "        return [int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))]\n",
        "\n",
        "    def _clip(b):\n",
        "        x1,y1,x2,y2 = b\n",
        "        x1=max(0,min(1024,x1)); y1=max(0,min(1024,y1))\n",
        "        x2=max(0,min(1024,x2)); y2=max(0,min(1024,y2))\n",
        "        return x1,y1,x2,y2\n",
        "\n",
        "    picked = []\n",
        "    rank = 0\n",
        "    for i in idx_sorted:\n",
        "        if threshold is not None and float(scores[i].item()) < threshold:\n",
        "            continue\n",
        "        b = _clip(_xyxy_1024(boxes[i]))\n",
        "        x1,y1,x2,y2 = b\n",
        "        if x2 <= x1 or y2 <= y1: continue\n",
        "\n",
        "        ok = True\n",
        "        if mask_inside_1024 is not None:\n",
        "            crop = mask_inside_1024[y1:y2, x1:x2]\n",
        "            area = (x2-x1)*(y2-y1)\n",
        "            if area <= 0: ok = False\n",
        "            else:\n",
        "                inside_frac = float(crop.sum())/float(area)\n",
        "                cxp,cyp = (x1+x2)//2, (y1+y2)//2\n",
        "                center_ok = (0<=cxp<1024 and 0<=cyp<1024 and bool(mask_inside_1024[cyp, cxp]))\n",
        "                ok = (inside_frac >= min_inside_frac) and (not center_must_be_inside or center_ok)\n",
        "\n",
        "        if not ok: continue\n",
        "\n",
        "        picked.append({\"i\": i, \"box1024\": b, \"score\": float(scores[i].item()), \"rank\": rank})\n",
        "        rank += 1\n",
        "        if rank >= TOP_K: break\n",
        "\n",
        "    if not picked:\n",
        "        # last resort: best raw DINO\n",
        "        i_best = int(torch.argmax(scores).item())\n",
        "        picked = [{\"i\": i_best, \"box1024\": _clip(_xyxy_1024(boxes[i_best])),\n",
        "                   \"score\": float(scores[i_best].item()), \"rank\": 0}]\n",
        "\n",
        "    # --- 4) normalize DINO within the picked set and apply rank weights ------\n",
        "    s = np.array([p[\"score\"] for p in picked], dtype=np.float32)\n",
        "    s_min, s_max = float(s.min()), float(s.max())\n",
        "    if s_max > s_min: s_norm = (s - s_min)/(s_max - s_min)\n",
        "    else: s_norm = np.ones_like(s)*0.5\n",
        "\n",
        "    for j,p in enumerate(picked):\n",
        "        rw = rank_weights[p[\"rank\"]] if p[\"rank\"] < len(rank_weights) else rank_weights[-1]\n",
        "        p[\"dino_norm_weighted\"] = float(s_norm[j] * rw)\n",
        "\n",
        "    # --- 5) spatial prior re-ranking -----------------------------------------\n",
        "    best = None\n",
        "    for p in picked:\n",
        "        x1,y1,x2,y2 = p[\"box1024\"]\n",
        "        area = (x2-x1)*(y2-y1)\n",
        "        cx_n = ((x1+x2)/2.0)/1024.0\n",
        "        cy_n = ((y1+y2)/2.0)/1024.0\n",
        "        area_n = area/float(1024*1024)\n",
        "        spatial = 0.0\n",
        "        if source_prior is not None:\n",
        "            spatial = _spatial_affinity(cx_n, cy_n, area_n, source_prior, mirror_ok=mirror_ok)\n",
        "        combo = w_spatial*spatial + w_dino*p[\"dino_norm_weighted\"]\n",
        "        p[\"spatial\"] = float(spatial); p[\"combo\"] = float(combo)\n",
        "        if best is None or combo > best[\"combo\"]:\n",
        "            best = p\n",
        "    '''\n",
        "    # --- 6) viz (optionally overlay mask used in scoring) --------------------\n",
        "    if viz:\n",
        "        img = padded.copy()\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        if viz_overlay_mask and mask_inside_1024 is not None:\n",
        "            # light overlay of the mask boundary for sanity check\n",
        "            edge = cv2.Canny((mask_inside_1024.astype(np.uint8))*255, 50, 150)\n",
        "            edge_rgb = np.stack([edge]*3, axis=-1)\n",
        "            base = np.array(img)\n",
        "            base[edge>0] = [0,255,0]  # green edge\n",
        "            img = Image.fromarray(base)\n",
        "\n",
        "        for p in picked:\n",
        "            x1,y1,x2,y2 = p[\"box1024\"]\n",
        "            w = 5 if p is best else 2\n",
        "            color = \"lime\" if p is best else \"yellow\"\n",
        "            draw.rectangle([x1,y1,x2,y2], outline=color, width=w)\n",
        "            label = f\"r{p['rank']+1} c{p['combo']:.2f}\"\n",
        "            draw.text((x1+3, y1+3), label, fill=\"white\")\n",
        "        plt.figure(figsize=(6,6)); plt.imshow(img); plt.axis(\"off\"); plt.title(\"Top-K after re-ranking (mask overlaid)\")\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "    # --- 7) map best to ORIGINAL image coords (of image_pil) -----------------\n",
        "    bx = boxes[best[\"i\"]].tolist()\n",
        "    cx, cy, w, h = bx\n",
        "    x1_1024 = (cx - w/2.0)*1024.0; y1_1024 = (cy - h/2.0)*1024.0\n",
        "    x2_1024 = (cx + w/2.0)*1024.0; y2_1024 = (cy + h/2.0)*1024.0\n",
        "    xyxy_orig = box_1024_to_original([x1_1024, y1_1024, x2_1024, y2_1024], W0, H0)\n",
        "    return xyxy_orig, float(scores[best[\"i\"]].item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def detect_detail(image_pil: Image.Image,\n",
        "                  detail_type: str,\n",
        "                  threshold: float = 0.05,\n",
        "                  used_boxes=None,\n",
        "                  keep_best: bool = False,           # don't pick outside fallback\n",
        "                  iou_thr: float = 0.35,\n",
        "                  restrict_mask: np.ndarray | None = None,\n",
        "                  # base gates (will be *relaxed* dynamically for small boxes)\n",
        "                  min_inside_frac: float = 0.40,     # tolerant for small logos\n",
        "                  max_outside_frac: float = 0.70,\n",
        "                  center_must_be_inside: bool = True,\n",
        "                  # morphology & perimeter\n",
        "                  erode_px: int = 1,\n",
        "                  dilate_px: int = 2,\n",
        "                  border_sample_px: int = 2,\n",
        "                  # debugging\n",
        "                  debug: bool = False,\n",
        "                  debug_topk: int = 5):\n",
        "    \"\"\"\n",
        "    Strict-but-dynamic detail locator with:\n",
        "      • Perimeter-majority polarity\n",
        "      • Dual masks: strict (eroded) and tolerant (dilated)\n",
        "      • Center-inside rule\n",
        "      • Dynamic thresholds (easier if box is small)\n",
        "      • Last-resort fallback: center-inside only\n",
        "    Returns: (xyxy_orig, score) or (None, None)\n",
        "    \"\"\"\n",
        "    used_boxes = used_boxes or []\n",
        "    prompt = (detail_type or \"\").strip() + \" .\"\n",
        "\n",
        "    orig_w, orig_h = image_pil.size\n",
        "\n",
        "    # 1) Visual restriction for DINO (mask outside with dark fill)\n",
        "    view = apply_binary_mask(image_pil, restrict_mask) if restrict_mask is not None else image_pil\n",
        "\n",
        "    # 2) Prepare 1024×1024 versions\n",
        "    padded = resize_and_pad(view)  # 1024×1024\n",
        "\n",
        "    mask_inside_strict = None\n",
        "    mask_inside_tol = None\n",
        "    if restrict_mask is not None:\n",
        "        # Build 1024 mask in SAME geometry as padded image\n",
        "        mL = Image.fromarray(restrict_mask.astype(np.uint8), mode=\"L\")\n",
        "        m1024L = resize_and_pad(mL, target_size=1024).convert(\"L\")\n",
        "        m1024 = (np.array(m1024L) > 0)  # True where mask is white in the file\n",
        "\n",
        "        # --- Perimeter majority to infer BACKGROUND ---\n",
        "        h, w = m1024.shape\n",
        "        b = max(1, int(border_sample_px))\n",
        "        top = m1024[0:b, :]\n",
        "        bottom = m1024[h-b:h, :]\n",
        "        left = m1024[:, 0:b]\n",
        "        right = m1024[:, w-b:w]\n",
        "        perim = np.concatenate([top.ravel(), bottom.ravel(), left.ravel(), right.ravel()])\n",
        "        ones = int(perim.sum())\n",
        "        zeros = int(perim.size - ones)\n",
        "        background_is_true = (ones >= zeros)   # majority value on border = background\n",
        "        if debug:\n",
        "            print(f\"[mask-perimeter] border True={ones} False={zeros} → background={'True/white' if background_is_true else 'False/black'}; erode_px={erode_px}; dilate_px={dilate_px}\")\n",
        "\n",
        "        # INSIDE base = not(background)\n",
        "        mask_inside = (~m1024) if background_is_true else m1024\n",
        "\n",
        "        # Dual masks\n",
        "        if erode_px and erode_px > 0:\n",
        "            k_e = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_px*2+1, erode_px*2+1))\n",
        "            mask_inside_strict = cv2.erode(mask_inside.astype(np.uint8), k_e, iterations=1).astype(bool)\n",
        "        else:\n",
        "            mask_inside_strict = mask_inside\n",
        "\n",
        "        if dilate_px and dilate_px > 0:\n",
        "            k_d = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_px*2+1, dilate_px*2+1))\n",
        "            mask_inside_tol = cv2.dilate(mask_inside.astype(np.uint8), k_d, iterations=1).astype(bool)\n",
        "        else:\n",
        "            mask_inside_tol = mask_inside\n",
        "\n",
        "    # 3) GroundingDINO forward\n",
        "    tens = T.ToTensor()(padded)\n",
        "    nt   = nested_tensor_from_tensor_list([tens.to(device)])\n",
        "    with torch.no_grad():\n",
        "        out = dino_model(nt, captions=[prompt])\n",
        "\n",
        "    logits = out[\"pred_logits\"][0].sigmoid().cpu()   # (N, C)\n",
        "    scores = logits.max(1).values                    # (N,)\n",
        "    boxes  = out[\"pred_boxes\"][0].cpu()              # (N, 4) or (4,)\n",
        "\n",
        "    # Ensure (N,4)\n",
        "    if boxes.ndim == 1:\n",
        "        boxes = boxes.view(-1, 4)\n",
        "    elif boxes.size(-1) != 4:\n",
        "        boxes = boxes.reshape(-1, 4)\n",
        "\n",
        "    N = boxes.shape[0]\n",
        "    if N == 0:\n",
        "        return (None, None)\n",
        "\n",
        "    # 4) Score threshold filter\n",
        "    keep_mask = (scores > threshold)\n",
        "    keep_idx = keep_mask.nonzero(as_tuple=False).flatten().to(dtype=torch.long, device=scores.device)\n",
        "    if keep_idx.numel() == 0:\n",
        "        keep_idx = torch.arange(N, dtype=torch.long, device=scores.device)\n",
        "\n",
        "    # Helpers\n",
        "    def _to_xyxy_1024(row):\n",
        "        cx, cy, w, h = row.tolist()\n",
        "        x1 = (cx - w/2.0) * 1024.0\n",
        "        y1 = (cy - h/2.0) * 1024.0\n",
        "        x2 = (cx + w/2.0) * 1024.0\n",
        "        y2 = (cy + h/2.0) * 1024.0\n",
        "        return [x1, y1, x2, y2]\n",
        "\n",
        "    def _clip_box(b):\n",
        "        x1,y1,x2,y2 = [int(round(v)) for v in b]\n",
        "        x1 = max(0, min(1024, x1)); y1 = max(0, min(1024, y1))\n",
        "        x2 = max(0, min(1024, x2)); y2 = max(0, min(1024, y2))\n",
        "        return x1,y1,x2,y2\n",
        "\n",
        "    # 5) Mask gating with dynamic thresholds\n",
        "    passes = []\n",
        "    debug_rows = []\n",
        "    if mask_inside_strict is not None and keep_idx.numel() > 0:\n",
        "        for i in keep_idx.tolist():\n",
        "            x1,y1,x2,y2 = _clip_box(_to_xyxy_1024(boxes[i]))\n",
        "            if x2 <= x1 or y2 <= y1:\n",
        "                continue\n",
        "\n",
        "            wB, hB = (x2-x1), (y2-y1)\n",
        "            box_area = wB * hB\n",
        "            if box_area <= 0:\n",
        "                continue\n",
        "\n",
        "            # Fractions on dual masks\n",
        "            crop_strict = mask_inside_strict[y1:y2, x1:x2]\n",
        "            crop_tol    = mask_inside_tol[y1:y2, x1:x2] if mask_inside_tol is not None else crop_strict\n",
        "            inside_frac_strict = float(crop_strict.sum()) / float(box_area)\n",
        "            inside_frac_tol    = float(crop_tol.sum())    / float(box_area)\n",
        "            outside_frac_strict = 1.0 - inside_frac_strict\n",
        "\n",
        "            # Center check (on tolerant mask)\n",
        "            cx_i, cy_i = (x1+x2)//2, (y1+y2)//2\n",
        "            center_ok = True\n",
        "            if center_must_be_inside:\n",
        "                center_ok = (0 <= cx_i < 1024 and 0 <= cy_i < 1024 and bool(mask_inside_tol[cy_i, cx_i]))\n",
        "\n",
        "            # Dynamic easing for small boxes (logos): shrink min_inside, expand max_outside a bit\n",
        "            # Relative to full 1024^2 canvas\n",
        "            rel_area = box_area / float(1024*1024)\n",
        "            dyn_min_inside = min_inside_frac\n",
        "            dyn_max_outside = max_outside_frac\n",
        "            if rel_area < 0.01:          # tiny box\n",
        "                dyn_min_inside = max(0.30, min_inside_frac - 0.10)\n",
        "                dyn_max_outside = min(0.85, max_outside_frac + 0.10)\n",
        "            elif rel_area < 0.03:        # small box\n",
        "                dyn_min_inside = max(0.35, min_inside_frac - 0.05)\n",
        "                dyn_max_outside = min(0.80, max_outside_frac + 0.05)\n",
        "\n",
        "            ok = (center_ok and\n",
        "                  (inside_frac_tol >= dyn_min_inside) and\n",
        "                  (outside_frac_strict <= dyn_max_outside))\n",
        "\n",
        "            if debug and len(debug_rows) < debug_topk:\n",
        "                debug_rows.append({\n",
        "                    \"i\": i,\n",
        "                    \"score\": float(scores[i].item()),\n",
        "                    \"box\": (x1,y1,x2,y2),\n",
        "                    \"rel_area\": rel_area,\n",
        "                    \"inside_strict\": inside_frac_strict,\n",
        "                    \"inside_tol\": inside_frac_tol,\n",
        "                    \"outside_strict\": outside_frac_strict,\n",
        "                    \"center_ok\": center_ok,\n",
        "                    \"passed\": ok\n",
        "                })\n",
        "\n",
        "            if ok:\n",
        "                passes.append(i)\n",
        "\n",
        "        keep_idx = torch.as_tensor(passes, dtype=torch.long, device=scores.device)\n",
        "\n",
        "        if debug and debug_rows:\n",
        "            print(\"[detect_detail/debug] top candidates (after score>thr):\")\n",
        "            for row in sorted(debug_rows, key=lambda r: r[\"score\"], reverse=True):\n",
        "                print(f\"  idx={row['i']:>3}  score={row['score']:.3f}  \"\n",
        "                      f\"inside_tol={row['inside_tol']:.2f}  outside_strict={row['outside_strict']:.2f}  \"\n",
        "                      f\"center={row['center_ok']}  rel_area={row['rel_area']:.4f}  pass={row['passed']}\")\n",
        "\n",
        "    # 6) Final selection (with a small inside-only fallback if nothing passed)\n",
        "    if keep_idx.numel() == 0 and mask_inside_strict is not None:\n",
        "        # Relaxed fallback: just require the center to be inside (tolerant)\n",
        "        relaxed = []\n",
        "        for i in range(N):\n",
        "            x1,y1,x2,y2 = _clip_box(_to_xyxy_1024(boxes[i]))\n",
        "            if x2 <= x1 or y2 <= y1:\n",
        "                continue\n",
        "            cx_i, cy_i = (x1+x2)//2, (y1+y2)//2\n",
        "            if 0 <= cx_i < 1024 and 0 <= cy_i < 1024 and bool(mask_inside_tol[cy_i, cx_i]):\n",
        "                relaxed.append(i)\n",
        "        if relaxed:\n",
        "            keep_idx = torch.as_tensor(relaxed, dtype=torch.long, device=scores.device)\n",
        "            if debug:\n",
        "                print(\"[detect_detail] relaxed center-inside fallback engaged; \"\n",
        "                      f\"{len(relaxed)} candidates center-inside.\")\n",
        "\n",
        "    if keep_idx.numel() == 0:\n",
        "        if not keep_best or scores.numel() == 0:\n",
        "            if debug:\n",
        "                print(\"[detect_detail] No candidate satisfied mask gates.\")\n",
        "            return (None, None)\n",
        "        idx_chosen = int(torch.argmax(scores).item())\n",
        "    else:\n",
        "        cand_scores = scores.index_select(0, keep_idx)\n",
        "        order = torch.argsort(cand_scores, descending=True)\n",
        "        conf_sorted = keep_idx.index_select(0, order)\n",
        "        top_k = min(2, conf_sorted.numel())\n",
        "        top_idx = conf_sorted[:top_k]\n",
        "        if top_idx.numel() == 1:\n",
        "            idx_chosen = int(top_idx.item())\n",
        "        else:\n",
        "            cand_boxes = boxes.index_select(0, top_idx)   # (2,4)\n",
        "            areas = cand_boxes[:, 2] * cand_boxes[:, 3]\n",
        "            idx_chosen = int(top_idx[torch.argmin(areas)].item())\n",
        "\n",
        "    # 7) Map to original image coords\n",
        "    cx, cy, w, h = boxes[idx_chosen].tolist()\n",
        "    x1_1024 = (cx - w/2.0) * 1024.0\n",
        "    y1_1024 = (cy - h/2.0) * 1024.0\n",
        "    x2_1024 = (cx + w/2.0) * 1024.0\n",
        "    y2_1024 = (cy + h/2.0) * 1024.0\n",
        "    xyxy_orig = box_1024_to_original([x1_1024, y1_1024, x2_1024, y2_1024], orig_w, orig_h)\n",
        "    return xyxy_orig, float(scores[idx_chosen].item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def detect_garment_box(img: Image.Image, garment_tag: str, threshold=0.25, restrict_mask: np.ndarray | None = None):\n",
        "    O_W, O_H = img.size\n",
        "    if restrict_mask is not None:\n",
        "        m1024 = resize_and_pad(Image.fromarray(restrict_mask,'L'), 1024).convert('L')\n",
        "        mask_1024_np = (np.array(m1024)>127)\n",
        "        ys, xs = np.where(mask_1024_np>0)\n",
        "        if xs.size==0 or ys.size==0: return None\n",
        "        x1,y1,x2,y2 = [float(xs.min()), float(ys.min()), float(xs.max()), float(ys.max())]\n",
        "        return box_1024_to_original([x1,y1,x2,y2], O_W, O_H)\n",
        "\n",
        "    prompt = f\"{garment_tag.strip()} .\"\n",
        "    padded = resize_and_pad(img)\n",
        "    tens = T.ToTensor()(padded)\n",
        "    nt = nested_tensor_from_tensor_list([tens.to(device)])\n",
        "\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.float32):\n",
        "      out = dino_model(nt, captions=[prompt])\n",
        "\n",
        "    scores = out[\"pred_logits\"][0].sigmoid().cpu().max(1).values\n",
        "    boxes  = out[\"pred_boxes\"][0].cpu()\n",
        "    keep = scores > threshold\n",
        "    if keep.sum()==0: return None\n",
        "    idx = keep.nonzero(as_tuple=True)[0][scores[keep].argmax()]\n",
        "    cx,cy,w,h = boxes[idx].tolist()\n",
        "    x1_1024=(cx-w/2)*1024.0; y1_1024=(cy-h/2)*1024.0\n",
        "    x2_1024=(cx+w/2)*1024.0; y2_1024=(cy+h/2)*1024.0\n",
        "    return box_1024_to_original([x1_1024,y1_1024,x2_1024,y2_1024], O_W, O_H)\n",
        "\n",
        "def bbox_to_mask(bb, img_size, pad_px=10):\n",
        "    W,H = img_size\n",
        "    x1,y1,x2,y2 = bb\n",
        "    x1 = max(0, x1-pad_px); y1 = max(0, y1-pad_px)\n",
        "    x2 = min(W-1, x2+pad_px); y2 = min(H-1, y2+pad_px)\n",
        "    m = np.zeros((H,W), np.uint8)\n",
        "    m[y1:y2, x1:x2] = 255\n",
        "    return m\n",
        "\n",
        "def crop_detail(image_pil, mask_np, bb_xyxy, out_size=1024, pad_px=20):\n",
        "    W,H = image_pil.size\n",
        "    x1,y1,x2,y2 = bb_xyxy\n",
        "    x1=max(0,x1-pad_px); y1=max(0,y1-pad_px)\n",
        "    x2=min(W,x2+pad_px); y2=min(H,y2+pad_px)\n",
        "    side = max(x2-x1, y2-y1)\n",
        "    cx,cy = (x1+x2)//2,(y1+y2)//2\n",
        "    lx=max(0,cx-side//2); rx=lx+side\n",
        "    ty=max(0,cy-side//2); by=ty+side\n",
        "    if rx>W: lx -= (rx-W); rx=W\n",
        "    if by>H: ty -= (by-H); by=H\n",
        "    crop_box=(lx,ty,rx,by)\n",
        "    img_c = image_pil.crop(crop_box).resize((out_size,out_size), Image.Resampling.LANCZOS)\n",
        "    m_c   = mask_np[ty:by, lx:rx]\n",
        "    m_c   = cv2.resize(m_c,(out_size,out_size), interpolation=cv2.INTER_NEAREST)\n",
        "    return img_c, m_c, crop_box\n",
        "\n",
        "def adaptive_brightness(img, strength_dark=0.15, strength_light=0.03, clip=(0,245)):\n",
        "    a = np.asarray(img).astype(np.float32)\n",
        "    lum = 0.2126*a[...,0] + 0.7152*a[...,1] + 0.0722*a[...,2]\n",
        "    mean_lum = float(lum.mean()/255.0)\n",
        "    if mean_lum < 0.5: factor = 1 + (-strength_dark) * (0.5 - mean_lum) * 2\n",
        "    else:               factor = 1 + (strength_light) * (mean_lum - 0.5) * 2\n",
        "    out = np.clip(a*factor, *clip).astype(np.uint8)\n",
        "    return Image.fromarray(out)\n",
        "\n",
        "def paste_crop_back(full_img: Image.Image, edited_crop: Image.Image, crop_box, crop_mask: np.ndarray,\n",
        "                    expand_px=20, feather_px=10) -> Image.Image:\n",
        "    edited_crop = adaptive_brightness(edited_crop, strength_dark=0.15, strength_light=0.03)\n",
        "    x1,y1,x2,y2 = crop_box\n",
        "    tgt_w, tgt_h = x2-x1, y2-y1\n",
        "    edit_rs = edited_crop.resize((tgt_w,tgt_h), Image.Resampling.LANCZOS)\n",
        "    mask_np = cv2.resize(crop_mask, (tgt_w,tgt_h), interpolation=cv2.INTER_NEAREST)\n",
        "    bin_mask = (mask_np>0).astype(np.uint8)\n",
        "    if expand_px>0:\n",
        "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (expand_px*2+1, expand_px*2+1))\n",
        "        bin_mask = cv2.dilate(bin_mask, k, iterations=1)\n",
        "    alpha = cv2.GaussianBlur(bin_mask.astype(np.float32)*255, (0,0), sigmaX=feather_px, sigmaY=feather_px)\n",
        "    alpha[mask_np>0] = 255\n",
        "    alpha = alpha.clip(0,255).astype(np.uint8)\n",
        "    mask_img = Image.fromarray(alpha)\n",
        "\n",
        "    region = full_img.crop((x1,y1,x2,y2))\n",
        "    comp = Image.composite(edit_rs, region, mask_img)\n",
        "    full_img.paste(comp,(x1,y1))\n",
        "    return full_img\n"
      ],
      "metadata": {
        "id": "9TD4abQU5yio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization for detail types from legacy names\n",
        "def _normalize_detail_type(t: str) -> str:\n",
        "    t = (t or \"\").strip().lower()\n",
        "    mapping = {\n",
        "        \"waistband lettering\": \"waist text\",\n",
        "        \"sleeve lettering\": \"sleeve text\",\n",
        "        \"sleeve_text\": \"sleeve text\",\n",
        "        \"waist_text\": \"waist text\",\n",
        "    }\n",
        "    return mapping.get(t, t)\n",
        "\n",
        "def _postprocess_details(payload: dict) -> dict:\n",
        "    details = payload.get(\"details\", [])\n",
        "    fixed = []\n",
        "    for d in details:\n",
        "        typ = _normalize_detail_type(d.get(\"type\"))\n",
        "        col = d.get(\"color\")\n",
        "        if typ in ALLOWED_DETAIL_TYPES:\n",
        "            ent = {\"type\": typ}\n",
        "            if typ != \"sleeve text\" and isinstance(col, str) and col.strip():\n",
        "                ent[\"color\"] = col.strip()\n",
        "            fixed.append(ent)\n",
        "    return {\"details\": fixed}\n",
        "\n",
        "def _try_parse_json(s: str) -> dict | None:\n",
        "    try:\n",
        "        obj = json.loads(s)\n",
        "        if isinstance(obj, dict) and \"details\" in obj:\n",
        "            return obj\n",
        "    except Exception:\n",
        "        pass\n",
        "    # try to extract first {...}\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", s)\n",
        "    if m:\n",
        "        try:\n",
        "            obj = json.loads(m.group(0))\n",
        "            if isinstance(obj, dict) and \"details\" in obj:\n",
        "                return obj\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def read_details_from_metadata(img_path: str) -> dict:\n",
        "    \"\"\"Return {'details':[...]} or {'details':[{'type':'logo'}]} if metadata not found.\"\"\"\n",
        "    try:\n",
        "        im = Image.open(img_path)\n",
        "        # 1) PNG/JPEG info dict\n",
        "        for k, v in (im.info or {}).items():\n",
        "            if isinstance(v, str):\n",
        "                obj = _try_parse_json(v)\n",
        "                if obj:\n",
        "                    return _postprocess_details(obj)\n",
        "        # 2) EXIF: UserComment / XPComment\n",
        "        try:\n",
        "            exif_dict = piexif.load(im.info.get(\"exif\", b\"\") or im.tobytes())\n",
        "        except Exception:\n",
        "            exif_dict = None\n",
        "\n",
        "        def _decode_uc(x):\n",
        "            if isinstance(x, bytes):\n",
        "                for head in [b\"ASCII\\0\\0\\0\", b\"UNICODE\\0\", b\"JIS\\0\\0\\0\"]:\n",
        "                    if x.startswith(head):\n",
        "                        x = x[len(head):]\n",
        "                try:\n",
        "                    return x.decode(\"utf-8\", \"ignore\")\n",
        "                except Exception:\n",
        "                    return x.decode(\"latin-1\", \"ignore\")\n",
        "            if isinstance(x, str):\n",
        "                return x\n",
        "            return None\n",
        "\n",
        "        if exif_dict:\n",
        "            uc = exif_dict.get(\"Exif\", {}).get(piexif.ExifIFD.UserComment, None)\n",
        "            s = _decode_uc(uc)\n",
        "            if s:\n",
        "                obj = _try_parse_json(s)\n",
        "                if obj:\n",
        "                    return _postprocess_details(obj)\n",
        "            xp = exif_dict.get(\"0th\", {}).get(0x9C9C, None)\n",
        "            if xp:\n",
        "                try:\n",
        "                    s = bytes(xp).decode(\"utf-16le\", \"ignore\").rstrip(\"\\x00\")\n",
        "                    obj = _try_parse_json(s)\n",
        "                    if obj:\n",
        "                        return _postprocess_details(obj)\n",
        "                except Exception:\n",
        "                    pass\n",
        "        # 3) XMP sidecar embedded?\n",
        "        if \"XML:com.adobe.xmp\" in (im.info or {}):\n",
        "            obj = _try_parse_json(im.info[\"XML:com.adobe.xmp\"])\n",
        "            if obj:\n",
        "                return _postprocess_details(obj)\n",
        "        # 4) Optional sidecar .json next to image\n",
        "        side = Path(img_path).with_suffix(\".json\")\n",
        "        if side.exists():\n",
        "            try:\n",
        "                obj = json.loads(side.read_text())\n",
        "                if \"details\" in obj:\n",
        "                    return _postprocess_details(obj)\n",
        "            except Exception:\n",
        "                pass\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ metadata read failed for {img_path}: {e}\")\n",
        "\n",
        "    # 👇 Fallback when nothing found\n",
        "    return {\"details\": [{\"type\": \"logo\"}]}\n",
        "\n",
        "\n",
        "# Garment type inference (from path)\n",
        "def extract_garment_type_from_path(image_path: str, allowed_types=ALLOWED_GARMENT_TYPES) -> str:\n",
        "    from pathlib import Path as _P\n",
        "    import re\n",
        "    def singularize(s):\n",
        "        if len(s)>4:\n",
        "            if s.endswith(\"es\"): return s[:-2]\n",
        "            if s.endswith(\"s\"):  return s[:-1]\n",
        "        return s\n",
        "    def normalize_key(s): return singularize(s.replace(\"-\",\"\").replace(\"_\",\"\").lower().strip())\n",
        "    norm_map = {}\n",
        "    for t in allowed_types:\n",
        "        base = normalize_key(t)\n",
        "        norm_map[base]=t\n",
        "        if not base.endswith(\"s\"): norm_map[base+\"s\"]=t\n",
        "        else:\n",
        "            if base.endswith(\"es\"): norm_map[base[:-2]]=t\n",
        "            else: norm_map[base[:-1]]=t\n",
        "    p = _P(image_path)\n",
        "    file_compact = re.sub(r\"[^a-z]+\",\"\", p.stem.lower())\n",
        "    for k,v in norm_map.items():\n",
        "        if k and k in file_compact: return v\n",
        "    # parent folders\n",
        "    for part in reversed(p.parts[:-1]):\n",
        "        if part.startswith(\".\"): continue\n",
        "        toks = [singularize(t) for t in re.split(r\"[^a-z]+\", part.lower()) if t]\n",
        "        for tok in toks:\n",
        "            if tok in norm_map: return norm_map[tok]\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "DL1y4tUs51S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Robust SKU+angle parsing (handles: \"SS-28623_fr (1).png\", \"Copy of SS-12345_bc_lft_v2.png\", \"SS-55555_fr_cl.png\") ===\n",
        "import os, re\n",
        "from pathlib import Path\n",
        "from functools import lru_cache\n",
        "\n",
        "# Reuse your global config: BASE_NAMES, ACCEPTABLE_SUFFIXES, VALID_EXTS, WORKING_DIR\n",
        "\n",
        "_SKU_RE = re.compile(r\"(SS-\\d{3,7})\", re.IGNORECASE)\n",
        "_COPY_RE = re.compile(r\"^(?:copy of\\s+)+\", re.IGNORECASE)\n",
        "\n",
        "def _strip_copy_prefix(s: str) -> str:\n",
        "    return _COPY_RE.sub(\"\", s).strip()\n",
        "\n",
        "def _angle_tokens_desc() -> list[str]:\n",
        "    # Longest-first to prefer 'fr_rght' over 'fr'\n",
        "    return sorted(list(set(BASE_NAMES)), key=len, reverse=True)\n",
        "\n",
        "def _token_delim_search(token: str, text: str) -> re.Match | None:\n",
        "    \"\"\"\n",
        "    Find token delimited by non-alphanumerics (underscore is allowed as a delimiter).\n",
        "    We treat [A-Za-z0-9] as 'wordy'; underscores/spaces/()/- etc. are delimiters.\n",
        "    \"\"\"\n",
        "    # Escape underscores in token for regex\n",
        "    tok = re.escape(token)\n",
        "    pattern = rf\"(?<![A-Za-z0-9]){tok}(?![A-Za-z0-9])\"\n",
        "    return re.search(pattern, text, flags=re.IGNORECASE)\n",
        "\n",
        "def extract_sku_and_angle_from_path(path_like: str) -> tuple[str | None, str | None]:\n",
        "    \"\"\"\n",
        "    Returns (SKU like 'SS-12345', angle_base like 'fr_lft'/'fr').\n",
        "    Strategy:\n",
        "      1) Extract SKU from filename; if not found, try parent dirs.\n",
        "      2) After SKU in the filename, scan the suffix for the LONGEST valid angle token.\n",
        "      3) Fallback to whole filename scan, then parent dirs.\n",
        "    \"\"\"\n",
        "    p = Path(path_like)\n",
        "    name = _strip_copy_prefix(p.name)\n",
        "\n",
        "    # --- 1) SKU from filename, else parents\n",
        "    m = _SKU_RE.search(name)\n",
        "    sku = m.group(1).upper() if m else None\n",
        "    if sku is None:\n",
        "        for part in reversed(p.parts):\n",
        "            mm = _SKU_RE.search(part)\n",
        "            if mm:\n",
        "                sku = mm.group(1).upper()\n",
        "                break\n",
        "\n",
        "    # --- 2) Angle after SKU region\n",
        "    angle = None\n",
        "    tokens = _angle_tokens_desc()\n",
        "    if sku:\n",
        "        mname = _SKU_RE.search(name)\n",
        "        if mname:\n",
        "            suffix = name[mname.end():]  # everything after the SKU\n",
        "            for tok in tokens:\n",
        "                if _token_delim_search(tok, suffix):\n",
        "                    angle = tok\n",
        "                    break\n",
        "\n",
        "    # --- 3) Fallback: whole filename, then parents\n",
        "    if angle is None:\n",
        "        for tok in tokens:\n",
        "            if _token_delim_search(tok, name):\n",
        "                angle = tok\n",
        "                break\n",
        "    if angle is None:\n",
        "        # Look in parent folders\n",
        "        for part in reversed(p.parts[:-1]):\n",
        "            part_clean = _strip_copy_prefix(part)\n",
        "            for tok in tokens:\n",
        "                if _token_delim_search(tok, part_clean):\n",
        "                    angle = tok\n",
        "                    break\n",
        "            if angle:\n",
        "                break\n",
        "\n",
        "    return sku, angle\n",
        "\n",
        "# ===================== Source finding via SKU folder anywhere =====================\n",
        "@lru_cache(maxsize=1024)\n",
        "def _find_sku_folder_anywhere(working_root: str, sku_name: str) -> Path | None:\n",
        "    wr = Path(working_root)\n",
        "    if not wr.exists():\n",
        "        return None\n",
        "    sku_low = sku_name.lower()\n",
        "    best: tuple[int, Path] | None = None\n",
        "    for dirpath, dirnames, _ in os.walk(wr):\n",
        "        leaf = os.path.basename(dirpath)\n",
        "        if leaf.lower() == sku_low:\n",
        "            depth = len(Path(dirpath).parts)\n",
        "            cand = Path(dirpath)\n",
        "            if best is None or depth < best[0]:\n",
        "                best = (depth, cand)\n",
        "    return best[1] if best else None\n",
        "\n",
        "\n",
        "def _list_valid_images(folder: Path) -> list[Path]:\n",
        "    \"\"\"\n",
        "    Return candidate source images in `folder`, excluding:\n",
        "      - any with 'generated', 'inpainted', '_nd', '_no_details', '_processed_by_detailer_'\n",
        "      - any with '_sec' anywhere in the filename (case-insensitive)\n",
        "    \"\"\"\n",
        "    deny_substrings = (\n",
        "        \"generated\",\n",
        "        \"inpainted\",\n",
        "        \"_nd\",\n",
        "        \"_no_details\",\n",
        "        \"_processed_by_detailer_\",\n",
        "        \"_sec\",   # ← NEW: ignore secondary variants\n",
        "    )\n",
        "    out = []\n",
        "    for p in folder.iterdir():\n",
        "        if not (p.is_file() and p.suffix in VALID_EXTS):\n",
        "            continue\n",
        "        name_low = p.name.lower()\n",
        "        if any(s in name_low for s in deny_substrings):\n",
        "            continue\n",
        "        out.append(p)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _rank_exact_angle(norm_stem: str, base: str, acceptable_suffixes: set[str]) -> int | None:\n",
        "    if norm_stem == f\"{base}_cut\": return 1\n",
        "    if norm_stem.startswith(base + \"_\") and norm_stem.endswith(\"_cut\"): return 2\n",
        "    if norm_stem == base: return 3\n",
        "    if norm_stem.startswith(base + \"_\"):\n",
        "        suf = norm_stem[len(base)+1:]\n",
        "        if suf in acceptable_suffixes: return 4\n",
        "    return None\n",
        "\n",
        "def _is_fr_family(base: str | None) -> bool:\n",
        "    if not base: return False\n",
        "    return base in (\"fr\",\"fr_cl\",\"fr_lft\",\"fr_rght\") or base.startswith(\"fr\")\n",
        "\n",
        "def _pick_source_in_dir(angle_base: str, directory: Path) -> Path | None:\n",
        "    entries = _list_valid_images(directory)\n",
        "    if not entries: return None\n",
        "    acceptable = set(ACCEPTABLE_SUFFIXES)\n",
        "\n",
        "    def _norm(p: Path) -> str:\n",
        "        return _strip_copy_prefix(p.stem).lower()\n",
        "\n",
        "    ranked: list[tuple[int,int,Path]] = []\n",
        "    if _is_fr_family(angle_base):\n",
        "        for p in entries:\n",
        "            n = _norm(p)\n",
        "            if n == \"fr_cut\": ranked.append((1,len(p.name),p)); continue\n",
        "            if n.startswith(\"fr_\") and n.endswith(\"_cut\"): ranked.append((2,len(p.name),p)); continue\n",
        "            if n == \"fr\": ranked.append((3,len(p.name),p)); continue\n",
        "            if n.startswith(\"fr_\"):\n",
        "                suf = n[len(\"fr_\"):]\n",
        "                if suf in acceptable: ranked.append((4,len(p.name),p)); continue\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        ranked=[]\n",
        "        for p in entries:\n",
        "            n=_norm(p)\n",
        "            r=_rank_exact_angle(n, angle_base, acceptable)\n",
        "            if r is not None: ranked.append((r,len(p.name),p))\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        return None\n",
        "    else:\n",
        "        for p in entries:\n",
        "            n=_norm(p)\n",
        "            r=_rank_exact_angle(n, angle_base, acceptable)\n",
        "            if r is not None: ranked.append((r,len(p.name),p))\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        return None\n",
        "\n",
        "def find_source_via_sku(gen_path: Path | str, working_root: Path | str) -> Path | None:\n",
        "    gen_path = Path(gen_path)\n",
        "    sku, angle_base = extract_sku_and_angle_from_path(str(gen_path))\n",
        "\n",
        "    if not sku:\n",
        "        print(f\"❌ Could not extract SKU from: {gen_path.name}\")\n",
        "        return None\n",
        "\n",
        "    if not angle_base:\n",
        "        # No noisy warning anymore; we’ll gracefully default.\n",
        "        angle_base = \"fr\"\n",
        "\n",
        "    sku_dir = _find_sku_folder_anywhere(str(working_root), sku)\n",
        "    if not sku_dir:\n",
        "        print(f\"❌ SKU folder '{sku}' not found anywhere under {working_root}\")\n",
        "        return None\n",
        "\n",
        "    ricardo = sku_dir / \"Ricardo\"\n",
        "    for d in (ricardo, sku_dir):\n",
        "        if d.exists() and d.is_dir():\n",
        "            hit = _pick_source_in_dir(angle_base, d)\n",
        "            if hit: return hit\n",
        "\n",
        "    print(f\"⚠️ No suitable source found in '{sku_dir}' (Ricardo or root) for angle '{angle_base}'\")\n",
        "    return None\n",
        "\n",
        "def build_inpaint_suffix(details: list[dict]) -> str:\n",
        "    def slug(s: str) -> str:\n",
        "        s = s.lower().replace(\" \", \"-\")\n",
        "        return re.sub(r\"[^a-z0-9\\-]+\", \"\", s).strip(\"-\")\n",
        "    parts=[]\n",
        "    for d in details:\n",
        "        t = d[\"type\"]\n",
        "        c = d.get(\"color\",\"\")\n",
        "        if t != \"sleeve text\" and c:\n",
        "            parts.append(slug(f\"{c}-{t}\"))\n",
        "        else:\n",
        "            parts.append(slug(t))\n",
        "    return \"_\".join(parts) if parts else \"none\"\n",
        "\n",
        "# --- Build the required base \"SS-12345-bc_lft\" from the queued filename ---\n",
        "def build_out_base_from_gen(gen_path: str) -> tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Returns (sku_upper, angle_lower, out_base).\n",
        "    out_base is 'SS-12345-bc_lft' (SKU + '-' + angle).\n",
        "    \"\"\"\n",
        "    sku, angle = extract_sku_and_angle_from_path(gen_path)\n",
        "    if not sku:\n",
        "        raise ValueError(f\"Cannot derive SKU from: {gen_path}\")\n",
        "    if not angle:\n",
        "        angle = \"fr\"\n",
        "    sku_up = sku.upper()\n",
        "    angle_lo = angle.lower()\n",
        "    return sku_up, angle_lo, f\"{sku_up}-{angle_lo}\"\n",
        "\n",
        "def target_already_has_inpainted(target_dir: str, sku: str, angle: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check TARGET_DIR for any file starting with 'SS-12345-bc_lft_inpainted'.\n",
        "    Case-insensitive; extension-agnostic.\n",
        "    \"\"\"\n",
        "    td = Path(target_dir)\n",
        "    if not td.exists():\n",
        "        return False\n",
        "    prefix = f\"{sku.upper()}-{angle.lower()}_inpainted\"\n",
        "    prefix_low = prefix.lower()\n",
        "    for p in td.iterdir():\n",
        "        if p.is_file() and p.suffix in VALID_EXTS:\n",
        "            if p.stem.lower().startswith(prefix_low):\n",
        "                return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "pbCd-SBI530x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _inpaint_one_detail(gen_full: Image.Image,\n",
        "                        src_full: Image.Image,\n",
        "                        detail_prompt: str,\n",
        "                        *,\n",
        "                        garment_tag: str,\n",
        "                        restrict_mask_full: np.ndarray | None,\n",
        "                        generous_pad_px: int,\n",
        "                        tiny_pad_px: int,\n",
        "                        seed: int,\n",
        "                        visualize: bool) -> Image.Image:\n",
        "\n",
        "    gen_view_for_dino = apply_binary_mask(gen_full, restrict_mask_full) if restrict_mask_full is not None else gen_full\n",
        "\n",
        "    gar_src_bb = detect_garment_box(src_full, garment_tag)\n",
        "    gar_gen_bb = detect_garment_box(gen_view_for_dino, garment_tag, restrict_mask=restrict_mask_full)\n",
        "    if gar_src_bb is None or gar_gen_bb is None:\n",
        "        print(\"❌ garment detection failed\"); return gen_full\n",
        "\n",
        "    # square garment crops\n",
        "    def crop_to_square(image: Image.Image, bbox, pad_px=0):\n",
        "        x1,y1,x2,y2 = bbox\n",
        "        w,h = x2-x1, y2-y1\n",
        "        side = max(w,h) + 2*pad_px\n",
        "        cx,cy = (x1+x2)//2, (y1+y2)//2\n",
        "        lx=max(0,cx-side//2); ty=max(0,cy-side//2)\n",
        "        rx=lx+side; by=ty+side\n",
        "        W,H=image.size\n",
        "        if rx>W: lx -= (rx-W); rx=W\n",
        "        if by>H: ty -= (by-H); by=H\n",
        "        crop = image.crop((max(lx,0),max(ty,0),min(rx,W),min(by,H)))\n",
        "        out  = Image.new(\"RGB\",(side,side),(255,255,255))\n",
        "        dx=max(0,-lx); dy=max(0,-ty)\n",
        "        out.paste(crop,(dx,dy))\n",
        "        return out, (lx,ty,rx,by)\n",
        "\n",
        "    src_sq, sq_src = crop_to_square(src_full, gar_src_bb)\n",
        "    gen_sq, sq_gen = crop_to_square(gen_view_for_dino, gar_gen_bb)\n",
        "\n",
        "    restrict_sq = None\n",
        "    if restrict_mask_full is not None:\n",
        "        x1,y1,x2,y2 = sq_gen\n",
        "        restrict_sq = restrict_mask_full[y1:y2, x1:x2]\n",
        "        restrict_sq = cv2.resize(restrict_sq, gen_sq.size, interpolation=cv2.INTER_NEAREST)\n",
        "    '''\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"source garment crop\", src_sq),\n",
        "            (\"generated garment crop (masked view)\", gen_sq)\n",
        "        ], cols=2, figsize=(12,8))\n",
        "    '''\n",
        "\n",
        "    src_garm_sq, sq_coords_src = crop_to_square(src_full, gar_src_bb, pad_px=0)\n",
        "    gen_garm_sq, sq_coords_gen = crop_to_square(gen_view_for_dino, gar_gen_bb, pad_px=0)\n",
        "\n",
        "\n",
        "    det_src_bb, _ = detect_detail(src_sq, detail_prompt)\n",
        "    prior = make_spatial_prior_from_box(det_src_bb, src_garm_sq.size)\n",
        "\n",
        "    det_gen_bb, _ = detect_detail_topk7(\n",
        "        gen_garm_sq,\n",
        "        detail_prompt,\n",
        "        source_prior=prior,\n",
        "        restrict_mask=(restrict_mask_full, \"FULL\"),  # pass FULL mask\n",
        "        crop_box_on_full=sq_coords_gen,              # the (x1,y1,x2,y2) used to make gen_garm_sq\n",
        "        viz=True, debug=True\n",
        "    )\n",
        "    if det_src_bb is None or det_gen_bb is None:\n",
        "        print(f\"❌ detail not found: {detail_prompt}\"); return gen_full\n",
        "\n",
        "    # back to full coords\n",
        "    lx_s, ty_s, _, _ = sq_src\n",
        "    lx_g, ty_g, _, _ = sq_gen\n",
        "    src_det_bb = [det_src_bb[0]+lx_s, det_src_bb[1]+ty_s, det_src_bb[2]+lx_s, det_src_bb[3]+ty_s]\n",
        "    gen_det_bb = [det_gen_bb[0]+lx_g, det_gen_bb[1]+ty_g, det_gen_bb[2]+lx_g, det_gen_bb[3]+ty_g]\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"detail on source\", _draw_bbox(src_full, src_det_bb)),\n",
        "            (\"detail on generated (masked)\", _draw_bbox(gen_view_for_dino, gen_det_bb))\n",
        "        ], cols=2, figsize=(12,8))\n",
        "\n",
        "    # masks\n",
        "    m_src = bbox_to_mask(src_det_bb, src_full.size, INPAINT_TINY_PAD)\n",
        "    m_gen = get_sam_contour_mask(gen_full, gen_det_bb)\n",
        "\n",
        "    # crops for IA\n",
        "    src_crop, src_mask, _   = crop_detail(src_full, m_src, src_det_bb, 1024, INPAINT_TINY_PAD)\n",
        "    gen_crop, gen_mask, box = crop_detail(gen_full, m_gen, gen_det_bb, 1024, INPAINT_GENEROUS_PAD)\n",
        "\n",
        "    # diptych\n",
        "    src_arr = np.array(src_crop)\n",
        "    src_msk3 = np.stack([src_mask]*3, -1)\n",
        "    masked_src = src_arr*(src_msk3//255) + 255*(1-src_msk3//255)\n",
        "\n",
        "    gen_arr = np.array(gen_crop)\n",
        "    gen_msk3 = np.stack([gen_mask]*3, -1)\n",
        "    zeros = np.zeros_like(masked_src)\n",
        "\n",
        "    diptych = np.concatenate([masked_src, gen_arr], axis=1).astype(np.uint8)\n",
        "    dip_mask = np.concatenate([zeros, gen_msk3], axis=1).astype(np.uint8)\n",
        "    dip_mask[dip_mask>0]=255\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"diptych\", Image.fromarray(diptych)),\n",
        "            (\"diptych mask\", Image.fromarray(dip_mask).convert(\"RGB\"))\n",
        "        ], cols=2, figsize=(12,8))\n",
        "\n",
        "    prior = redux(Image.fromarray(masked_src))\n",
        "    gen_obj = torch.Generator(device).manual_seed(seed)\n",
        "    ia_out = pipe(\n",
        "        image=Image.fromarray(diptych),\n",
        "        mask_image=Image.fromarray(dip_mask),\n",
        "        height=1024,\n",
        "        width=2048,\n",
        "        max_sequence_length=512,\n",
        "        num_inference_steps=60,\n",
        "        guidance_scale=30,\n",
        "        generator=gen_obj,\n",
        "        **prior\n",
        "    ).images[0]\n",
        "\n",
        "    right_crop = ia_out.crop((1024,0,2048,1024))\n",
        "    gen_full = paste_crop_back(gen_full, right_crop, box, gen_mask)\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"IA result (2048×1024)\", ia_out),\n",
        "            (\"after this detail\", gen_full)\n",
        "        ], cols=2, figsize=(14,8))\n",
        "\n",
        "    return gen_full\n",
        "\n",
        "def inpaint_with_details_list(generated_path: str,\n",
        "                              source_path: str,\n",
        "                              details: list[dict],\n",
        "                              garment_type: str | None,\n",
        "                              visualize: bool = True) -> Image.Image:\n",
        "\n",
        "    gen_full = open_upright(generated_path)\n",
        "    src_full = open_source_with_black_bg(source_path)\n",
        "\n",
        "    restrict_mask_full = load_binary_mask_for_generated(generated_path, source_path, gen_full)\n",
        "\n",
        "    if restrict_mask_full is None:\n",
        "        print(\"⚠️  No garment mask found — proceeding without restriction.\")\n",
        "    else:\n",
        "        print(\"✅ Garment mask loaded & aligned for\", os.path.basename(generated_path))\n",
        "\n",
        "    if garment_type is None or not garment_type.strip():\n",
        "        garment_type = extract_garment_type_from_path(source_path)\n",
        "    if not garment_type:\n",
        "        garment_type = \"t-shirt\"  # conservative default prompt\n",
        "\n",
        "    # twinset (optional, keep simple)\n",
        "    garment_tags = [garment_type.lower()]\n",
        "    if garment_type.lower() in TWINSET_TYPES:\n",
        "        garment_tags = [TOP_GARMENTS[0], BOTTOM_GARMENTS[0]]\n",
        "\n",
        "    out_img = gen_full.copy()\n",
        "    for gtag in garment_tags:\n",
        "        for d in details:\n",
        "            d_type = d[\"type\"]\n",
        "            prompt_str = f\"{d_type}\".strip()\n",
        "            print(f\"🔄 Inpainting detail: {prompt_str}  (garment={gtag})\")\n",
        "            out_img = _inpaint_one_detail(\n",
        "                out_img, src_full, prompt_str,\n",
        "                garment_tag=gtag,\n",
        "                restrict_mask_full=restrict_mask_full,\n",
        "                generous_pad_px=INPAINT_GENEROUS_PAD,\n",
        "                tiny_pad_px=INPAINT_TINY_PAD,\n",
        "                seed=INPAINT_SEED,\n",
        "                visualize=visualize\n",
        "            )\n",
        "\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return out_img\n"
      ],
      "metadata": {
        "id": "UkjJwDwh558v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "def process_detailer_queue():\n",
        "    queue_root = Path(DETAILER_QUEUE_FOLDER)\n",
        "    if not queue_root.exists():\n",
        "        print(f\"❌ Queue folder does not exist: {queue_root}\")\n",
        "        return\n",
        "\n",
        "    gen_files = [p for p in queue_root.rglob(\"*\") if p.is_file() and p.suffix in VALID_EXTS]\n",
        "    if not gen_files:\n",
        "        print(f\"ℹ️ No images found in {queue_root}\")\n",
        "        return\n",
        "\n",
        "    processed = skipped = failed = 0\n",
        "\n",
        "    for gen_path in sorted(gen_files, key=lambda p: (str(p.parent), p.name)):\n",
        "        try:\n",
        "            print(\"\\n\" + \"_\"*80)\n",
        "            print(f\"🎯 Queue item: {gen_path}\")\n",
        "\n",
        "            # 1) Read details from metadata\n",
        "            meta = read_details_from_metadata(str(gen_path))\n",
        "            if not meta or not meta.get(\"details\"):\n",
        "                print(\"⏭️  No details found in metadata — skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            details = [d for d in meta[\"details\"] if d[\"type\"] in ALLOWED_DETAIL_TYPES]\n",
        "            if not details:\n",
        "                print(\"⏭️  Details list empty after normalization — skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # 2) Find source garment near this item\n",
        "            src_p = find_source_via_sku(gen_path, Path(WORKING_DIR))\n",
        "            if not src_p:\n",
        "                print(\"⏭️  Source garment not found — skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            source_base = Path(src_p).stem  # e.g. SS-12345_fr\n",
        "            sku_up, angle_lo, out_base = build_out_base_from_gen(str(gen_path))\n",
        "            out_ext = \".png\"\n",
        "\n",
        "            # 3) Skip guard: any prior inpainted for this SKU+angle?\n",
        "            if SKIP_IF_ALREADY_INPAINTED and target_already_has_inpainted(TARGET_DIR, sku_up, angle_lo):\n",
        "              print(f\"⏭️  Already have inpainted for {out_base} in TARGET_DIR — skipping\")\n",
        "              skipped += 1\n",
        "              continue\n",
        "\n",
        "            # 4) Inpaint\n",
        "            garment_type = extract_garment_type_from_path(str(src_p))\n",
        "            out_img = inpaint_with_details_list(\n",
        "                str(gen_path),\n",
        "                str(src_p),\n",
        "                details=details,\n",
        "                garment_type=garment_type,\n",
        "                visualize=VISUALIZE\n",
        "            )\n",
        "\n",
        "            # 5) Build output names (keep source naming; append detail suffixes)\n",
        "            suffix   = build_inpaint_suffix(details)   # unchanged\n",
        "            dst_src  = Path(TARGET_DIR) / f\"{out_base}{out_ext}\"                         # e.g., SS-12345-bc_lft.jpg\n",
        "            dst_ia   = Path(TARGET_DIR) / f\"{out_base}_inpainted_{suffix}{out_ext}\"      # e.g., SS-12345-bc_lft_inpainted_red_logo.jpg\n",
        "\n",
        "            # 6) Save outputs: copy source + save inpainted\n",
        "            #if not dst_src.exists():\n",
        "            #    shutil.copy2(str(src_p), str(dst_src))\n",
        "            #    print(f\"📎 Saved source → {dst_src.name}\")\n",
        "            #else:\n",
        "            #    print(f\"📎 Source already present in TARGET_DIR → {dst_src.name}\")\n",
        "\n",
        "            # --- Save inpainted result ---\n",
        "            out_img.save(str(dst_ia))\n",
        "            print(f\"✅ Saved inpainted → {dst_ia.name}\")\n",
        "            processed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed on {gen_path.name}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "    print(\"\\n==== SUMMARY ====\")\n",
        "    print(f\"Processed: {processed}  |  Skipped: {skipped}  |  Failed: {failed}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ekO6QtZR59KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RUN"
      ],
      "metadata": {
        "id": "XPGXKHLhO_hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "process_detailer_queue()"
      ],
      "metadata": {
        "id": "pxMzQe-U5_Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UNASSIGN"
      ],
      "metadata": {
        "id": "qpoDyMhnPO83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "GUsJyqO4PN0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}