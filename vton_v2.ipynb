{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VTON v2 \u2014 Nanobanana Pro (Google Cloud API)\n",
        "\n",
        "This notebook rebuilds the v1 workflow using Google's nanobanana pro image model. It keeps the SKU + angle list flow, Google Drive / gspread ops sync, source search, and the crop/pasteback logic with square 1:1 crops. Masks, LoRA, GPT scoring, and HYPIR are removed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Install the Google Cloud generative AI client and authenticate for Drive/Sheets. The GEMINI_API_KEY should be stored in Colab `userdata`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Setup: Google auth + Drive + deps ---\n",
        "!pip install -q -U \"google-genai>=1.40.0\" gspread google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
        "\n",
        "import os, sys, textwrap, json, pathlib, typing\n",
        "from google.colab import auth, drive, userdata\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY or ''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select angles\n",
        "Toggle which base angles should be produced for each SKU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fr_lft = True #@param {type:\"boolean\"}\n",
        "fr_rght = True #@param {type:\"boolean\"}\n",
        "fr_cl = True #@param {type:\"boolean\"}\n",
        "bc_lft = True #@param {type:\"boolean\"}\n",
        "bc_rght = True #@param {type:\"boolean\"}\n",
        "lft = True #@param {type:\"boolean\"}\n",
        "rght = True #@param {type:\"boolean\"}\n",
        "bc_ = True #@param {type:\"boolean\"}\n",
        "fr_ = True #@param {type:\"boolean\"}\n",
        "fr_cl_btm = False #@param {type:\"boolean\"}\n",
        "fr_cl_tp = False #@param {type:\"boolean\"}\n",
        "\n",
        "names = [\"fr_lft\",\"fr_rght\",\"fr_cl\",\"bc_lft\",\"bc_rght\",\"lft\",\"rght\",\"bc_\",\"fr_\",\"fr_cl_btm\",\"fr_cl_tp\"]\n",
        "ALLOWED_BASES = [n for n in names if locals()[n]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config\n",
        "Only SKU list mode is kept. Adjust roots for garments, base/model photos, and output destinations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Unified CONFIG ---\n",
        "RUN_MODE = \"sku_list\"\n",
        "SKU_CSV = \"28748, 28920\"  #@param {type:\"string\"}\n",
        "\n",
        "GARMENTS_ROOT = \"/content/drive/MyDrive/Dazzl/Garments\"  #@param {type:\"string\"}\n",
        "BASE_ROOT     = \"/content/drive/MyDrive/Dazzl/BasePhotos\"  #@param {type:\"string\"}\n",
        "OUTPUT_DIR    = \"/content/drive/MyDrive/Dazzl/vton_v2_outputs\"  #@param {type:\"string\"}\n",
        "\n",
        "# Google Sheets / Drive\n",
        "GOOGLE_SHEET_ID = \"\"  #@param {type:\"string\"}\n",
        "OPERATIONS_SHEET_NAME = \"operations\"\n",
        "DRIVE_UPLOAD_PARENT_ID = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# File filters + cropping\n",
        "VALID_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\", \".webp\"]\n",
        "IGNORE_DIRS = {\"__pycache__\", \".ipynb_checkpoints\", \"thumbnails\"}\n",
        "CROP_MARGIN = 200   # pixels away from garment when cropping\n",
        "TARGET_ASPECT = \"1:1\"\n",
        "IMAGE_SIZE = \"4K\"\n",
        "\n",
        "# Prompt used for nanobanana pro try-on\n",
        "TRYON_PROMPT = textwrap.dedent(\"\"\"\\\n",
        "You are an expert virtual try-on AI. You will be given a 'model image' and a 'garment image'. Your task is to create a new photorealistic image where the person from the 'model image' is wearing the clothing from the 'garment image'.\n",
        "\n",
        "Crucial Rules:\n",
        "1.  Complete Garment Replacement: You MUST completely REMOVE and REPLACE the clothing item worn by the person in the 'model image' with the new garment. No part of the original clothing (e.g., collars, sleeves, patterns) should be visible in the final image.\n",
        "2.  Preserve the Model: The person's face, hair, body shape, and pose from the 'model image' MUST remain unchanged.\n",
        "3.  Preserve the Background: The entire background from the 'model image' MUST be preserved perfectly.\n",
        "4.  Apply the Garment: Realistically fit the new garment onto the person. It should adapt to their pose with natural folds, shadows, and lighting consistent with the original scene.\n",
        "5.  Output: Return ONLY the final, edited image. Do not include any text.\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilities\n",
        "SKU normalization, angle helpers, source searching, and crop helpers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, re, fnmatch, math, uuid, pytz, random, gc, tempfile, traceback\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Normalize SKU list to SS-##### format\n",
        "def normalize_sku_list(sku_csv: str) -> str:\n",
        "    skus = []\n",
        "    for raw in sku_csv.split(','):\n",
        "        sku = raw.strip().upper()\n",
        "        match = re.search(r'(\\d+)', sku)\n",
        "        if match:\n",
        "            skus.append(f\"SS-{match.group(1)}\")\n",
        "    return \", \".join(skus)\n",
        "\n",
        "SKU_CSV = normalize_sku_list(SKU_CSV)\n",
        "\n",
        "# Parsing helpers\n",
        "def _parse_csv_list(s):\n",
        "    return [x.strip().casefold() for x in (s or \"\").split(',') if x.strip()]\n",
        "\n",
        "def _norm_sku(s):\n",
        "    if s is None: return \"\"\n",
        "    s = str(s).replace(\"\u00a0\",\" \")\n",
        "    s = \" \".join(s.split())\n",
        "    return s.casefold()\n",
        "\n",
        "def _norm_angle(s):\n",
        "    s = (s or \"\").strip().lower()\n",
        "    return s.strip(\"_ \").replace(\"-\", \"_\")\n",
        "\n",
        "ANGLE_ALIASES = {\n",
        "    \"fr_cl\": [\"fr\", \"fr_\"],\n",
        "}\n",
        "\n",
        "def expand_allowed_angles(angles):\n",
        "    expanded = set()\n",
        "    for a in (angles or []):\n",
        "        a_norm = _norm_angle(a)\n",
        "        expanded.add(a_norm)\n",
        "        for alt in ANGLE_ALIASES.get(a_norm, []):\n",
        "            expanded.add(_norm_angle(alt))\n",
        "    return expanded\n",
        "\n",
        "IGNORE_DIRS = {d.lower() for d in IGNORE_DIRS}\n",
        "\n",
        "def _is_image_file(name: str) -> bool:\n",
        "    return name.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS))\n",
        "\n",
        "def _is_sku_folder(path: str) -> bool:\n",
        "    base = os.path.basename(os.path.normpath(path)).lower()\n",
        "    if base in IGNORE_DIRS:\n",
        "        return False\n",
        "    try:\n",
        "        for f in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, f)) and _is_image_file(f):\n",
        "                return True\n",
        "    except Exception:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "# Walkers\n",
        "def iter_sku_folders(root: str):\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        dirnames[:] = [d for d in dirnames if d.lower() not in IGNORE_DIRS]\n",
        "        if any(_is_image_file(f) for f in filenames):\n",
        "            yield dirpath\n",
        "\n",
        "def resolve_targets(idents_csv: str, garments_root: str):\n",
        "    idents = [s.strip() for s in idents_csv.replace(';', ',').split(',') if s.strip()]\n",
        "    if not idents: return [], []\n",
        "\n",
        "    all_sku_dirs = list(iter_sku_folders(garments_root))\n",
        "    rel_map = {p: os.path.relpath(p, garments_root) for p in all_sku_dirs}\n",
        "    base_map = {p: os.path.basename(p) for p in all_sku_dirs}\n",
        "\n",
        "    # index every folder by basename so we can match SKU names even when\n",
        "    # the immediate SKU folder does not contain images (only nested angle folders).\n",
        "    name_index = {}\n",
        "    for dirpath, dirnames, filenames in os.walk(garments_root):\n",
        "        dirnames[:] = [d for d in dirnames if d.lower() not in IGNORE_DIRS]\n",
        "        name_index.setdefault(os.path.basename(dirpath).lower(), []).append(dirpath)\n",
        "\n",
        "    seen, out, unmatched = set(), [], []\n",
        "\n",
        "    def add_path(p):\n",
        "        ap = os.path.abspath(p)\n",
        "        if os.path.isdir(ap):\n",
        "            if _is_sku_folder(ap):\n",
        "                if ap not in seen:\n",
        "                    seen.add(ap); out.append(ap)\n",
        "            else:\n",
        "                for leaf in iter_sku_folders(ap):\n",
        "                    a = os.path.abspath(leaf)\n",
        "                    if a not in seen:\n",
        "                        seen.add(a); out.append(a)\n",
        "        else:\n",
        "            unmatched.append(p)\n",
        "\n",
        "    for ident in idents:\n",
        "        ident_lower = ident.lower()\n",
        "        if os.path.isabs(ident):\n",
        "            add_path(ident)\n",
        "            continue\n",
        "\n",
        "        matched_any = False\n",
        "        glob_paths = fnmatch.filter(rel_map.values(), ident) + fnmatch.filter(base_map.values(), ident)\n",
        "        for rel in glob_paths:\n",
        "            add_path(os.path.join(garments_root, rel)); matched_any = True\n",
        "\n",
        "        for dirpath in name_index.get(ident_lower, []):\n",
        "            add_path(dirpath); matched_any = True\n",
        "\n",
        "        if not matched_any:\n",
        "            unmatched.append(ident)\n",
        "\n",
        "    return out, unmatched\n",
        "\n",
        "# Image helpers\n",
        "WHITE_RGB = (255,255,255)\n",
        "\n",
        "def flatten_alpha_to_white(img: Image.Image) -> Image.Image:\n",
        "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
        "        bg = Image.new(\"RGB\", img.size, WHITE_RGB)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "        return bg\n",
        "    return img.convert(\"RGB\")\n",
        "\n",
        "\n",
        "def _tight_bbox_nonwhite_or_opaque(img: Image.Image):\n",
        "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
        "        arr = np.asarray(img.convert(\"RGBA\"))\n",
        "        alpha = arr[...,3]\n",
        "        fg = alpha > 0\n",
        "    else:\n",
        "        arr = np.asarray(img.convert(\"RGB\"))\n",
        "        fg = ~((arr[...,0]==255)&(arr[...,1]==255)&(arr[...,2]==255))\n",
        "    if not np.any(fg): return None\n",
        "    ys, xs = np.where(fg)\n",
        "    x0, x1 = int(xs.min()), int(xs.max())+1\n",
        "    y0, y1 = int(ys.min()), int(ys.max())+1\n",
        "    return (x0,y0,x1,y1)\n",
        "\n",
        "\n",
        "def crop_square_with_margin(img: Image.Image, margin: int = CROP_MARGIN):\n",
        "    base = flatten_alpha_to_white(img)\n",
        "    bbox = _tight_bbox_nonwhite_or_opaque(img)\n",
        "    if bbox is None:\n",
        "        w,h = base.size\n",
        "        side = min(w,h)\n",
        "        box = ((w-side)//2, (h-side)//2, (w+side)//2, (h+side)//2)\n",
        "        return base.crop(box), box\n",
        "    x0,y0,x1,y1 = bbox\n",
        "    x0 = max(0, x0 - margin); y0 = max(0, y0 - margin)\n",
        "    x1 = min(base.width, x1 + margin); y1 = min(base.height, y1 + margin)\n",
        "    bw, bh = x1 - x0, y1 - y0\n",
        "    side = max(bw, bh)\n",
        "    cx, cy = x0 + bw//2, y0 + bh//2\n",
        "    half = side//2\n",
        "    x0 = max(0, cx - half); y0 = max(0, cy - half)\n",
        "    x1 = min(base.width, x0 + side); y1 = min(base.height, y0 + side)\n",
        "    x0 = max(0, x1 - side); y0 = max(0, y1 - side)\n",
        "    box = (int(x0), int(y0), int(x1), int(y1))\n",
        "    return base.crop(box), box\n",
        "\n",
        "\n",
        "def to_centered_square(gar: Image.Image, fill=WHITE_RGB) -> Image.Image:\n",
        "    w,h = gar.size; side = max(w,h)\n",
        "    sq = Image.new(\"RGB\", (side, side), fill)\n",
        "    ox, oy = (side-w)//2, (side-h)//2\n",
        "    sq.paste(gar, (ox,oy))\n",
        "    return sq\n",
        "\n",
        "\n",
        "def expand_as_list(angles):\n",
        "    exp = list(expand_allowed_angles(angles))\n",
        "    exp = [_norm_angle(a) for a in exp]\n",
        "    exp.sort(key=len, reverse=True)\n",
        "    return exp\n",
        "\n",
        "\n",
        "def pick_target_angle(source_angle: str, allowed_outputs: set) -> str | None:\n",
        "    s = _norm_angle(source_angle)\n",
        "    for target in allowed_outputs:\n",
        "        fam = {_norm_angle(x) for x in expand_allowed_angles([target])}\n",
        "        if s in fam:\n",
        "            return _norm_angle(target)\n",
        "    return None\n",
        "\n",
        "\n",
        "def open_upright(path) -> Image.Image:\n",
        "    # EXIF-aware loader\n",
        "    with Image.open(path) as im:\n",
        "        return ImageOps.exif_transpose(im.convert(\"RGB\"))\n",
        "\n",
        "\n",
        "def show_gallery(img_list, titles=None, cols=3, w=4):\n",
        "    \"\"\"\n",
        "    Display PIL images in a flexible grid (same style as v1).\n",
        "    \"\"\"\n",
        "    titles = titles or [None]*len(img_list)\n",
        "    rows = math.ceil(len(img_list) / cols)\n",
        "    plt.figure(figsize=(cols*w, rows*w))\n",
        "    for idx, (img, title) in enumerate(zip(img_list, titles)):\n",
        "        plt.subplot(rows, cols, idx+1)\n",
        "        plt.imshow(ImageOps.exif_transpose(img))\n",
        "        if title:\n",
        "            plt.title(title)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paste-back helper\n",
        "Square crops with 200px margin are pasted back without masks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import ImageChops\n",
        "\n",
        "def paste_crop_back(full_img: Image.Image, edited_crop: Image.Image, crop_box):\n",
        "    x0,y0,x1,y1 = crop_box\n",
        "    target_w, target_h = x1 - x0, y1 - y0\n",
        "    if edited_crop.size != (target_w, target_h):\n",
        "        edited_crop = edited_crop.resize((target_w, target_h), resample=Image.Resampling.LANCZOS)\n",
        "    out = full_img.copy()\n",
        "    out.paste(edited_crop, (x0, y0))\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google APIs\n",
        "Authorize gspread and Drive upload + operations logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import google.auth\n",
        "SCOPES = [\"https://www.googleapis.com/auth/drive\", \"https://www.googleapis.com/auth/spreadsheets\"]\n",
        "creds, _ = google.auth.default(scopes=SCOPES)\n",
        "\n",
        "import gspread\n",
        "gs = gspread.authorize(creds)\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "drive_svc = build(\"drive\", \"v3\", credentials=creds)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure_dir(p):\n",
        "    os.makedirs(p, exist_ok=True); return p\n",
        "\n",
        "ensure_dir(OUTPUT_DIR)\n",
        "\n",
        "def build_output_filename(sku_name: str, angle_code: str, ext=\".png\") -> str:\n",
        "    angle_clean = _norm_angle(angle_code)\n",
        "    return f\"{sku_name}-{angle_clean}{ext}\"\n",
        "\n",
        "def upload_to_drive(local_path: str, parent_id: str | None = None):\n",
        "    if not parent_id:\n",
        "        return None\n",
        "    file_metadata = {\"name\": os.path.basename(local_path)}\n",
        "    if parent_id:\n",
        "        file_metadata[\"parents\"] = [parent_id]\n",
        "    media = MediaFileUpload(local_path, mimetype=\"image/png\")\n",
        "    created = drive_svc.files().create(body=file_metadata, media_body=media, fields=\"id,webViewLink\").execute()\n",
        "    return created\n",
        "\n",
        "def log_operation(row):\n",
        "    if not GOOGLE_SHEET_ID:\n",
        "        return None\n",
        "    sh = gs.open_by_key(GOOGLE_SHEET_ID)\n",
        "    try:\n",
        "        ws = sh.worksheet(OPERATIONS_SHEET_NAME)\n",
        "    except Exception:\n",
        "        ws = sh.add_worksheet(title=OPERATIONS_SHEET_NAME, rows=1000, cols=10)\n",
        "    ws.append_row(row, value_input_option=\"USER_ENTERED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nanobanana pro client and generation\n",
        "Use the Google Cloud API with enforced 1:1 aspect ratio and 4K resolution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "PRO_MODEL_ID = \"gemini-3-pro-image-preview\"\n",
        "\n",
        "def run_nanobanana_tryon(model_img: PILImage.Image, garment_img: PILImage.Image, *, extra_prompt: str = \"\") -> PILImage.Image:\n",
        "    contents = [TRYON_PROMPT]\n",
        "    if extra_prompt:\n",
        "        contents.append(extra_prompt)\n",
        "    contents.extend([model_img, garment_img])\n",
        "    response = client.models.generate_content(\n",
        "        model=PRO_MODEL_ID,\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(\n",
        "            response_modalities=[\"IMAGE\"],\n",
        "            image_config=types.ImageConfig(\n",
        "                aspect_ratio=TARGET_ASPECT,\n",
        "                image_size=IMAGE_SIZE\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    for part in response.parts:\n",
        "        as_image = part.as_image()\n",
        "        if as_image:\n",
        "            return as_image\n",
        "    raise RuntimeError(\"No image returned from nanobanana pro\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch helpers\n",
        "Search for garment/base sources, crop garments to squares with 200px margin, generate 1:1 try-on results, paste back if needed, and sync to Drive/Sheets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def list_images_for_angle(folder: str, angle_code: str):\n",
        "    angle_norm = _norm_angle(angle_code)\n",
        "    files = []\n",
        "    for f in os.listdir(folder):\n",
        "        if not _is_image_file(f):\n",
        "            continue\n",
        "        name = os.path.splitext(f)[0].lower()\n",
        "        if angle_norm in name.split('_') or name.startswith(angle_norm):\n",
        "            files.append(os.path.join(folder, f))\n",
        "    return sorted(files)\n",
        "\n",
        "def find_first_image(folder: str, angle_code: str):\n",
        "    imgs = list_images_for_angle(folder, angle_code)\n",
        "    return imgs[0] if imgs else None\n",
        "\n",
        "def load_image(path: str):\n",
        "    return open_upright(path)\n",
        "\n",
        "def process_one_garment_folder(folder_path: str, allowed_angles=None):\n",
        "    allowed_outputs = {_norm_angle(a) for a in (allowed_angles or [])}\n",
        "    sku_name = os.path.basename(folder_path)\n",
        "    base_folder = os.path.join(BASE_ROOT, sku_name)\n",
        "    if not os.path.isdir(base_folder):\n",
        "        print(f\"\u26a0\ufe0f  {sku_name}: no base folder for {base_folder}\")\n",
        "        return []\n",
        "\n",
        "    angles_to_process = expand_as_list(allowed_outputs) if allowed_outputs else expand_as_list(ALLOWED_BASES)\n",
        "    worklist = []\n",
        "    for ang in angles_to_process:\n",
        "        garment_path = find_first_image(folder_path, ang)\n",
        "        base_path = find_first_image(base_folder, ang)\n",
        "        if not garment_path or not base_path:\n",
        "            print(f\"\u23ed\ufe0f  {sku_name} {ang}: garment or base missing (garment={bool(garment_path)}, base={bool(base_path)})\")\n",
        "            continue\n",
        "        worklist.append((ang, garment_path, base_path))\n",
        "\n",
        "    print(f\"\u25b6\ufe0f  {sku_name}: {len(worklist)} image(s) to generate (angles={angles_to_process})\")\n",
        "    if not worklist:\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    for idx, (ang, garment_path, base_path) in enumerate(worklist, start=1):\n",
        "        print(f\"   {idx:>3}/{len(worklist):<3} {ang} \u2192 garment={os.path.basename(garment_path)} | base={os.path.basename(base_path)}\")\n",
        "        garment_img_raw = load_image(garment_path)\n",
        "        garment_crop, crop_box = crop_square_with_margin(garment_img_raw, CROP_MARGIN)\n",
        "        garment_sq = to_centered_square(garment_crop)\n",
        "        model_img = load_image(base_path)\n",
        "\n",
        "        show_gallery(\n",
        "            [garment_img_raw, garment_crop, garment_sq],\n",
        "            [\"Source garment\", f\"Crop (200px margin) {crop_box}\", \"Square garment for 1:1\"]\n",
        "        )\n",
        "        show_gallery(\n",
        "            [model_img, garment_sq],\n",
        "            [f\"Base/model [{ang}]\", \"Garment input to nanobanana pro\"],\n",
        "            cols=2,\n",
        "            w=5\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            print(\"      \ud83d\ude80 Sending to nanobanana pro\u2026\")\n",
        "            generated = run_nanobanana_tryon(model_img, garment_sq)\n",
        "        except Exception as ex:\n",
        "            print(f\"      \u274c {sku_name} {ang}: generation failed \u2192 {ex}\")\n",
        "            continue\n",
        "\n",
        "        show_gallery([generated], [\"Nanobanana pro output\"], cols=1, w=6)\n",
        "\n",
        "        fname = build_output_filename(sku_name, ang)\n",
        "        out_path = os.path.join(OUTPUT_DIR, fname)\n",
        "        ensure_dir(os.path.dirname(out_path))\n",
        "        generated.save(out_path)\n",
        "        print(f\"      \ud83d\udcbe saved \u2192 {out_path}\")\n",
        "\n",
        "        drive_info = upload_to_drive(out_path, DRIVE_UPLOAD_PARENT_ID)\n",
        "        if drive_info:\n",
        "            print(f\"      \u2601\ufe0f uploaded \u2192 {drive_info.get('webViewLink')}\")\n",
        "        log_operation([sku_name, ang, os.path.relpath(out_path, OUTPUT_DIR), datetime.utcnow().isoformat(), (drive_info or {}).get('webViewLink', \"\")])\n",
        "        results.append(out_path)\n",
        "    return results\n",
        "\n",
        "def run_list():\n",
        "    targets, unmatched = resolve_targets(SKU_CSV, GARMENTS_ROOT)\n",
        "    if unmatched:\n",
        "        print(\"Unmatched identifiers:\", unmatched)\n",
        "    print(f\"Resolved {len(targets)} garment folders\")\n",
        "    for t in targets:\n",
        "        process_one_garment_folder(t, allowed_angles=ALLOWED_BASES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dispatch\n",
        "Trigger batch processing for the normalized SKU list.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if RUN_MODE != \"sku_list\":\n",
        "    raise ValueError(\"Only sku_list mode is supported in v2\")\n",
        "run_list()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O4KzsXGV_ee1",
        "umaizfLYv7ww",
        "D7pcfKd0_iB_",
        "w3WTzeGw_nEv",
        "HFMF2dYwIlyZ",
        "IU5VwKPQIody"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07103d96144e433b8a0dec5bd6484757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64da8b050b0a476ea28bf518acdc0c76",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f270ea1b62e4342b74bd5aa6d837688",
            "value": 5
          }
        },
        "0e5bbb730420408481535e6642f07103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11643dbc95be4d0f8ea22e6c4a3dcc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5bbb730420408481535e6642f07103",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ea5c3cb9e1384e0a83368ec0a9722a08",
            "value": "\u20075/75\u2007[00:11&lt;02:47,\u2007\u20072.39s/it]"
          }
        },
        "2c40d233898c4dbda46119818a35436f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef487a23fa9411cbeb2c630dc358f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c40d233898c4dbda46119818a35436f",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ee7070ccbdaf4e3aa757c2a5ce84176e",
            "value": "\u2007\u20077%"
          }
        },
        "42847e933f2342d5b001324d78fa41ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ef487a23fa9411cbeb2c630dc358f80",
              "IPY_MODEL_07103d96144e433b8a0dec5bd6484757",
              "IPY_MODEL_11643dbc95be4d0f8ea22e6c4a3dcc8c"
            ],
            "layout": "IPY_MODEL_fa063be14ccb427bb2040cddb43fd503"
          }
        },
        "64da8b050b0a476ea28bf518acdc0c76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f270ea1b62e4342b74bd5aa6d837688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea5c3cb9e1384e0a83368ec0a9722a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee7070ccbdaf4e3aa757c2a5ce84176e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa063be14ccb427bb2040cddb43fd503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}