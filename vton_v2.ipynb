{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4KzsXGV_ee1"
      },
      "source": [
        "# INSTALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3aXFfY54iAH"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# --- Setup: Google auth + Drive + NanoBanana Pro deps ---\n",
        "\n",
        "import sys, os, subprocess, textwrap, importlib\n",
        "\n",
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install fal-client requests\n",
        "!pip -q install --upgrade pip\n",
        "!pip install \"google-genai>=1.40.0\" pillow numpy opencv-python-headless matplotlib gspread google-auth google-auth-oauthlib google-api-python-client piexif tqdm\n",
        "\n",
        "print(\"\u2705 Setup done for NanoBanana Pro.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DETAILER INSTALLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WXWS5m9Ozyt"
      },
      "source": [
        "#INSTALLS (restart & reinstall again after this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZUgwThxBmUv",
        "outputId": "166da4bd-6295-4bc3-9072-91d530800dc8"
      },
      "outputs": [],
      "source": [
        "# SAM3 via Hugging Face transformers\n",
        "!pip install -q \"git+https://github.com/huggingface/transformers.git\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHz7WW6oBpDz"
      },
      "outputs": [],
      "source": [
        "# GroundingDINO setup removed \u2014 SAM3 now handles detection + segmentation in one model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CjRycBjyBsdk",
        "outputId": "c46ccd3b-1454-41b8-ed2a-7d60b86d25c5"
      },
      "outputs": [],
      "source": [
        "%pip -q install open_clip_torch ninja wheel transformers accelerate \\\n",
        "                 sentencepiece protobuf huggingface_hub opencv-python\n",
        "!pip install -U --no-deps --force-reinstall \"git+https://github.com/huggingface/diffusers.git@main\"\n",
        "#%pip -q install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install --upgrade open_clip_torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kufDQpabB4h7",
        "outputId": "803c6239-e109-41ce-c7bb-0c99c1156dec"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone --depth 1 https://github.com/song-wensong/insert-anything.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkLr9zB3CJEl",
        "outputId": "00fb6f7f-c8cd-4973-acb0-3892e7f9f441"
      },
      "outputs": [],
      "source": [
        "!pip install https://huggingface.co/mit-han-lab/nunchaku/resolve/main/nunchaku-0.2.0+torch2.6-cp312-cp312-linux_x86_64.whl\n",
        "!pip install torch==2.6 torchvision==0.21 torchaudio==2.6\n",
        "!pip install ninja wheel diffusers transformers accelerate sentencepiece protobuf huggingface_hub\n",
        "!git clone https://huggingface.co/aha2023/insert-anything-lora-for-nunchaku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DU2Vo3gUxdl"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys, subprocess, textwrap, importlib\n",
        "import os, re, fnmatch, math, uuid, pytz, random, gc, tempfile, traceback\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageChops, ImageFilter, ImageDraw, ImageFont\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umaizfLYv7ww"
      },
      "source": [
        "# Select angles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4VplVzrviJT"
      },
      "outputs": [],
      "source": [
        "fr_lft = True #@param {type:\"boolean\"}\n",
        "fr_rght = True #@param {type:\"boolean\"}\n",
        "fr_cl = True #@param {type:\"boolean\"}\n",
        "bc_lft = True #@param {type:\"boolean\"}\n",
        "bc_rght = True #@param {type:\"boolean\"}\n",
        "lft = True #@param {type:\"boolean\"}\n",
        "rght = True #@param {type:\"boolean\"}\n",
        "bc_ = True #@param {type:\"boolean\"}\n",
        "fr_ = True #@param {type:\"boolean\"}\n",
        "fr_cl_btm = False #@param {type:\"boolean\"}\n",
        "fr_cl_tp = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "names = [\"fr_lft\",\"fr_rght\",\"fr_cl\",\"bc_lft\",\"bc_rght\",\"lft\",\"rght\",\"bc_\",\"fr_\",\"fr_cl_btm\",\"fr_cl_tp\"]\n",
        "ALLOWED_BASES = [n for n in names if locals()[n]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7pcfKd0_iB_"
      },
      "source": [
        "# CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq87guNN-V3D"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# --- Unified CONFIG ---\n",
        "from google.colab import userdata\n",
        "FAL_KEY = userdata.get('FAL_KEY')\n",
        "\n",
        "# Selection mode: list only\n",
        "RUN_MODE = \"sku_list\"     #@param [\"sku_list\"]\n",
        "\n",
        "# For RUN_MODE == \"sku_list\"\n",
        "SKU_CSV = \"28920\"  #@param {type:\"string\"}\n",
        "\n",
        "# Paths\n",
        "BASE_PHOTOS_ROOT  = \"/content/drive/MyDrive/Dazzl/SikSilk/SKSLK_MODELS/\"\n",
        "GARMENTS_ROOT     = \"/content/drive/MyDrive/Dazzl/SikSilk/AlexGens/SikSilk/\"\n",
        "\n",
        "\n",
        "# Filename/dir policy\n",
        "VALID_EXTENSIONS  = (\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\")\n",
        "IGNORE_DIRS       = {\"old\", \"__MACOSX\", \".ds_store\", \"Ricardo\", \"toweling\"}\n",
        "SKIP_FILENAME_TOKENS_CSV   = \"mask, generated, _close, _open, freelance, _backup\"   # substrings to skip\n",
        "SKIP_BASENAME_SUFFIXES_CSV = \"_sec\"                             # stem endings to skip\n",
        "REQUIRE_CUT_IN_FILENAME    = False   #@param {type:\"boolean\"}\n",
        "PREFER_AGNOSTIC_MASKS = True #@param {type:\"boolean\"}\n",
        "secondary_garment = True #@param {type:\"boolean\"}\n",
        "SECONDARY_GARMENT = secondary_garment\n",
        "\n",
        "# Cropping / paste-back (square 1:1, generous garment margin)\n",
        "CROP_PADDING      = 300        # px padding around garment when building crop\n",
        "UPPER_PADDING     = 200        # extra padding above garment\n",
        "HORIZ_PADDING     = 150        # horizontal padding\n",
        "MASK_EXPAND_PX    = 100        # outward growth before feather\n",
        "MASK_FEATHER_PX   = 30         # Gaussian sigma for feathering\n",
        "CROP_MIN_MARGIN   = 20        # minimum margin even if mask touches edge\n",
        "\n",
        "TARGET_ASPECT = (1, 1)         # enforce square crops for 1:1 generations\n",
        "\n",
        "# NanoBanana Pro (Google GenAI)\n",
        "NANOBANANA_MODEL_ID = \"gemini-3-pro-image-preview\"\n",
        "GEN_ASPECT_RATIO    = \"1:1\"\n",
        "GEN_IMAGE_SIZE      = \"4K\" #@param [\"1K\", \"2K\", \"4K\"]\n",
        "\n",
        "\n",
        "MAIN_PROMPT_INTRO = \"\"\"You are an expert virtual try-on AI. You will be given a 'model image' and a 'garment image'. Your task is to create a new photorealistic image where the person from the 'model image' is wearing the clothing from the 'garment image'.\"\"\"\n",
        "\n",
        "SECONDARY_PROMPT_INTRO = \"\"\"You are an expert virtual try-on AI. You will be given a 'model image' and a 'garment image'. Your task is to create a new photorealistic image where the person from the 'model image' is wearing the clothing from the 'garment image' as a complementary garment to their main.\"\"\"\n",
        "\n",
        "MAIN_PROMPT_RULES = [\n",
        "    \"**Complete Garment Replacement:** You MUST completely REMOVE and REPLACE the clothing item worn by the person in the 'model image' with the new garment. No part of the original clothing (e.g., collars, sleeves, patterns) should be visible in the final image.\",\n",
        "    \"**Preserve the Model:** The person's face, hair, body shape, and pose from the 'model image' MUST remain unchanged, pixel-for-pixel.\",\n",
        "    \"**Preserve the Background:** The entire background from the 'model image' MUST be preserved perfectly, pixel-for-pixel.\",\n",
        "    \"**Apply the Garment:** Realistically fit the new garment onto the person. It should adapt to their pose with natural folds, shadows, and lighting consistent with the original scene.\",\n",
        "    \"**Output:** Return ONLY the final, edited image. Do not include any text.\",\n",
        "    \"**Bespoke quality:** The garment should be ironed (if applicable), pretty and sit perfectly well \u2014 this is a professional fashion product photoshoot.\",\n",
        "]\n",
        "\n",
        "MAIN_TEXTURE_RULE = \"**Fabric Texture:** Use the provided 'Main texture reference' image to match the fabric texture, print, and sheen perfectly on the garment.\"\n",
        "\n",
        "SECONDARY_PROMPT_RULES = [\n",
        "    \"**Complete {sec_type} Garment Replacement:** You MUST completely REMOVE and REPLACE the {sec_type} clothing item worn by the person in the 'model image' with the new {sec_type} garment. No part of the original cloth (e.g., collars, sleeves, patterns) should be visible in the final image.\",\n",
        "    \"**Preserve the Model:** The person's face, hair, body shape, and pose from the 'model image' MUST remain unchanged, pixel-for-pixel.\",\n",
        "    \"**Preserve the Background:** The entire background from the 'model image' MUST be preserved perfectly, pixel-for-pixel.\",\n",
        "    \"**Apply the {sec_type} Garment:** Realistically fit the new {sec_type} garment onto the person. It should adapt to their pose with natural folds, shadows, and lighting consistent with the original scene.\",\n",
        "    \"**Bespoke quality:** the {sec_type} garment should be ironed (if applicable), pretty and sit perfectly well \u2014 this is a professional fashion product photoshoot.\",\n",
        "    \"**Preserve EXACT composition:** the source composition shouldn't change even slightly.\",\n",
        "    \"**Inpaint only what is needed:** Carefully consider, which part of the provided garment would be visible in the given angle. If target garment is seen only partly \u2014 replace that part with corresponding part of the new garment, but nothing else.\",\n",
        "    \"**NEVER ZOOM IN or OUT**\",\n",
        "    \"**Output:** Return ONLY the final, edited image. Do not include any text.\",\n",
        "]\n",
        "\n",
        "SECONDARY_TEXTURE_RULE = \"**Fabric Texture:** Use the provided texture reference image to match the {sec_type} garment's fabric texture, print, and sheen perfectly.\"\n",
        "\n",
        "def _numbered_rules(rules):\n",
        "    return \"\\n\".join(f\"{i+1}. {rule}\" for i, rule in enumerate(rules))\n",
        "\n",
        "def build_main_prompt(include_texture: bool = False):\n",
        "    rules = list(MAIN_PROMPT_RULES)\n",
        "    if include_texture:\n",
        "        rules.insert(5, MAIN_TEXTURE_RULE)  # ensure texture guidance is #6\n",
        "    return f\"{MAIN_PROMPT_INTRO}\\n\\n**Crucial Rules:**\\n\" + _numbered_rules(rules)\n",
        "\n",
        "def build_secondary_prompt(sec_type: str, include_texture: bool = False):\n",
        "    sec = sec_type or \"secondary\"\n",
        "    rules = [r.format(sec_type=sec) for r in SECONDARY_PROMPT_RULES]\n",
        "    if include_texture:\n",
        "        rules.insert(5, SECONDARY_TEXTURE_RULE.format(sec_type=sec))\n",
        "    intro = SECONDARY_PROMPT_INTRO.format(sec_type=sec)\n",
        "    return f\"{intro}\\n\\n**Crucial Rules:**\\n\" + _numbered_rules(rules)\n",
        "\n",
        "TRYON_PROMPT = build_main_prompt(include_texture=False)\n",
        "SECONDARY_TRYON_PROMPT = build_secondary_prompt(sec_type=\"secondary\", include_texture=False)\n",
        "\n",
        "# SAM3 segmentation (fal.ai)\n",
        "FAL_SAM_MODEL_ID = \"fal-ai/sam-3/image\"\n",
        "MASK_MAX_SIZE     = 1024   # px max side sent for segmentation\n",
        "MASK_PROMPT_TEMPLATE = \"{category}\"\n",
        "\n",
        "\n",
        "# Sheet-related (Ops removed) kept only for Gen Log appends\n",
        "SPREADSHEET_ID = \"1Kbq9__sEUQiuDPuza5Xy_hRyIn8pUvmfFj6vhPBrp8Y\"\n",
        "GEN_LOG_SHEET  = \"Gen Log\"\n",
        "\n",
        "# Misc\n",
        "SHOW_VISUALS = True\n",
        "TIMEZONE     = \"Europe/Lisbon\"\n",
        "OPERATOR     = \"Ivan\"\n",
        "OUTPUT_DIR   = \"/content/drive/MyDrive/Dazzl/SikSilk/SS_OUTPUT_FOLDER/v1-5/\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# === Garment/type taxonomy (kept) ===\n",
        "ALLOWED_GARMENT_TYPES = [\n",
        "    \"hoodie\",\"jeans\",\"joggers\",\"shorts\",\"sweater\",\"swimwear\",\n",
        "    \"t-shirt\",\"shirts\",\"track top\",\"trousers\",\"twinset\",\"polo\",\"vests\",\"shirts\"\n",
        "]\n",
        "TOP_GARMENTS    = [\"t-shirts\",\"shirts\",\"sweaters\",\"hoodies\",\"polos\",\"vests\"]\n",
        "BOTTOM_GARMENTS = [\"shorts\",\"joggers\",\"trousers\",\"jeans\", \"pants\", \"swimwear\"]\n",
        "TWINSET_TYPES   = [\"twinset\"]\n",
        "\n",
        "# === Details tokens ===\n",
        "ALLOWED_DETAIL_TYPES = [\"crest\",\"logo\",\"patch\"]\n",
        "\n",
        "# Angle sheet tokens (kept for compatibility, not used in v1.3)\n",
        "ANGLE_NEEDS_REGENERATE_TOKEN = \"Regenerate\"\n",
        "ENFORCE_BAN_SUBSTRINGS     = True\n",
        "BANNED_SUBSTRINGS_CSV      = \"wrong, pair, combo\"\n",
        "ENFORCE_REQUIRE_SUBSTRINGS = False\n",
        "REQUIRED_SUBSTRINGS_CSV    = \"\"\n",
        "REQUIRED_SUBSTRINGS_MODE   = \"ANY\"   # \"ANY\" | \"ALL\"\n",
        "\n",
        "def normalize_sku_list(sku_csv: str) -> str:\n",
        "    skus = []\n",
        "    for raw in sku_csv.split(','):\n",
        "        sku = raw.strip().upper()\n",
        "        match = re.search(r'(\\d+)', sku)\n",
        "        if match:\n",
        "            sku_number = match.group(1)\n",
        "            skus.append(f\"SS-{sku_number}\")\n",
        "    # Return as CSV string\n",
        "    return \", \".join(skus)\n",
        "\n",
        "SKU_CSV = normalize_sku_list(SKU_CSV)\n",
        "\n",
        "print(\"\u2705 Config ready for NanoBanana Pro v1.3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DETAILER CONFIG (shared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Detailer (logo cleanup) CONFIG ---\n",
        "RUN_DETAILER_AFTER_TRYON = True  # disable if you only want try-on\n",
        "DETAILER_VISUALIZE = False       # set True for debug plots\n",
        "DETAILER_ONLY_TYPES = [\"logo\"]  # fallback prompts when metadata has no details\n",
        "\n",
        "DETAILER_QUEUE_FOLDER = \"/content/drive/MyDrive/DETAILER_TODO\"\n",
        "TARGET_DIR = OUTPUT_DIR          # reuse try-on outputs\n",
        "WORKING_DIR = GARMENTS_ROOT      # source search root for detailer\n",
        "MASKS_ROOT = BASE_PHOTOS_ROOT    # mask lookup root (category/subcategory)\n",
        "\n",
        "# Detailer model/runtime knobs\n",
        "DEVICE_STR = \"cuda\"\n",
        "INPAINT_GENEROUS_PAD = 150\n",
        "INPAINT_TINY_PAD = 6\n",
        "INPAINT_SEED = 2025\n",
        "SKIP_IF_ALREADY_INPAINTED = False\n",
        "USE_BF16_INFERENCE = True\n",
        "VISUALIZE = False\n",
        "\n",
        "# Shared constants\n",
        "VALID_EXTS = VALID_EXTENSIONS\n",
        "BASE_NAMES = [\"fr_rght\", \"fr_lft\", \"fr_cl\", \"fr\", \"lft\", \"rght\", \"bc_lft\", \"bc_rght\", \"bc\", \"bc_cl\"]\n",
        "ACCEPTABLE_SUFFIXES = [\"cut\"]\n",
        "\n",
        "# Expand garment/detail taxonomies so both flows agree\n",
        "TOP_GARMENTS = sorted(set(list(TOP_GARMENTS) + [\"t-shirt\", \"shirt\", \"sweater\", \"hoodie\", \"track top\", \"vest\"]))\n",
        "BOTTOM_GARMENTS = sorted(set(list(BOTTOM_GARMENTS) + [\"shorts\", \"jogger-trousers\", \"trousers\", \"jeans\", \"swimwear\"]))\n",
        "TWINSET_TYPES = sorted(set(list(TWINSET_TYPES) + [\"twinset\"]))\n",
        "ALLOWED_DETAIL_TYPES = sorted(set(list(ALLOWED_DETAIL_TYPES) + [\"waist text\", \"sleeve text\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3WTzeGw_nEv"
      },
      "source": [
        "# UTILS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAeR9BUW-8Lp"
      },
      "outputs": [],
      "source": [
        "# --- Core utilities: normalization, angles, walking, masks (agnostic-first) ---\n",
        "\n",
        "import os, re, fnmatch, math, uuid, pytz, random, gc, tempfile, traceback\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageChops, ImageFilter\n",
        "\n",
        "\n",
        "\n",
        "# Parsers\n",
        "def _parse_csv_list(s):  return [x.strip().casefold() for x in (s or \"\").split(\",\") if x.strip()]\n",
        "BANNED_SUBSTRINGS       = _parse_csv_list(BANNED_SUBSTRINGS_CSV)\n",
        "REQUIRED_SUBSTRINGS     = _parse_csv_list(REQUIRED_SUBSTRINGS_CSV)\n",
        "SKIP_FILENAME_TOKENS    = set(_parse_csv_list(SKIP_FILENAME_TOKENS_CSV))\n",
        "SKIP_BASENAME_SUFFIXES  = tuple(_parse_csv_list(SKIP_BASENAME_SUFFIXES_CSV))\n",
        "\n",
        "# Normalizers\n",
        "def _norm_sku(s):\n",
        "    if s is None: return \"\"\n",
        "    s = str(s).replace(\"\\u00A0\",\" \")\n",
        "    s = \" \".join(s.split())\n",
        "    return s.casefold()\n",
        "\n",
        "def _norm_angle(s):\n",
        "    s = (s or \"\").strip().lower()\n",
        "    return s.strip(\"_ \").replace(\"-\", \"_\")\n",
        "\n",
        "# Angle aliases\n",
        "ANGLE_ALIASES = {\n",
        "    \"fr_cl\":   [\"fr\", \"fr_\"],\n",
        "    \"fr\":      [\"fr_cl\"],\n",
        "    \"bc_lft\":  [\"bc\", \"bc_\"],\n",
        "    \"bc_rght\": [\"bc\", \"bc_\"],\n",
        "}\n",
        "\n",
        "\n",
        "# --- Helpers to keep outputs strict, sources flexible ---\n",
        "def expand_as_list(angles):\n",
        "    exp = list(expand_allowed_angles(angles))\n",
        "    exp = [_norm_angle(a) for a in exp]\n",
        "    exp.sort(key=len, reverse=True)  # prefer 'fr_cl' over 'fr'\n",
        "    return exp\n",
        "\n",
        "def pick_target_angle(source_angle: str, allowed_outputs: set) -> str | None:\n",
        "    s = _norm_angle(source_angle)\n",
        "    for target in allowed_outputs:\n",
        "        fam = {_norm_angle(x) for x in expand_allowed_angles([target])}\n",
        "        if s in fam:\n",
        "            return _norm_angle(target)\n",
        "    return None\n",
        "\n",
        "\n",
        "def expand_allowed_angles(angles):\n",
        "    expanded = set()\n",
        "    for a in (angles or []):\n",
        "        a_norm = _norm_angle(a)\n",
        "        expanded.add(a_norm)\n",
        "        for alt in ANGLE_ALIASES.get(a_norm, []):\n",
        "            expanded.add(_norm_angle(alt))\n",
        "    return expanded\n",
        "\n",
        "# Ignore set\n",
        "IGNORE_DIRS = {d.lower() for d in IGNORE_DIRS}\n",
        "\n",
        "# Walkers\n",
        "def _is_sku_folder(path: str) -> bool:\n",
        "    if os.path.basename(os.path.normpath(path)).lower() in IGNORE_DIRS:\n",
        "        return False\n",
        "    try:\n",
        "        for f in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, f)) and f.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS)):\n",
        "                return True\n",
        "    except Exception:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def iter_sku_folders(root: str):\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        dirnames[:] = [d for d in dirnames if d.lower() not in IGNORE_DIRS]\n",
        "        if any(f.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS)) for f in filenames):\n",
        "            yield dirpath\n",
        "\n",
        "def resolve_targets(idents_csv: str, garments_root: str):\n",
        "    \"\"\"\n",
        "    Accepts:\n",
        "      \u2022 Plain SKU names, relative paths (Category/Subcategory/SKU), or absolute dirs\n",
        "      \u2022 Glob patterns (e.g., 'Hoodies/*' or 'SKSLK_12*')\n",
        "      \u2022 Directories that are NOT SKU leaves \u2192 expand to all descendant SKU leaves\n",
        "    \"\"\"\n",
        "    idents = [s.strip() for s in idents_csv.replace(\"\\n\", \",\").split(\",\") if s.strip()]\n",
        "    if not idents: return [], []\n",
        "\n",
        "    all_sku_dirs = list(iter_sku_folders(garments_root))\n",
        "    rel_map = {p: os.path.relpath(p, garments_root) for p in all_sku_dirs}\n",
        "    base_map = {p: os.path.basename(p) for p in all_sku_dirs}\n",
        "\n",
        "    seen, out, unmatched = set(), [], []\n",
        "    def add_path(p):\n",
        "        ap = os.path.abspath(p)\n",
        "        if os.path.isdir(ap):\n",
        "            if _is_sku_folder(ap):\n",
        "                if ap not in seen:\n",
        "                    seen.add(ap); out.append(ap)\n",
        "            else:\n",
        "                # Expand directory to all descendant SKU leaves\n",
        "                for leaf in iter_sku_folders(ap):\n",
        "                    a = os.path.abspath(leaf)\n",
        "                    if a not in seen:\n",
        "                        seen.add(a); out.append(a)\n",
        "\n",
        "    for ident in idents:\n",
        "        before = len(out)\n",
        "        # Absolute directory or SKU path\n",
        "        if os.path.isabs(ident) and os.path.isdir(ident):\n",
        "            add_path(ident)\n",
        "\n",
        "        # Relative under garments root (dir or SKU)\n",
        "        rel_candidate = os.path.join(garments_root, ident)\n",
        "        if os.path.exists(rel_candidate):\n",
        "            add_path(rel_candidate)\n",
        "\n",
        "        # Glob/pattern over known SKU leaves (by basename or relative path)\n",
        "        for p in all_sku_dirs:\n",
        "            if fnmatch.fnmatch(base_map[p], ident) or fnmatch.fnmatch(rel_map[p], ident):\n",
        "                add_path(p)\n",
        "\n",
        "        if len(out) == before:\n",
        "            unmatched.append(ident)\n",
        "\n",
        "    out.sort()\n",
        "    return out, unmatched\n",
        "\n",
        "# Base/mask location resolution\n",
        "def resolve_base_mask_dir(sku_folder: str,\n",
        "                          garments_root: str = GARMENTS_ROOT,\n",
        "                          base_root: str = BASE_PHOTOS_ROOT):\n",
        "    \"\"\"\n",
        "    Map .../GARMENTS_ROOT/Category/Subcategory/SKU \u2192 .../BASE_ROOT/Category/Subcategory\n",
        "    With robust fallbacks.\n",
        "    \"\"\"\n",
        "    abs_sku = os.path.abspath(sku_folder)\n",
        "    abs_gar = os.path.abspath(garments_root)\n",
        "    try:\n",
        "        rel = os.path.relpath(abs_sku, abs_gar)\n",
        "    except Exception:\n",
        "        rel = None\n",
        "\n",
        "    if rel and not rel.startswith(\"..\"):\n",
        "        rel_parent = os.path.dirname(rel)\n",
        "        cand = os.path.join(base_root, rel_parent)\n",
        "        if os.path.isdir(cand): return cand\n",
        "\n",
        "    subcat = os.path.basename(os.path.dirname(abs_sku))\n",
        "    cat    = os.path.basename(os.path.dirname(os.path.dirname(abs_sku)))\n",
        "    cand2  = os.path.join(base_root, cat, subcat)\n",
        "    if os.path.isdir(cand2): return cand2\n",
        "\n",
        "    cand3  = os.path.join(base_root, subcat)\n",
        "    if os.path.isdir(cand3): return cand3\n",
        "    return None\n",
        "\n",
        "def _valid_ext(fname): return fname.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS))\n",
        "\n",
        "def _file_prefix_or_none(filename: str):\n",
        "    low = filename.lower()\n",
        "    for base in ALLOWED_BASES:\n",
        "        if low.startswith(base): return base\n",
        "    return None\n",
        "\n",
        "def _find_image_with_stem_and_suffix(directory, stem, suffix=\"\"):\n",
        "    if not directory or not os.path.isdir(directory):\n",
        "        return None\n",
        "    stem = stem.lower()\n",
        "    for file in os.listdir(directory):\n",
        "        fname, fext = os.path.splitext(file)\n",
        "        if fext.lower() in (\".png\",\".jpg\",\".jpeg\") and fname.lower() == f\"{stem}{suffix}\":\n",
        "            return os.path.join(directory, file)\n",
        "    return None\n",
        "\n",
        "# --- Existence check in Google Drive by Colab-style path ---\n",
        "def drive_file_exists_any_ext_at_colab_path(target_colab_path: str,\n",
        "                                            exts=(\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\")) -> bool:\n",
        "    \"\"\"\n",
        "    Given a Colab-style *file* path (incl. a filename with any extension),\n",
        "    checks if a file with the SAME stem exists in the same folder with any of the allowed extensions.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parent_id, desired_name = _resolve_parent_id_and_filename_from_colab_path(target_colab_path)\n",
        "        stem, _ = os.path.splitext(desired_name)\n",
        "        files = _list_children(parent_id, q_extra=\"\")  # list once; filter locally\n",
        "        allowed = {e.lower() for e in exts}\n",
        "        for f in files:\n",
        "            fname = f.get(\"name\", \"\")\n",
        "            s, e = os.path.splitext(fname)\n",
        "            if s == stem and e.lower() in allowed:\n",
        "                return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0\ufe0f Ext-agnostic existence check failed for {target_colab_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# === NEW: mask finding with AGNOSTIC priority ===\n",
        "def find_mask_path(base_subcat_dir: str, stem_no_cut: str):\n",
        "    \"\"\"\n",
        "    Priority:\n",
        "      1) {stem}_mask_agnostic.(png|jpg|jpeg)\n",
        "      2) {stem}_mask.(png|jpg|jpeg)\n",
        "    \"\"\"\n",
        "    if not base_subcat_dir or not os.path.isdir(base_subcat_dir):\n",
        "        return None\n",
        "\n",
        "    candidates = []\n",
        "    if PREFER_AGNOSTIC_MASKS:\n",
        "      for ext in (\".png\",\".jpg\",\".jpeg\",\".PNG\",\".JPG\",\".JPEG\"):\n",
        "          candidates.append(os.path.join(base_subcat_dir, f\"{stem_no_cut}_mask_agnostic{ext}\"))\n",
        "    for ext in (\".png\",\".jpg\",\".jpeg\",\".PNG\",\".JPG\",\".JPEG\"):\n",
        "        candidates.append(os.path.join(base_subcat_dir, f\"{stem_no_cut}_mask{ext}\"))\n",
        "\n",
        "    for p in candidates:\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_secondary_garment_path(folder_path: str, main_filename: str):\n",
        "    \"\"\"\n",
        "    Locate the secondary garment paired with a primary garment file.\n",
        "    Example: main 'bc_lft_cut.png' -> looks for 'bc_lft_sec_cut.(png|jpg)'.\n",
        "    Falls back to a non-cut variant when REQUIRE_CUT_IN_FILENAME is False.\n",
        "    \"\"\"\n",
        "    stem, _ = os.path.splitext(main_filename)\n",
        "    has_cut = stem.endswith(\"_cut\")\n",
        "    core = stem[:-4] if has_cut else stem\n",
        "\n",
        "    candidates = [f\"{core}_sec_cut\"]\n",
        "    if not REQUIRE_CUT_IN_FILENAME:\n",
        "        candidates.append(f\"{core}_sec\")\n",
        "    if not has_cut:\n",
        "        candidates.append(f\"{stem}_sec_cut\")\n",
        "\n",
        "    seen = set()\n",
        "    for cand in candidates:\n",
        "        if cand in seen:\n",
        "            continue\n",
        "        seen.add(cand)\n",
        "        for ext in VALID_EXTENSIONS:\n",
        "            path = os.path.join(folder_path, f\"{cand}{ext}\")\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "    return None\n",
        "\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# --- Aspect-ratio bbox (replaces square bbox usage) ---\n",
        "\n",
        "\n",
        "\n",
        "def find_aspect_bbox(\n",
        "    mask: Image.Image,\n",
        "    aspect: tuple[int,int] = (1,1),   # width:height, e.g. (1280,1600)\n",
        "    padding: int = 40,\n",
        "    upper_padding: int | None = None,\n",
        "    horiz_padding: int = 0,\n",
        "    min_margin: int | None = None,\n",
        "    allow_padding: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Return a rectangular bbox [x0, y0, x1, y1] that fully contains the mask + padding\n",
        "    and matches the requested aspect ratio. When allow_padding is True the box may\n",
        "    extend outside the image; callers should pad when cropping to preserve aspect.\n",
        "    When allow_padding is False the bbox is kept inside the image while expanding\n",
        "    other directions to honor the aspect ratio (minimal in-frame crop).\n",
        "    \"\"\"\n",
        "    if min_margin is None:\n",
        "        try:\n",
        "            min_margin = int(MASK_EXPAND_PX + 3 * MASK_FEATHER_PX + 5)\n",
        "        except Exception:\n",
        "            min_margin = 40\n",
        "\n",
        "    m = np.array(mask.convert(\"L\"))\n",
        "    h, w = m.shape\n",
        "    ys, xs = np.where(m > 128)\n",
        "    if xs.size == 0:\n",
        "        raise ValueError(\"Mask has no white pixels!\")\n",
        "\n",
        "    x_min, x_max = int(xs.min()), int(xs.max())\n",
        "    y_min, y_max = int(ys.min()), int(ys.max())\n",
        "\n",
        "    if upper_padding is None:\n",
        "        upper_padding = padding\n",
        "\n",
        "    # Initial padded bbox (can go outside image bounds; padding applied later)\n",
        "    x0 = x_min - horiz_padding - min_margin\n",
        "    x1 = x_max + horiz_padding + min_margin\n",
        "    y0 = y_min - upper_padding - min_margin\n",
        "    y1 = y_max + padding + min_margin\n",
        "\n",
        "    bw, bh = (x1 - x0), (y1 - y0)\n",
        "    aw, ah = aspect\n",
        "    target_ar = float(aw) / float(max(1, ah))\n",
        "\n",
        "    def expand_to_aspect(x0, y0, x1, y1):\n",
        "        bw = x1 - x0; bh = y1 - y0\n",
        "        cur_ar = bw / float(max(1, bh))\n",
        "        if cur_ar < target_ar:\n",
        "            need_w = int(np.ceil(target_ar * bh))\n",
        "            grow = max(0, need_w - bw)\n",
        "            x0 -= grow // 2\n",
        "            x1 += grow - grow // 2\n",
        "        elif cur_ar > target_ar:\n",
        "            need_h = int(np.ceil(bw / target_ar))\n",
        "            grow = max(0, need_h - bh)\n",
        "            y0 -= grow // 2\n",
        "            y1 += grow - grow // 2\n",
        "        return x0, y0, x1, y1\n",
        "\n",
        "    x0, y0, x1, y1 = expand_to_aspect(x0, y0, x1, y1)\n",
        "\n",
        "    if allow_padding:\n",
        "        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
        "        return [x0, y0, x1, y1]\n",
        "\n",
        "    # Constrain inside the frame without padding (used for secondary flow)\n",
        "    x0 = max(0.0, float(x0))\n",
        "    y0 = max(0.0, float(y0))\n",
        "    x1 = min(w, float(x1))\n",
        "    y1 = min(h, float(y1))\n",
        "\n",
        "    bw, bh = x1 - x0, y1 - y0\n",
        "    if bw <= 0 or bh <= 0:\n",
        "        return [0, 0, w, h]\n",
        "\n",
        "    def place_span(b0, b1, size, limit):\n",
        "        size = min(size, limit)\n",
        "        span = b1 - b0\n",
        "        min_start = max(0.0, b1 - size)\n",
        "        max_start = min(limit - size, b0)\n",
        "        desired = b0 - (size - span) / 2.0\n",
        "        start = min(max(desired, min_start), max_start)\n",
        "        end = start + size\n",
        "        if end > limit:\n",
        "            start -= (end - limit)\n",
        "            end = limit\n",
        "        if start < 0:\n",
        "            end -= start\n",
        "            start = 0\n",
        "        return start, end\n",
        "\n",
        "    if aw == ah:\n",
        "        target_size = max(bw, bh)\n",
        "        target_size = min(target_size, w, h)\n",
        "        x0, x1 = place_span(x0, x1, target_size, float(w))\n",
        "        y0, y1 = place_span(y0, y1, target_size, float(h))\n",
        "    else:\n",
        "        target_w = max(bw, float(np.ceil(bh * target_ar)))\n",
        "        target_h = max(bh, float(np.ceil(target_w / target_ar)))\n",
        "        target_w = min(target_w, w)\n",
        "        target_h = min(target_h, h)\n",
        "        x0, x1 = place_span(x0, x1, target_w, float(w))\n",
        "        y0, y1 = place_span(y0, y1, target_h, float(h))\n",
        "\n",
        "    return [int(round(x0)), int(round(y0)), int(round(x1)), int(round(y1))]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def crop_with_padding(img: Image.Image, bbox, fill):\n",
        "    \"\"\"Crop using bbox (which may extend outside the image) and pad missing areas with fill.\"\"\"\n",
        "    x0, y0, x1, y1 = map(int, bbox)\n",
        "    w, h = img.size\n",
        "    tgt_w, tgt_h = x1 - x0, y1 - y0\n",
        "    out = Image.new(img.mode, (tgt_w, tgt_h), fill)\n",
        "\n",
        "    src_box = (\n",
        "        max(0, x0),\n",
        "        max(0, y0),\n",
        "        min(w, x1),\n",
        "        min(h, y1),\n",
        "    )\n",
        "    dst_xy = (max(0, -x0), max(0, -y0))\n",
        "\n",
        "    if src_box[2] > src_box[0] and src_box[3] > src_box[1]:\n",
        "        region = img.crop(src_box)\n",
        "        out.paste(region, dst_xy)\n",
        "    return out\n",
        "\n",
        "WHITE_RGB = (255,255,255)\n",
        "\n",
        "def flatten_alpha_to_white(img: Image.Image) -> Image.Image:\n",
        "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
        "        bg = Image.new(\"RGB\", img.size, WHITE_RGB)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "        return bg\n",
        "    return img.convert(\"RGB\")\n",
        "\n",
        "def _tight_bbox_nonwhite_or_opaque(img: Image.Image):\n",
        "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
        "        arr = np.asarray(img.convert(\"RGBA\"))\n",
        "        alpha = arr[...,3]\n",
        "        fg = alpha > 0\n",
        "    else:\n",
        "        arr = np.asarray(img.convert(\"RGB\"))\n",
        "        fg = ~((arr[...,0]==255)&(arr[...,1]==255)&(arr[...,2]==255))\n",
        "    if not np.any(fg): return None\n",
        "    ys, xs = np.where(fg)\n",
        "    x0, x1 = int(xs.min()), int(xs.max())+1\n",
        "    y0, y1 = int(ys.min()), int(ys.max())+1\n",
        "    return (x0,y0,x1,y1)\n",
        "\n",
        "def crop_garment_keep_aspect(img: Image.Image) -> Image.Image:\n",
        "    bbox = _tight_bbox_nonwhite_or_opaque(img)\n",
        "    base = flatten_alpha_to_white(img)\n",
        "    if bbox is None: return base\n",
        "    full_bbox = (0,0,base.width,base.height)\n",
        "    if bbox == full_bbox: return base\n",
        "    return base.crop(bbox)\n",
        "\n",
        "def to_centered_square(gar: Image.Image, fill=WHITE_RGB) -> Image.Image:\n",
        "    w,h = gar.size; side = max(w,h)\n",
        "    sq = Image.new(\"RGB\", (side, side), fill)\n",
        "    ox, oy = (side-w)//2, (side-h)//2\n",
        "    sq.paste(gar, (ox,oy)); return sq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _add_caption_above_square(square_img: Image.Image, heading: str) -> Image.Image:\n",
        "    pad_top = max(60, square_img.height // 5)\n",
        "    canvas = Image.new(\"RGB\", (square_img.width, square_img.height + pad_top), WHITE_RGB)\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "    font_size = max(64, square_img.width // 9)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "    bbox = draw.textbbox((0, 0), heading, font=font)\n",
        "    text_w = bbox[2] - bbox[0]\n",
        "    text_h = bbox[3] - bbox[1]\n",
        "    text_x = max(0, (canvas.width - text_w) // 2)\n",
        "    text_y = max(0, (pad_top - text_h) // 2)\n",
        "    draw.text((text_x, text_y), heading, fill=(0, 0, 0), font=font)\n",
        "    canvas.paste(square_img, (0, pad_top))\n",
        "    return canvas\n",
        "\n",
        "def build_no_texture_card(size):\n",
        "    w, h = size if size and len(size) == 2 else (512, 512)\n",
        "    w = max(128, int(w))\n",
        "    h = max(128, int(h))\n",
        "    canvas = Image.new(\"RGB\", (w, h), WHITE_RGB)\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "    text = \"No texture file found\"\n",
        "    font_size = max(64, min(w, h) // 9)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "    draw.text(((w - tw) // 2, (h - th) // 2), text, fill=(0, 0, 0), font=font)\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def load_texture_reference(folder_path: str, *, secondary: bool = False, heading: str = \"Main texture reference\") -> Image.Image | None:\n",
        "    \"\"\"\n",
        "    Load a texture reference if present:\n",
        "      - texture.(png|jpg|jpeg) for primary\n",
        "      - texture_sec.(png|jpg|jpeg) for secondary\n",
        "    Crop to a square and add a caption banner above on white.\n",
        "    \"\"\"\n",
        "    stem = \"texture_sec\" if secondary else \"texture\"\n",
        "    for ext in VALID_EXTENSIONS:\n",
        "        candidate = os.path.join(folder_path, f\"{stem}{ext}\")\n",
        "        if os.path.exists(candidate):\n",
        "            try:\n",
        "                raw = open_upright(candidate).convert(\"RGB\")\n",
        "                side = min(raw.size)\n",
        "                if side <= 0:\n",
        "                    continue\n",
        "                square = ImageOps.fit(raw, (side, side), method=Image.Resampling.LANCZOS, centering=(0.5, 0.5))\n",
        "                return _add_caption_above_square(square, heading)\n",
        "            except Exception as tex_err:\n",
        "                print(f\"      \u26a0\ufe0f Unable to use texture reference '{candidate}': {tex_err}\")\n",
        "                return None\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbJ9VKUEzhaP"
      },
      "outputs": [],
      "source": [
        "# --- Visualisation helpers (restored) ---\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "def open_upright(path) -> Image.Image:\n",
        "    # EXIF-aware loader (same as before)\n",
        "    with Image.open(path) as im:\n",
        "        return ImageOps.exif_transpose(im)\n",
        "\n",
        "def show_gallery(img_list, titles=None, cols=3, w=4):\n",
        "    \"\"\"\n",
        "    Display PIL images in a flexible grid (identical behaviour to your original).\n",
        "    Only renders if SHOW_VISUALS is True.\n",
        "    \"\"\"\n",
        "    if not globals().get(\"SHOW_VISUALS\", False):\n",
        "        return\n",
        "\n",
        "    n = len(img_list)\n",
        "    rows = math.ceil(n / cols)\n",
        "    plt.figure(figsize=(cols * w, rows * w))\n",
        "\n",
        "    for i, img in enumerate(img_list):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        # Accept PIL, torch tensors or numpy arrays (4-D batch \u21d2 pick first)\n",
        "        if isinstance(img, np.ndarray) and img.ndim == 4:\n",
        "            img = img[0]  # (B,H,W,C) \u2192 (H,W,C)\n",
        "        # Torch tensors are printed via duck-typing check to avoid hard import\n",
        "        if \"Tensor\" in str(type(img)):\n",
        "            img = img.detach().cpu().permute(1, 2, 0).numpy()\n",
        "        plt.imshow(img)\n",
        "        if titles and i < len(titles):\n",
        "            plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOhtSL7B-_-f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "def paste_crop_back_debug(\n",
        "    full_img: Image.Image,\n",
        "    edited_crop: Image.Image,\n",
        "    crop_box,               # (x0, y0, x1, y1) in full_img coords\n",
        "    crop_mask,              # H\u00d7W uint8/bool, garment=white in crop coords\n",
        "    solid_expand_px: int = 8,   # grow the 100% opaque region\n",
        "    halo_px: int = 40,          # thickness of the soft halo OUTSIDE solid\n",
        "    feather_px: int = 20,       # Gaussian sigma for halo\n",
        "    *,\n",
        "    bin_thresh: int = 127,\n",
        "    edge_feather_px: int = 15,  # clamp width at crop borders\n",
        "):\n",
        "    x0, y0, x1, y1 = map(int, crop_box)\n",
        "    tgt_w, tgt_h   = (x1 - x0), (y1 - y0)\n",
        "\n",
        "    # --- resize edited crop ---\n",
        "    edit_rs = edited_crop.resize((tgt_w, tgt_h), Image.Resampling.LANCZOS)\n",
        "\n",
        "    # --- 1) binary silhouette mask in crop coords ---\n",
        "    mask_np = crop_mask\n",
        "    if isinstance(mask_np, Image.Image):\n",
        "        mask_np = np.array(mask_np.convert(\"L\"))\n",
        "    if mask_np.ndim == 3:\n",
        "        mask_np = mask_np[..., 0]\n",
        "\n",
        "    mask_np = cv2.resize(mask_np, (tgt_w, tgt_h), interpolation=cv2.INTER_NEAREST)\n",
        "    mask_bin = (mask_np > bin_thresh).astype(np.uint8)\n",
        "\n",
        "    # --- 2) solid = expanded garment, outer = solid + halo -------------------\n",
        "    def dilate(mask, r):\n",
        "        if r <= 0:\n",
        "            return mask.copy()\n",
        "        ksize = max(1, r * 2 + 1)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))\n",
        "        return cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    solid = dilate(mask_bin, solid_expand_px)               # fully opaque region\n",
        "    outer = dilate(solid, halo_px)                          # solid + halo shell\n",
        "\n",
        "    # band where we want partial alpha\n",
        "    band = outer.clip(0, 1).astype(np.float32) * 255.0\n",
        "\n",
        "    # --- 3) blur the band to get a smooth halo --------------------------------\n",
        "    if feather_px > 0:\n",
        "        band = cv2.GaussianBlur(\n",
        "            band, (0, 0),\n",
        "            sigmaX=feather_px,\n",
        "            sigmaY=feather_px,\n",
        "        )\n",
        "\n",
        "    # --- 4) clamp halo near crop borders (no recursion) -----------------------\n",
        "    H, W = band.shape\n",
        "    ef = max(1, int(edge_feather_px))\n",
        "    ef = min(ef, H // 2, W // 2)\n",
        "\n",
        "    leaks_top    = band[0, :].max() > 0\n",
        "    leaks_bottom = band[-1, :].max() > 0\n",
        "    leaks_left   = band[:, 0].max() > 0\n",
        "    leaks_right  = band[:, -1].max() > 0\n",
        "\n",
        "    if leaks_top and ef > 0:\n",
        "        ramp = np.linspace(0.0, 1.0, ef, endpoint=True).reshape(-1, 1)\n",
        "        band[:ef, :] *= ramp\n",
        "    if leaks_bottom and ef > 0:\n",
        "        ramp = np.linspace(1.0, 0.0, ef, endpoint=True).reshape(-1, 1)\n",
        "        band[-ef:, :] *= ramp\n",
        "    if leaks_left and ef > 0:\n",
        "        ramp = np.linspace(0.0, 1.0, ef, endpoint=True).reshape(1, -1)\n",
        "        band[:, :ef] *= ramp\n",
        "    if leaks_right and ef > 0:\n",
        "        ramp = np.linspace(1.0, 0.0, ef, endpoint=True).reshape(1, -1)\n",
        "        band[:, -ef:] *= ramp\n",
        "\n",
        "    # --- 5) final alpha: 255 inside solid, halo in the band only --------------\n",
        "    alpha = band.copy()\n",
        "    alpha[solid > 0] = 255.0\n",
        "    alpha = np.clip(alpha, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # --- 6) composite back into full image ------------------------------------\n",
        "    mask_img = Image.fromarray(alpha, mode=\"L\")\n",
        "    region   = full_img.crop((x0, y0, x1, y1))\n",
        "    comp     = Image.composite(edit_rs, region, mask_img)\n",
        "    out_img  = full_img.copy()\n",
        "    out_img.paste(comp, (x0, y0))\n",
        "\n",
        "    return out_img, alpha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br9dskEm_CBL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- NanoBanana Pro try-on (Google Cloud GenAI) ---\n",
        "\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from PIL import Image\n",
        "\n",
        "def _load_gemini_api_key():\n",
        "    key = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GEMINI_APIKEY\")\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        key = key or userdata.get(\"GEMINI_API_KEY\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    if not key:\n",
        "        raise ValueError(\"Set GEMINI_API_KEY in environment or Colab userdata.\")\n",
        "    return key\n",
        "\n",
        "genai_client = genai.Client(api_key=_load_gemini_api_key())\n",
        "\n",
        "def _extract_first_image(resp):\n",
        "    import io\n",
        "    parts = []\n",
        "    if hasattr(resp, \"parts\"):\n",
        "        parts.extend(resp.parts)\n",
        "    for cand in getattr(resp, \"candidates\", []):\n",
        "        parts.extend(getattr(getattr(cand, \"content\", None), \"parts\", []) or [])\n",
        "\n",
        "    for part in parts:\n",
        "        if isinstance(part, Image.Image):\n",
        "            return part\n",
        "        as_image = getattr(part, \"as_image\", None)\n",
        "        if callable(as_image):\n",
        "            img = as_image()\n",
        "            if isinstance(img, Image.Image):\n",
        "                return img\n",
        "        inline = getattr(part, \"inline_data\", None)\n",
        "        if inline and getattr(inline, \"data\", None):\n",
        "            return Image.open(io.BytesIO(inline.data)).convert(\"RGB\")\n",
        "    raise ValueError(\"No image returned from NanoBanana Pro response.\")\n",
        "\n",
        "\n",
        "def run_nanobanana_tryon(model_image: Image.Image, garment_image: Image.Image,\n",
        "                         *, aspect_ratio: str = GEN_ASPECT_RATIO,\n",
        "                         image_size: str = GEN_IMAGE_SIZE,\n",
        "                         prompt: str | None = None,\n",
        "                         extra_images=None):\n",
        "    prompt_text = prompt or TRYON_PROMPT\n",
        "    contents = [\n",
        "        prompt_text,\n",
        "        \"Model image:\",\n",
        "        model_image.convert(\"RGB\"),\n",
        "        \"Garment image:\",\n",
        "        garment_image.convert(\"RGB\"),\n",
        "    ]\n",
        "    if extra_images:\n",
        "        contents.extend(extra_images)\n",
        "    resp = genai_client.models.generate_content(\n",
        "        model=NANOBANANA_MODEL_ID,\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(\n",
        "            response_modalities=[\"IMAGE\"],\n",
        "            image_config=types.ImageConfig(\n",
        "                aspect_ratio=aspect_ratio,\n",
        "                image_size=image_size,\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        "    img = _extract_first_image(resp)\n",
        "    return img.convert(\"RGB\")\n",
        "\n",
        "print(\"\u2705 NanoBanana Pro client ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESv1VQVOnkTu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- SAM3 segmentation via fal.ai for on-the-fly garment masks ---\n",
        "\n",
        "import base64, io, json\n",
        "import fal_client\n",
        "import requests\n",
        "\n",
        "MASK_CACHE = {}\n",
        "TOP_GARMENTS_SET = {g.casefold() for g in TOP_GARMENTS}\n",
        "BOTTOM_GARMENTS_SET = {g.casefold() for g in BOTTOM_GARMENTS}\n",
        "\n",
        "def _classify_garment_category(category: str) -> str | None:\n",
        "    cat_norm = re.sub(r\"\\s+\", \" \", str(category or \"\").strip()).casefold()\n",
        "    if cat_norm in TOP_GARMENTS_SET:\n",
        "        return \"top\"\n",
        "    if cat_norm in BOTTOM_GARMENTS_SET:\n",
        "        return \"bottom\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def _garment_category_from_path(path: str) -> str:\n",
        "    parts = os.path.normpath(path).split(os.sep)\n",
        "    lowers = [p.casefold() for p in parts]\n",
        "    cat = None\n",
        "    if \"siksilk\" in lowers:\n",
        "        last_idx = len(lowers) - 1 - lowers[::-1].index(\"siksilk\")\n",
        "        if last_idx + 1 < len(parts):\n",
        "            cat = parts[last_idx + 1]\n",
        "    if not cat:\n",
        "        try:\n",
        "            rel = os.path.relpath(path, GARMENTS_ROOT)\n",
        "            if not rel.startswith(\"..\"):  # path is under garments root\n",
        "                rel_parts = rel.split(os.sep)\n",
        "                if rel_parts:\n",
        "                    cat = rel_parts[0]\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not cat:\n",
        "        parent = os.path.basename(os.path.dirname(path))\n",
        "        cat = parent or \"garment\"\n",
        "    cat_clean = re.sub(r\"[_]+\", \" \", str(cat)).strip()\n",
        "    cat_clean = re.sub(r\"\\s+\", \" \", cat_clean)\n",
        "    return cat_clean or \"garment\"\n",
        "\n",
        "def _build_mask_prompt(category: str, variant: str | None = None) -> str:\n",
        "    clean_category = str(category).strip()\n",
        "    clean_category = clean_category.rstrip(\"s\") if clean_category else clean_category\n",
        "    prompt = MASK_PROMPT_TEMPLATE.format(category=clean_category, variant=(variant or \"\").strip())\n",
        "    prompt = prompt.strip()\n",
        "    return prompt or clean_category\n",
        "\n",
        "def _strip_json_block(text: str) -> str:\n",
        "    if \"```json\" in text:\n",
        "        return text.split(\"```json\", 1)[1].split(\"```\", 1)[0].strip()\n",
        "    if \"```\" in text:\n",
        "        return text.split(\"```\", 1)[1].split(\"```\", 1)[0].strip()\n",
        "    return text.strip()\n",
        "\n",
        "def _mask_data_to_canvas(data_url: str, target_size):\n",
        "    w, h = target_size\n",
        "    if data_url.startswith(\"http\"):\n",
        "        resp = requests.get(data_url)\n",
        "        resp.raise_for_status()\n",
        "        raw = resp.content\n",
        "    else:\n",
        "        encoded = data_url.split(\",\", 1)[1] if \",\" in data_url else data_url\n",
        "        encoded = encoded.strip()\n",
        "        if not encoded:\n",
        "            raise ValueError(\"Mask data missing from SAM response.\")\n",
        "        pad_len = (-len(encoded)) % 4\n",
        "        if pad_len:\n",
        "            encoded = encoded + \"=\" * pad_len\n",
        "        try:\n",
        "            raw = base64.b64decode(encoded)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Invalid mask image data: {e}\")\n",
        "    mask_img = Image.open(io.BytesIO(raw)).convert(\"L\")\n",
        "    if mask_img.size != (w, h):\n",
        "        mask_img = mask_img.resize((w, h), Image.Resampling.NEAREST)\n",
        "    return mask_img.point(lambda v: 255 if v > 128 else 0)\n",
        "\n",
        "def _image_to_data_url(img: Image.Image) -> str:\n",
        "    buf = io.BytesIO()\n",
        "    img.save(buf, format=\"PNG\")\n",
        "    return \"data:image/png;base64,\" + base64.b64encode(buf.getvalue()).decode()\n",
        "\n",
        "def _extract_masks_from_result(result):\n",
        "    masks = []\n",
        "    for m in result.get(\"masks\") or []:\n",
        "        if isinstance(m, dict):\n",
        "            data = m.get(\"file_data\") or m.get(\"data\")\n",
        "            ct = m.get(\"content_type\") or \"image/png\"\n",
        "            if data:\n",
        "                if not str(data).startswith(\"data:\"):\n",
        "                    data = f\"data:{ct};base64,{data}\"\n",
        "                masks.append(data)\n",
        "            elif m.get(\"url\"):\n",
        "                masks.append(m[\"url\"])\n",
        "        elif isinstance(m, str):\n",
        "            masks.append(m)\n",
        "    img = result.get(\"image\")\n",
        "    if img:\n",
        "        if isinstance(img, dict):\n",
        "            data = img.get(\"file_data\") or img.get(\"data\")\n",
        "            ct = img.get(\"content_type\") or \"image/png\"\n",
        "            if data:\n",
        "                if not str(data).startswith(\"data:\"):\n",
        "                    data = f\"data:{ct};base64,{data}\"\n",
        "                masks.append(data)\n",
        "            elif img.get(\"url\"):\n",
        "                masks.append(img[\"url\"])\n",
        "        elif isinstance(img, str):\n",
        "            masks.append(img)\n",
        "    return masks\n",
        "\n",
        "def _fetch_sam_masks(image_data_url: str, category: str):\n",
        "    logs = []\n",
        "    def _on_queue(update):\n",
        "        if isinstance(update, fal_client.InProgress):\n",
        "            for log in update.logs:\n",
        "                msg = log.get(\"message\")\n",
        "                if msg:\n",
        "                    logs.append(msg)\n",
        "                    print(msg)\n",
        "    result = fal_client.subscribe(\n",
        "        FAL_SAM_MODEL_ID,\n",
        "        arguments={\n",
        "            \"image_url\": image_data_url,\n",
        "            \"text_prompt\": category,\n",
        "            \"apply_mask\": False,\n",
        "            \"return_multiple_masks\": False,\n",
        "            \"max_masks\": 1,\n",
        "            \"output_format\": \"png\",\n",
        "            \"sync_mode\": True,\n",
        "        },\n",
        "        with_logs=True,\n",
        "        on_queue_update=_on_queue,\n",
        "    )\n",
        "    return _extract_masks_from_result(result)\n",
        "\n",
        "def generate_mask_with_gemini(base_img_path: str, garment_folder: str, *, mask_variant: str | None = None):\n",
        "    cache_key = (base_img_path, garment_folder, mask_variant or \"primary\")\n",
        "    if cache_key in MASK_CACHE:\n",
        "        return MASK_CACHE[cache_key]\n",
        "    if not FAL_KEY:\n",
        "        raise ValueError(\"Set FAL_KEY variable for fal.ai SAM3 segmentation.\")\n",
        "    category = _garment_category_from_path(garment_folder)\n",
        "    prompt_category = str(category).strip()\n",
        "    main_class = _classify_garment_category(category)\n",
        "    if mask_variant:\n",
        "        prompt_category = f\"{prompt_category} ({mask_variant})\"\n",
        "        if \"sec\" in str(mask_variant).lower() and main_class:\n",
        "            if main_class == \"top\":\n",
        "                prompt_category = \"bottom garment\"\n",
        "            elif main_class == \"bottom\":\n",
        "                prompt_category = \"upper clothes\"\n",
        "    prompt_category = prompt_category.rstrip(\"s\") if prompt_category else prompt_category\n",
        "    base_img = Image.open(base_img_path).convert(\"RGB\")\n",
        "    orig_w, orig_h = base_img.size\n",
        "    inf_img = base_img\n",
        "    scale = 1.0\n",
        "    max_side = max(orig_w, orig_h)\n",
        "    if max_side > MASK_MAX_SIZE:\n",
        "        scale = MASK_MAX_SIZE / float(max_side)\n",
        "        inf_img = base_img.resize((max(1, int(orig_w * scale)), max(1, int(orig_h * scale))), Image.Resampling.LANCZOS)\n",
        "\n",
        "    print(f\"Segmentation started for {os.path.basename(base_img_path)} [{prompt_category}] via fal.ai SAM3\")\n",
        "    prompt = _build_mask_prompt(prompt_category, mask_variant)\n",
        "    masks = _fetch_sam_masks(_image_to_data_url(inf_img), prompt)\n",
        "    if not masks:\n",
        "        raise ValueError(\"SAM3 did not return any masks.\")\n",
        "\n",
        "    mask_canvas = None\n",
        "    errors = []\n",
        "    for m in masks:\n",
        "        if not isinstance(m, str):\n",
        "            continue\n",
        "        try:\n",
        "            mask_canvas = _mask_data_to_canvas(m, inf_img.size)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            errors.append(str(e))\n",
        "            continue\n",
        "\n",
        "    if mask_canvas is None:\n",
        "        raise ValueError(f\"SAM3 returned masks but none were usable: {errors}\")\n",
        "\n",
        "    if scale != 1.0:\n",
        "        mask_canvas = mask_canvas.resize((orig_w, orig_h), Image.Resampling.NEAREST)\n",
        "    result = (mask_canvas, f\"sam3:{prompt_category}\")\n",
        "    MASK_CACHE[cache_key] = result\n",
        "    return result\n",
        "\n",
        "print(\"\u2705 SAM3 mask generation ready (fal.ai)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfNf3NHxjMaj"
      },
      "outputs": [],
      "source": [
        "# Colab cell \u2014 output routing + metadata helpers\n",
        "import os, json\n",
        "from PIL import PngImagePlugin\n",
        "\n",
        "def ensure_dir(p):\n",
        "    os.makedirs(p, exist_ok=True); return p\n",
        "\n",
        "ensure_dir(OUTPUT_DIR)\n",
        "\n",
        "def build_output_filename(sku_name: str, angle_code: str, ext=\".png\", suffix=\"\") -> str:\n",
        "    # Examples: SS-12345-fr_rght or SS-12345-bc_lft\n",
        "    angle_clean = _norm_angle(angle_code)\n",
        "    suffix = suffix or \"\"\n",
        "    return f\"{sku_name}-{angle_clean}{suffix}{ext}\"\n",
        "\n",
        "\n",
        "import json, piexif\n",
        "from PIL import Image\n",
        "\n",
        "def save_png_with_metadata(img, out_path, details_payload=None, quality=95):\n",
        "    if details_payload:\n",
        "        # Encode JSON as UTF-8 with an ASCII prefix per EXIF spec for UserComment\n",
        "        payload = json.dumps(details_payload, ensure_ascii=False).encode(\"utf-8\")\n",
        "        user_comment = b\"ASCII\\x00\\x00\\x00\" + payload  # indicates undefined/UTF-8\n",
        "        exif_dict = {\"0th\": {}, \"Exif\": {piexif.ExifIFD.UserComment: user_comment}, \"1st\": {}, \"GPS\": {}, \"Interop\": {}}\n",
        "        exif_bytes = piexif.dump(exif_dict)\n",
        "        img.save(out_path, format=\"PNG\", exif=exif_bytes)\n",
        "    else:\n",
        "        img.save(out_path, format=\"PNG\")\n",
        "\n",
        "import json, piexif\n",
        "from PIL import Image, ImageOps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBN_kgOo_GRI"
      },
      "outputs": [],
      "source": [
        "# --- Google APIs: gspread + Drive upload (Operations sync removed) ---\n",
        "\n",
        "import google.auth\n",
        "SCOPES = [\"https://www.googleapis.com/auth/drive\", \"https://www.googleapis.com/auth/spreadsheets\"]\n",
        "creds, _ = google.auth.default(scopes=SCOPES)\n",
        "\n",
        "import gspread\n",
        "gs = gspread.authorize(creds)\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "drive_svc = build(\"drive\", \"v3\", credentials=creds)\n",
        "\n",
        "FOLDER_MIME   = \"application/vnd.google-apps.folder\"\n",
        "SHORTCUT_MIME = \"application/vnd.google-apps.shortcut\"\n",
        "PATH_PREFIX   = \"/content/drive/MyDrive/\"\n",
        "\n",
        "def _escape_name(name: str) -> str: return name.replace(\"'\", r\"'\")\n",
        "\n",
        "def _maybe_follow_shortcut(file_obj):\n",
        "    if file_obj.get(\"mimeType\") == SHORTCUT_MIME:\n",
        "        sd = file_obj.get(\"shortcutDetails\", {}) or {}\n",
        "        return sd.get(\"targetId\"), sd.get(\"targetMimeType\")\n",
        "    return file_obj.get(\"id\"), file_obj.get(\"mimeType\")\n",
        "\n",
        "def _list_children(parent_id: str, q_extra: str, page_size: int = 1000):\n",
        "    q = f\"'{parent_id}' in parents and trashed = false\"\n",
        "    if q_extra: q += f\" and ({q_extra})\"\n",
        "    resp = drive_svc.files().list(\n",
        "        q=q, spaces=\"drive\", pageSize=page_size,\n",
        "        fields=\"files(id,name,mimeType,shortcutDetails)\",\n",
        "        includeItemsFromAllDrives=True, supportsAllDrives=True,\n",
        "    ).execute()\n",
        "    return resp.get(\"files\", [])\n",
        "\n",
        "def _find_folder_id(parent_id: str, name: str):\n",
        "    files = _list_children(\n",
        "        parent_id,\n",
        "        q_extra=(\n",
        "            f\"name = '{_escape_name(name)}' and \"\n",
        "            f\"(mimeType = '{FOLDER_MIME}' or mimeType = '{SHORTCUT_MIME}')\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Direct folder match\n",
        "    for f in files:\n",
        "        if f[\"mimeType\"] == FOLDER_MIME:\n",
        "            return f[\"id\"]\n",
        "\n",
        "    # Shortcut to folder\n",
        "    for f in files:\n",
        "        if f[\"mimeType\"] == SHORTCUT_MIME:\n",
        "            tid, tmime = _maybe_follow_shortcut(f)\n",
        "            if tmime == FOLDER_MIME:\n",
        "                return tid\n",
        "\n",
        "    # Fallback: match by case-insensitive name\n",
        "    files = _list_children(\n",
        "        parent_id,\n",
        "        q_extra=(\n",
        "            f\"(mimeType = '{FOLDER_MIME}' or mimeType = '{SHORTCUT_MIME}')\"\n",
        "        ),\n",
        "    )\n",
        "    needle = name.strip().casefold()\n",
        "\n",
        "    for f in files:\n",
        "        if f.get(\"name\", \"\").strip().casefold() == needle:\n",
        "            tid, tmime = _maybe_follow_shortcut(f)\n",
        "            if tmime == FOLDER_MIME:\n",
        "                return tid\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def _resolve_parent_id_and_filename_from_colab_path(colab_path: str):\n",
        "    if not colab_path.startswith(PATH_PREFIX):\n",
        "        raise ValueError(\n",
        "            f\"This helper supports only '{PATH_PREFIX}...'. Got: {colab_path}\"\n",
        "        )\n",
        "\n",
        "    parts = colab_path[len(PATH_PREFIX):].strip(\"/\").split(\"/\")\n",
        "    if not parts:\n",
        "        raise ValueError(\"Path must include a file name.\")\n",
        "\n",
        "    parent_id = \"root\"\n",
        "\n",
        "    for part in parts[:-1]:\n",
        "        next_id = _find_folder_id(parent_id, part)\n",
        "        if not next_id:\n",
        "            raise FileNotFoundError(f\"Folder not found in path: '{part}'\")\n",
        "        parent_id = next_id\n",
        "\n",
        "    desired_name = parts[-1]\n",
        "    return parent_id, desired_name\n",
        "\n",
        "\n",
        "def upload_to_drive_folder(\n",
        "    local_path: str,\n",
        "    parent_folder_id: str,\n",
        "    desired_name: str | None = None\n",
        "):\n",
        "    media = MediaFileUpload(local_path, resumable=True)\n",
        "    body = {\n",
        "        \"name\": desired_name or os.path.basename(local_path),\n",
        "        \"parents\": [parent_folder_id],\n",
        "    }\n",
        "\n",
        "    file = (\n",
        "        drive_svc.files()\n",
        "        .create(\n",
        "            body=body,\n",
        "            media_body=media,\n",
        "            fields=\"id, webViewLink, name, parents\",\n",
        "            supportsAllDrives=True,\n",
        "        )\n",
        "        .execute()\n",
        "    )\n",
        "\n",
        "    drive_svc.permissions().create(\n",
        "        fileId=file[\"id\"],\n",
        "        body={\"type\": \"anyone\", \"role\": \"reader\"},\n",
        "        fields=\"id\",\n",
        "        supportsAllDrives=True,\n",
        "    ).execute()\n",
        "\n",
        "    return file\n",
        "\n",
        "\n",
        "def upload_file_and_append_to_sheet(\n",
        "    local_path: str,\n",
        "    target_colab_path: str,\n",
        "    sku_name: str,\n",
        "    angle: str,\n",
        "    spreadsheet_id: str | None,\n",
        "    worksheet_name: str | None,\n",
        "):\n",
        "    parent_id, desired_name = _resolve_parent_id_and_filename_from_colab_path(\n",
        "        target_colab_path\n",
        "    )\n",
        "\n",
        "    uploaded = upload_to_drive_folder(local_path, parent_id, desired_name)\n",
        "    file_id = uploaded[\"id\"]\n",
        "\n",
        "    file_url = (\n",
        "        uploaded.get(\"webViewLink\")\n",
        "        or f\"https://drive.google.com/file/d/{file_id}/view?usp=sharing\"\n",
        "    )\n",
        "    folder_url = f\"https://drive.google.com/drive/folders/{parent_id}\"\n",
        "\n",
        "    if spreadsheet_id and worksheet_name:\n",
        "        ts = datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%m-%d %H:%M:%S\")\n",
        "        uid = str(uuid.uuid4())\n",
        "\n",
        "        sh = gs.open_by_key(spreadsheet_id)\n",
        "        ws = sh.worksheet(worksheet_name)\n",
        "\n",
        "        sku_cell = f'=HYPERLINK(\"{folder_url}\"; \"{sku_name}\")'\n",
        "\n",
        "        ws.append_row(\n",
        "            [\n",
        "                sku_cell,\n",
        "                angle,\n",
        "                ts,\n",
        "                file_url,\n",
        "                uid,\n",
        "                \"Girls need to check\",\n",
        "                OPERATOR,\n",
        "            ],\n",
        "            value_input_option=\"USER_ENTERED\",\n",
        "        )\n",
        "\n",
        "    return {\"file_url\": file_url}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DETAILER SETUP + UTILS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdvcT9PEO5ye"
      },
      "source": [
        "#SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNmBx946B-JK",
        "outputId": "d7a0b5e1-b424-4d84-c4d5-58fb1f726244"
      },
      "outputs": [],
      "source": [
        "import os, sys, torch, numpy as np, cv2, base64, gc, json\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "from PIL import Image, ImageOps\n",
        "import piexif\n",
        "\n",
        "CPU_DEVICE = torch.device(\"cpu\")\n",
        "GPU_DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else CPU_DEVICE\n",
        "\n",
        "device = torch.device(DEVICE_STR if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"\u2705 Torch device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "0ce3dbfa3a114d988fc62b6c9ed98aab",
            "11517e487afa473abac383b9efaa5c7b",
            "7028b59f4d5c4166b1769e140ef386fd",
            "0a73f3bacea845379e0b6a927c9dea7e",
            "1fcf083bbf954ff1bf37ada3cd3c30d5",
            "4fd93a4cd2de46bd9d15a4755ae12102",
            "a51521be386846eda04d2bdf520d52f7",
            "0888c84d331d4452a5cce6d6afda14e0",
            "7c5e63df2c3c4144a95b83877d2e622a",
            "0b14e06815a64828b6c1bed44b72e7d4",
            "f5962d2c47cd4fe286c17bd62f62aadb"
          ]
        },
        "id": "azEqfSb-5p5F",
        "outputId": "05277307-ad6b-4572-ed41-3b6d82663ec2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import Sam3Processor, Sam3Model\n",
        "\n",
        "HF_SAM3_ID = \"facebook/sam3\"\n",
        "SAM3_CONFIDENCE = 0.05   # permissive to catch small logos; raise if predictions get noisy\n",
        "SAM3_RESOLUTION = 1024\n",
        "SAM3_PREFERRED_DEVICE = GPU_DEVICE  # pin SAM3 to CPU to avoid VRAM pressure\n",
        "SAM3_DEVICE = CPU_DEVICE  # keep SAM3 on CPU until needed to leave VRAM for insert-anything\n",
        "\n",
        "sam3_processor = Sam3Processor.from_pretrained(HF_SAM3_ID)\n",
        "sam3_model = Sam3Model.from_pretrained(HF_SAM3_ID).to(SAM3_DEVICE)\n",
        "sam3_model.eval()\n",
        "print(f\"\u2705 HF SAM3 ready (current device: {SAM3_DEVICE}, preferred: {SAM3_PREFERRED_DEVICE})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "dccaf990377b4690aae829d03ed302de",
            "908d7b1661bc4a5aaf3108983819b5a9",
            "71175ff97e9a43c3bac1cbc72e5060bd",
            "48f01c245c4542a6868c340fb08382f7",
            "7c585665999144f2b0611eff8248cdd8",
            "e1df25f9b36f45698c6efb70f8310fb7",
            "24bfa48a0cc74f8ca850c0d6217f1d1d",
            "100f33513f2246ae89d0da72f0fb5108",
            "bf58709f69434605a871dbd8eed256a9",
            "d55fff92fd05430cac0d0dca873efa3d",
            "ae4b4886a23e4230b44446164474360a",
            "9541658b7f32499eb83d1f34f1a99829",
            "81b2e62a17d04660a6bf0131d0184d78",
            "535f81d037ed40859bfb0855f1a7fac1",
            "16ac3d25bc8a4fb4aba749a92251bde6",
            "f0b8247247aa4cf7974b9f502ba79c5d",
            "a2cdfa3fcae2497085e7e3ed23742de6",
            "2ab9416431a44ad9abc207f994d3b0b5",
            "ad7a42121b584cd0bd83f8dcf3360f69",
            "e4cb80f7ca3c4669b8eb97018473de19",
            "56ded5613f224feaaf90f20bb65c76a9",
            "52564325ca684d0c9ed39bb4e75d5829",
            "2b09b1b42cdb491aa3c75dd8570ff564",
            "5e4a887fd9e64c209346b02c675e44a1",
            "c11c0f061ccc4a04a8c3bdd12a190eda",
            "011ebf3383414757aeaaff9e37c0d3c0",
            "e646a855f00c430ab191a01a223abe77",
            "63db910c289f4bc09566d763ba2332ec",
            "c3f3b06c97d94390ac064e6d91969cad",
            "4cd604395db940f792a8fe97d7e959a0",
            "b82a6335abb74cb5b4985a9da8ae2018",
            "944a41be57094812b61f7e84bcf3fbd7",
            "a957690fe34f4d60b9b75df9e9205396",
            "4723b5d76a5f4406a454c777e040d321",
            "ce9d5c9bb4434dd6b6108293e895e87c",
            "106b9309c97943c393427cfb230e4bd1",
            "19e597fba5b042a7bd4f98ef29c6a1c1",
            "7cfbfb55d60240e28751df0f8f988f5a",
            "d269690bf0724663a56053d16447472b",
            "4e8984a1507e4049903e8068fe0ba6fb",
            "85197b3ff708441fb76621de24d9bdef",
            "a807732abb23439ebf7ee0f50eb430ee",
            "71a39ba304254e748a816935b23dc331",
            "2f2eca9f0a8744c89d7eb58a79972823",
            "9526c597587746f4a26be50d4697f2e8",
            "68f54fb0fe1d4b1b8f8a7a803a5748cd",
            "6e889fcd02dd4bababd5337a57cca486",
            "f8c9c744b9eb450292cfaad5b3831c4e",
            "5d240d5e53c849d6b022ba87c1714837",
            "ab9b840ed6a0435f8b7db9e7e209f935",
            "16ba9ff3771a427abdf15eb6ea40aec8",
            "bf4a4eb38715412980ab268c3d98c427",
            "df4fb92d216e42c488109fafb0d67c52",
            "f2ee3ddd56d04477b19e9282b7d9ad87",
            "5bb4b3ef23a84e8f9c9f93af3e3a63a3"
          ]
        },
        "id": "f4e99gLxT3TM",
        "outputId": "eed1411f-1f13-4373-da3d-c05b805365da"
      },
      "outputs": [],
      "source": [
        "#@title Insert_anything on nunchaku\n",
        "%cd /content/insert-anything\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from diffusers import FluxFillPipeline, FluxPriorReduxPipeline\n",
        "from utils.utils import get_bbox_from_mask, expand_bbox, pad_to_square, box2squre, expand_image_mask\n",
        "from nunchaku.models.transformers.transformer_flux import NunchakuFluxTransformer2dModel\n",
        "from datetime import datetime\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "IA_DEVICE = GPU_DEVICE\n",
        "IA_CPU_OFFLOAD = True  # sequential/model CPU offload for ~10GB GPUs; set False to keep models on GPU\n",
        "IA_OFFLOAD_FOLDER = \"/content/ia_offload\"\n",
        "dtype = torch.bfloat16\n",
        "size = (1024, 1024)\n",
        "\n",
        "\n",
        "\n",
        "# Load the pre-trained model and LoRA-for-nunchaku weights\n",
        "# Please replace the paths with your own paths\n",
        "transformer = NunchakuFluxTransformer2dModel.from_pretrained(\"mit-han-lab/svdq-int4-flux.1-fill-dev\")\n",
        "\n",
        "pipe = FluxFillPipeline.from_pretrained(\n",
        "    \"black-forest-labs/FLUX.1-Fill-dev\",\n",
        "    transformer=transformer,\n",
        "    torch_dtype=dtype\n",
        ")\n",
        "\n",
        "\n",
        "transformer.update_lora_params(\n",
        "    path_or_state_dict=\"/content/drive/MyDrive/insert-anything-lora/insert-anything_extracted_lora_rank_256-bf16.safetensors\"\n",
        ")\n",
        "\n",
        "\n",
        "# Adjust the LoRA strength\n",
        "transformer.set_lora_strength(1)\n",
        "\n",
        "redux = FluxPriorReduxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-Redux-dev\").to(dtype=dtype)\n",
        "\n",
        "\n",
        "\n",
        "# The purpose of this code is to reduce the GPU memory usage to 26GB, but it will increase the inference time accordingly.\n",
        "os.environ[\"NNCF_GROUP_SIZE\"] = \"-1\"      # disable token merging\n",
        "\n",
        "if IA_CPU_OFFLOAD:\n",
        "    try:\n",
        "        pipe.enable_model_cpu_offload(gpu_id=0, offload_folder=IA_OFFLOAD_FOLDER)\n",
        "        redux.enable_model_cpu_offload(gpu_id=0, offload_folder=IA_OFFLOAD_FOLDER)\n",
        "    except TypeError:\n",
        "        pipe.enable_model_cpu_offload(gpu_id=0)\n",
        "        redux.enable_model_cpu_offload(gpu_id=0)\n",
        "    IA_DEVICE = GPU_DEVICE\n",
        "    print(\"\u2705 Insert-anything pipelines using model CPU offload (10GB-friendly)\")\n",
        "else:\n",
        "    pipe.to(IA_DEVICE)\n",
        "    redux.to(IA_DEVICE)\n",
        "    print(f\"\u2705 Insert-anything pipelines ready on {IA_DEVICE}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nznhr0CO8xT"
      },
      "source": [
        "# UTILS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5N9LysfFp9c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGxk8vnk5wU9"
      },
      "outputs": [],
      "source": [
        "def open_upright(path) -> Image.Image:\n",
        "    with Image.open(path) as im:\n",
        "        return ImageOps.exif_transpose(im).convert(\"RGB\")\n",
        "\n",
        "def open_source_with_black_bg(path: str) -> Image.Image:\n",
        "    im = Image.open(path)\n",
        "    im = ImageOps.exif_transpose(im)\n",
        "    name_low = os.path.basename(path).lower()\n",
        "    if \"_cut\" in name_low and im.mode in (\"RGBA\",\"LA\"):\n",
        "        rgb = im.convert(\"RGB\")\n",
        "        alpha = im.getchannel(\"A\")\n",
        "        black = Image.new(\"RGB\", im.size, (0,0,0))\n",
        "        return Image.composite(rgb, black, alpha)\n",
        "    return im.convert(\"RGB\")\n",
        "\n",
        "\n",
        "# NEW \u2014 root of subcategory-wide garment masks\n",
        "MASKS_ROOT = MASKS_ROOT  # reuse configured masks root\n",
        "MASK_EXTS = ('.png', '.jpg', '.jpeg', '.webp', '.PNG', '.JPG', '.JPEG', '.WEBP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps, ImageDraw\n",
        "\n",
        "# --- Helper: get <Category>/<Subcategory> from the *source* path ------------\n",
        "_SKU_DIR_RE = re.compile(r\"SS-\\d{3,7}\", re.IGNORECASE)\n",
        "\n",
        "def _category_subcategory_from_source(src_path: str) -> tuple[str, str] | None:\n",
        "    \"\"\"\n",
        "    Resolve (Category, Subcategory) from the garment *source* path.\n",
        "    Preferred: relative to WORKING_DIR \u2192 parts[0], parts[1].\n",
        "    Fallback: find the SKU folder in the path and take the two parents.\n",
        "    Returns None if not resolvable.\n",
        "    \"\"\"\n",
        "    p = Path(src_path).resolve()\n",
        "    wr = Path(WORKING_DIR).resolve()\n",
        "\n",
        "    # Preferred: relative to WORKING_DIR\n",
        "    try:\n",
        "        rel = p.relative_to(wr)\n",
        "        parts = rel.parts\n",
        "        # Expect: Category/Subcategory/SKU/<file>\n",
        "        if len(parts) >= 3:\n",
        "            return parts[0], parts[1]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Fallback: locate the SKU dir and take its two parents as Cat/Subcat\n",
        "    parts = p.parts\n",
        "    sku_idx = None\n",
        "    for i, part in enumerate(parts):\n",
        "        if _SKU_DIR_RE.fullmatch(part or \"\"):\n",
        "            sku_idx = i\n",
        "            break\n",
        "    if sku_idx is not None and sku_idx >= 2:\n",
        "        return parts[sku_idx - 2], parts[sku_idx - 1]\n",
        "\n",
        "    # Last resort: try after an explicit 'SikSilk' anchor\n",
        "    if \"SikSilk\" in parts:\n",
        "        j = parts.index(\"SikSilk\")\n",
        "        if len(parts) >= j + 3:\n",
        "            return parts[j + 1], parts[j + 2]\n",
        "\n",
        "    return None\n",
        "\n",
        "# --- New: derive mask basename from *angle*, not from filename heuristics ----\n",
        "def _mask_basename_from_angle(angle_code: str | None) -> str | None:\n",
        "    \"\"\"\n",
        "    Map 'fr' -> 'fr_mask', 'fr_lft' -> 'fr_lft_mask', 'bc_cl' -> 'bc_cl_mask', etc.\n",
        "    If angle_code is missing, return None (\u2192 no mask).\n",
        "    \"\"\"\n",
        "    if not angle_code:\n",
        "        return None\n",
        "    angle = angle_code.strip().lower()\n",
        "    return f\"{angle}_mask\"\n",
        "\n",
        "# --- Exact-only mask finder ---------------------------------------------------\n",
        "\n",
        "def find_mask_for_generated_exact(gen_path: str, source_path: str) -> Path | None:\n",
        "    \"\"\"\n",
        "    EXACT lookup (no fuzzy fallbacks):\n",
        "      angle  = parsed from queued filename/path (e.g., SS-12345_fr_cl.* -> 'fr_cl')\n",
        "      (cat, subcat) = derived from source_path\n",
        "      priority: <angle>_mask_agnostic.<ext>  \u2192  <angle>_mask.<ext>\n",
        "      searched in: MASKS_ROOT / cat / subcat\n",
        "    \"\"\"\n",
        "    # 1) angle from queued filename\n",
        "    _, angle = extract_sku_and_angle_from_path(gen_path)\n",
        "    if not angle:\n",
        "        print(\"\u26a0\ufe0f  No angle parsed \u2014 proceeding without a mask.\")\n",
        "        return None\n",
        "    angle = angle.strip().lower()\n",
        "\n",
        "    # 2) category/subcategory from source path\n",
        "    cat_sub = _category_subcategory_from_source(source_path)\n",
        "    if not cat_sub:\n",
        "        print(\"\u26a0\ufe0f  Could not resolve Category/Subcategory from source path \u2014 no mask.\")\n",
        "        return None\n",
        "    category, subcategory = cat_sub\n",
        "\n",
        "    mask_dir = Path(MASKS_ROOT) / category / subcategory\n",
        "\n",
        "    # 3) Try agnostic first, then regular; exact names only\n",
        "    candidates = [f\"{angle}_mask_agnostic\", f\"{angle}_mask\"]\n",
        "\n",
        "    for name in candidates:\n",
        "        for ext in MASK_EXTS:\n",
        "            cand = mask_dir / f\"{name}{ext}\"\n",
        "            if cand.exists():\n",
        "                which = \"agnostic\" if name.endswith(\"_agnostic\") else \"regular\"\n",
        "                print(f\"\u2705 Found {which} mask: {cand}\")\n",
        "                return cand\n",
        "\n",
        "    print(f\"\u26a0\ufe0f  No exact mask found in {mask_dir} for angle '{angle}' \"\n",
        "          f\"(tried {candidates} with MASK_EXTS). Proceeding without mask.\")\n",
        "    return None\n",
        "\n",
        "def load_binary_mask_for_generated(gen_path: str, source_path: str, gen_img: Image.Image) -> np.ndarray | None:\n",
        "    mp = find_mask_for_generated_exact(gen_path, source_path)\n",
        "    if mp is None:\n",
        "        return None\n",
        "    with Image.open(mp) as m:\n",
        "        m = ImageOps.exif_transpose(m)\n",
        "        return align_mask_to_image(m, gen_img)\n",
        "\n",
        "# --- Align (unchanged) --------------------------------------------------------\n",
        "def align_mask_to_image(mask_img: Image.Image, target_img: Image.Image) -> np.ndarray:\n",
        "    mw, mh = mask_img.size\n",
        "    tw, th = target_img.size\n",
        "    if mh == th and mw > 0 and (tw % mw) == 0 and 1 < (tw // mw) <= 3:\n",
        "        k = tw // mw\n",
        "        tiled = Image.new('L', (tw, th), 0)\n",
        "        src = mask_img.convert('L')\n",
        "        for i in range(k):\n",
        "            tiled.paste(src, (i * mw, 0))\n",
        "        M = np.array(tiled, dtype=np.uint8)\n",
        "    else:\n",
        "        if mw == 0 or mh == 0:\n",
        "            return np.zeros((th, tw), np.uint8)\n",
        "        scale = max(mw / tw, mh / th)\n",
        "        new_w = int(round(mw / scale)); new_h = int(round(mh / scale))\n",
        "        m_resized = mask_img.convert('L').resize((new_w, new_h), Image.NEAREST)\n",
        "        M = np.zeros((th, tw), np.uint8)\n",
        "        x0 = (tw - new_w) // 2; y0 = (th - new_h) // 2\n",
        "        M[y0:y0+new_h, x0:x0+new_w] = np.array(m_resized, dtype=np.uint8)\n",
        "    return ((M > 127).astype(np.uint8) * 255)\n",
        "\n",
        "\n",
        "def enlarge_mask(mask_np: np.ndarray, scale: float = 1.05) -> np.ndarray:\n",
        "    \"\"\"Dilate mask outward based on object size (\u2248scale of the foreground).\"\"\"\n",
        "    if mask_np is None:\n",
        "        return None\n",
        "    mask = (mask_np > 0).astype(np.uint8)\n",
        "    ys, xs = np.where(mask)\n",
        "    if ys.size == 0 or scale <= 1.0:\n",
        "        return (mask_np > 0).astype(np.uint8) * 255\n",
        "    h_obj = ys.max() - ys.min() + 1\n",
        "    w_obj = xs.max() - xs.min() + 1\n",
        "    grow = max(1, int(round(max(h_obj, w_obj) * (scale - 1.0))))\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (grow * 2 + 1, grow * 2 + 1))\n",
        "    out = cv2.dilate(mask, kernel, iterations=1)\n",
        "    return (out > 0).astype(np.uint8) * 255\n",
        "\n",
        "\n",
        "\n",
        "# ---- visuals\n",
        "def _draw_bbox(img: Image.Image, bb_xyxy, color=\"lime\", width=4):\n",
        "    out = img.copy()\n",
        "    if bb_xyxy is None: return out\n",
        "    draw = ImageDraw.Draw(out)\n",
        "    draw.rectangle(bb_xyxy, outline=color, width=width)\n",
        "    return out\n",
        "\n",
        "def _show_images(pairs, cols=3, figsize=(16,12)):\n",
        "    rows = int(np.ceil(len(pairs) / cols))\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "    axes = axes.flatten() if rows*cols>1 else [axes]\n",
        "    for ax,(title,img) in zip(axes, pairs):\n",
        "        ax.imshow(img); ax.set_title(title, fontsize=10); ax.axis(\"off\")\n",
        "    for ax in axes[len(pairs):]: ax.axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def resize_and_pad(image, target_size=1024):\n",
        "    w, h = image.size\n",
        "    scale = target_size / max(1, max(w, h))\n",
        "    new_w, new_h = int(round(w * scale)), int(round(h * scale))\n",
        "    image_resized = image.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "    pad_w = (target_size - new_w) // 2\n",
        "    pad_h = (target_size - new_h) // 2\n",
        "    padding = (pad_w, pad_h, target_size - new_w - pad_w, target_size - new_h - pad_h)\n",
        "\n",
        "    # \u2705 Match fill type to mode\n",
        "    mode = image_resized.mode\n",
        "    if mode in (\"L\", \"1\", \"I\", \"F\"):\n",
        "        fill_color = 0                      # int for single-channel\n",
        "    elif mode == \"RGBA\":\n",
        "        fill_color = (0, 0, 0, 0)           # transparent for RGBA\n",
        "    else:\n",
        "        fill_color = (0, 0, 0)              # RGB tuple for RGB/others\n",
        "\n",
        "    return ImageOps.expand(image_resized, padding, fill=fill_color)\n",
        "\n",
        "def box_1024_to_original(box_xyxy_1024, original_w, original_h):\n",
        "    x1_1024, y1_1024, x2_1024, y2_1024 = [float(v) for v in box_xyxy_1024]\n",
        "    target_size = 1024\n",
        "    w, h = original_w, original_h\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(round(w*scale)), int(round(h*scale))\n",
        "    pad_w = (target_size - new_w)//2\n",
        "    pad_h = (target_size - new_h)//2\n",
        "    x1 = (x1_1024 - pad_w) / scale; x2 = (x2_1024 - pad_w) / scale\n",
        "    y1 = (y1_1024 - pad_h) / scale; y2 = (y2_1024 - pad_h) / scale\n",
        "    x1 = min(max(int(round(x1)),0), w); x2 = min(max(int(round(x2)),0), w)\n",
        "    y1 = min(max(int(round(y1)),0), h); y2 = min(max(int(round(y2)),0), h)\n",
        "    return [x1,y1,x2,y2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TD4abQU5yio"
      },
      "outputs": [],
      "source": [
        "def apply_binary_mask(img_rgb: Image.Image, mask_np: np.ndarray | None, outside_color=(5,5,5)) -> Image.Image:\n",
        "    if mask_np is None:\n",
        "        return img_rgb\n",
        "    mask_L = Image.fromarray(mask_np.astype(np.uint8))\n",
        "    mode = img_rgb.mode\n",
        "    if mode not in (\"RGB\", \"RGBA\", \"L\"):\n",
        "        img_rgb = img_rgb.convert(\"RGB\")\n",
        "        mode = \"RGB\"\n",
        "    if mode == \"RGB\":\n",
        "        if isinstance(outside_color, int):\n",
        "            outside_color = (outside_color,) * 3\n",
        "        bg = Image.new(\"RGB\", img_rgb.size, outside_color)\n",
        "    elif mode == \"RGBA\":\n",
        "        if isinstance(outside_color, int):\n",
        "            outside_color = (outside_color,) * 3 + (255,)\n",
        "        elif len(outside_color) == 3:\n",
        "            outside_color = (*outside_color, 255)\n",
        "        bg = Image.new(\"RGBA\", img_rgb.size, outside_color)\n",
        "    else:\n",
        "        if isinstance(outside_color, tuple):\n",
        "            outside_color = int(np.mean(outside_color))\n",
        "        bg = Image.new(\"L\", img_rgb.size, int(outside_color))\n",
        "    return Image.composite(img_rgb, bg, mask_L)\n",
        "\n",
        "\n",
        "# Dynamic, perimeter-based mask gating for detect_detail (logo-friendly)\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "\n",
        "# --- VRAM juggling to avoid SAM3 + IA sharing GPU at the same time ----------------\n",
        "if \"IA_DEVICE\" not in globals():\n",
        "    IA_DEVICE = GPU_DEVICE\n",
        "\n",
        "def _move_sam3_to(target: torch.device):\n",
        "    global SAM3_DEVICE\n",
        "    target = torch.device(target)\n",
        "    if target.type == \"cuda\" and not torch.cuda.is_available():\n",
        "        target = CPU_DEVICE\n",
        "    if SAM3_DEVICE == target:\n",
        "        return\n",
        "    sam3_model.to(target)\n",
        "    SAM3_DEVICE = target\n",
        "    if target.type == \"cpu\":\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "\n",
        "def _move_insert_anything_to(target: torch.device):\n",
        "    global IA_DEVICE\n",
        "    target = torch.device(target)\n",
        "    if target.type == \"cuda\" and not torch.cuda.is_available():\n",
        "        target = CPU_DEVICE\n",
        "    if IA_CPU_OFFLOAD:\n",
        "        IA_DEVICE = GPU_DEVICE if target.type == \"cuda\" else CPU_DEVICE\n",
        "        return\n",
        "    if IA_DEVICE == target:\n",
        "        return\n",
        "    pipe.to(target)\n",
        "    redux.to(target)\n",
        "    IA_DEVICE = target\n",
        "    if target.type == \"cpu\":\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "\n",
        "def _prepare_for_sam3():\n",
        "    global IA_DEVICE\n",
        "    if IA_CPU_OFFLOAD:\n",
        "        _move_sam3_to(SAM3_PREFERRED_DEVICE)\n",
        "        IA_DEVICE = GPU_DEVICE\n",
        "        return\n",
        "    _move_insert_anything_to(CPU_DEVICE)\n",
        "    _move_sam3_to(SAM3_PREFERRED_DEVICE)\n",
        "\n",
        "\n",
        "def _prepare_for_insert_anything():\n",
        "    global IA_DEVICE\n",
        "    if IA_CPU_OFFLOAD:\n",
        "        _move_sam3_to(CPU_DEVICE)\n",
        "        IA_DEVICE = GPU_DEVICE\n",
        "        return\n",
        "    _move_sam3_to(CPU_DEVICE)\n",
        "    _move_insert_anything_to(GPU_DEVICE)\n",
        "\n",
        "\n",
        "# --- SAM3 helpers -----------------------------------------------------------\n",
        "def _clip_box_to_image(box_xyxy, w: int, h: int):\n",
        "    x1, y1, x2, y2 = box_xyxy\n",
        "    x1 = max(0, min(w, int(round(x1))))\n",
        "    y1 = max(0, min(h, int(round(y1))))\n",
        "    x2 = max(0, min(w, int(round(x2))))\n",
        "    y2 = max(0, min(h, int(round(y2))))\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "\n",
        "def _sam3_predict_text(image_pil: Image.Image, prompt: str, *, max_dets: int = 12, score_threshold: float = SAM3_CONFIDENCE):\n",
        "    \"\"\"Run SAM3 (HF) with a text prompt and return sorted predictions.\"\"\"\n",
        "    if not prompt:\n",
        "        return []\n",
        "    if \"sam3_processor\" not in globals() or \"sam3_model\" not in globals():\n",
        "        raise RuntimeError(\"SAM3 is not initialized. Run the SAM3 setup cell first.\")\n",
        "\n",
        "    inputs = sam3_processor(images=image_pil, text=prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(SAM3_DEVICE) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = sam3_model(**inputs)\n",
        "\n",
        "    processed = sam3_processor.post_process_instance_segmentation(\n",
        "        outputs,\n",
        "        threshold=score_threshold,\n",
        "        target_sizes=[image_pil.size[::-1]],\n",
        "    )[0]\n",
        "\n",
        "    boxes = processed.get(\"boxes\")\n",
        "    scores = processed.get(\"scores\")\n",
        "    masks = processed.get(\"masks\")\n",
        "    if boxes is None or scores is None or boxes.numel() == 0:\n",
        "        return []\n",
        "\n",
        "    boxes_np = boxes.detach().cpu().numpy()\n",
        "    scores_np = scores.detach().cpu().numpy()\n",
        "    masks_np = masks.detach().cpu().numpy() if masks is not None else None\n",
        "\n",
        "    order = scores_np.argsort()[::-1]\n",
        "    preds = []\n",
        "    for idx in order[:max_dets]:\n",
        "        mask_np = None\n",
        "        if masks_np is not None:\n",
        "            mask_np = (masks_np[idx] > 0.5).astype(np.uint8)\n",
        "        preds.append({\n",
        "            \"box\": boxes_np[idx].tolist(),\n",
        "            \"score\": float(scores_np[idx]),\n",
        "            \"mask\": mask_np,\n",
        "        })\n",
        "    return preds\n",
        "\n",
        "def _mask_crop_to_full(mask_crop: np.ndarray | None, crop_box_on_full, full_size):\n",
        "    \"\"\"\n",
        "    Place a mask (aligned to a crop image) back onto the full canvas.\n",
        "    crop_box_on_full = (lx, ty, rx, by) used to produce the crop.\n",
        "    full_size = (W, H) of the destination image.\n",
        "    \"\"\"\n",
        "    if mask_crop is None or crop_box_on_full is None:\n",
        "        return mask_crop\n",
        "\n",
        "    full_w, full_h = full_size\n",
        "    lx, ty, rx, by = [int(round(v)) for v in crop_box_on_full]\n",
        "    x0, y0 = max(0, lx), max(0, ty)\n",
        "    x1, y1 = min(rx, full_w), min(by, full_h)\n",
        "    if x1 <= x0 or y1 <= y0:\n",
        "        return np.zeros((full_h, full_w), np.uint8)\n",
        "\n",
        "    mx0, my0 = max(0, -lx), max(0, -ty)\n",
        "    mx1, my1 = mx0 + (x1 - x0), my0 + (y1 - y0)\n",
        "\n",
        "    patch = mask_crop[my0:my1, mx0:mx1]\n",
        "    if patch.shape[1] != (x1 - x0) or patch.shape[0] != (y1 - y0):\n",
        "        patch = cv2.resize(patch, (x1 - x0, y1 - y0), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    full_mask = np.zeros((full_h, full_w), np.uint8)\n",
        "    full_mask[y0:y1, x0:x1] = (patch > 0).astype(np.uint8) * 255\n",
        "    return full_mask\n",
        "\n",
        "\n",
        "# Spatially guided detect_detail:\n",
        "# - perimeter-based mask polarity (as before)\n",
        "# - strict+tolerant mask gates\n",
        "# - spatial prior from source garment (normalized center+area)\n",
        "# - combined score = w_score * norm_score + w_spatial * spatial_affinity\n",
        "\n",
        "\n",
        "# ---- helpers ---------------------------------------------------------------\n",
        "# Top-7 spatial re-ranking for detail detection\n",
        "# - Keeps perimeter-based mask polarity & light gates\n",
        "# - Takes SAM3's highest-scoring proposals, filters with mask gates, then\n",
        "#   re-ranks TOP_K using spatial prior from the SOURCE garment\n",
        "# - Normalizes SAM3 scores within those K and slightly down-weights rank-1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- helpers you already use elsewhere ----------\n",
        "def make_spatial_prior_from_box(bb_xyxy, img_size):\n",
        "    \"\"\"Build prior from SOURCE detail box on its garment crop. Normalized to [0,1].\"\"\"\n",
        "    if bb_xyxy is None:\n",
        "        return None\n",
        "    W, H = img_size\n",
        "    x1, y1, x2, y2 = [float(v) for v in bb_xyxy]\n",
        "    x1 = max(0.0, min(W, x1)); y1 = max(0.0, min(H, y1))\n",
        "    x2 = max(0.0, min(W, x2)); y2 = max(0.0, min(H, y2))\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return None\n",
        "    cx = ((x1 + x2) / 2.0) / max(1.0, W)\n",
        "    cy = ((y1 + y2) / 2.0) / max(1.0, H)\n",
        "    area = ((x2 - x1) * (y2 - y1)) / max(1.0, (W * H))\n",
        "    return {\"cx\": float(cx), \"cy\": float(cy), \"area\": float(area)}\n",
        "\n",
        "def _spatial_affinity(cx_n, cy_n, area_n, prior, mirror_ok=True,\n",
        "                      sigma_center=0.16, sigma_area=0.50):\n",
        "    \"\"\"Gaussian affinity in [0,1] for center & (log)area; mirror-aware.\"\"\"\n",
        "    def _aff(cx_p):\n",
        "        dc2 = (cx_n - cx_p)**2 + (cy_n - prior[\"cy\"])**2\n",
        "        s_center = np.exp(- dc2 / (2.0 * (sigma_center**2)))\n",
        "        a = max(1e-6, area_n); ap = max(1e-6, prior[\"area\"])\n",
        "        dlog = np.log(a / ap)\n",
        "        s_area = np.exp(- (dlog**2) / (2.0 * (sigma_area**2)))\n",
        "        return float(s_center * s_area)\n",
        "    base = _aff(prior[\"cx\"])\n",
        "    if mirror_ok:\n",
        "        return max(base, _aff(1.0 - prior[\"cx\"]))\n",
        "    return base\n",
        "\n",
        "# ---------- main: top-7 re-ranking ----------\n",
        "\n",
        "\n",
        "def _ensure_mask_for_image(mask_input, image_pil, *, crop_box_on_full=None):\n",
        "    \"\"\"\n",
        "    Align a mask to image_pil.\n",
        "\n",
        "    mask_input:\n",
        "      \u2022 np.ndarray aligned to image_pil (H\u00d7W)  OR\n",
        "      \u2022 (mask_full_np, \"FULL\") + crop_box_on_full=(lx,ty,rx,by) from crop_to_square\n",
        "\n",
        "    Returns: uint8 mask (0/255) aligned to image_pil.size, with the same padding\n",
        "    behavior as crop_to_square (i.e., if the crop went outside, we pad zeros).\n",
        "    \"\"\"\n",
        "    if mask_input is None or (isinstance(mask_input, tuple) and len(mask_input)==2 and mask_input[0] is None):\n",
        "        return None\n",
        "\n",
        "    # Case 1: already aligned to this image\n",
        "    if not (isinstance(mask_input, tuple) and len(mask_input) == 2 and isinstance(mask_input[0], np.ndarray) and mask_input[1] == \"FULL\"):\n",
        "        m = mask_input\n",
        "        if m.ndim == 3:\n",
        "            m = m[...,0] if m.shape[2] > 1 else m.squeeze(-1)\n",
        "        if m.dtype != np.uint8:\n",
        "            m = (m > 0).astype(np.uint8) * 255\n",
        "        if (m.shape[1], m.shape[0]) != image_pil.size:\n",
        "            m = cv2.resize(m, image_pil.size, interpolation=cv2.INTER_NEAREST)\n",
        "        return m\n",
        "\n",
        "    # Case 2: FULL mask + crop box from crop_to_square\n",
        "    mask_full, _ = mask_input\n",
        "    assert crop_box_on_full is not None, \"crop_box_on_full is required for FULL mask.\"\n",
        "\n",
        "    Hf, Wf = mask_full.shape[:2]\n",
        "    lx, ty, rx, by = crop_box_on_full  # exactly what crop_to_square returned\n",
        "\n",
        "    # Target canvas (the square side used by crop_to_square)\n",
        "    tgt_w = int(round(rx - lx))\n",
        "    tgt_h = int(round(by - ty))\n",
        "\n",
        "    # Source window (clamped to the full image bounds)\n",
        "    sx1 = int(np.floor(max(0, lx)))\n",
        "    sy1 = int(np.floor(max(0, ty)))\n",
        "    sx2 = int(np.ceil(min(Wf, rx)))\n",
        "    sy2 = int(np.ceil(min(Hf, by)))\n",
        "\n",
        "    # Offsets where the source window lands on the target canvas\n",
        "    dx = int(np.floor(max(0, -lx)))   # same as crop_to_square's dx\n",
        "    dy = int(np.floor(max(0, -ty)))   # same as crop_to_square's dy\n",
        "\n",
        "    # Build canvas and paste the clipped region at (dx,dy)\n",
        "    canvas = np.zeros((tgt_h, tgt_w), dtype=np.uint8)\n",
        "    if sx2 > sx1 and sy2 > sy1:\n",
        "        patch = mask_full[sy1:sy2, sx1:sx2]\n",
        "        if patch.ndim == 3:\n",
        "            patch = patch[...,0] if patch.shape[2] > 1 else patch.squeeze(-1)\n",
        "        ph, pw = patch.shape[:2]\n",
        "        canvas[dy:dy+ph, dx:dx+pw] = (patch > 0).astype(np.uint8) * 255\n",
        "\n",
        "    # If image_pil size differs by a pixel due to rounding, align by resize\n",
        "    if (canvas.shape[1], canvas.shape[0]) != image_pil.size:\n",
        "        canvas = cv2.resize(canvas, image_pil.size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def _build_inside_mask_1024(mask_aligned_np, image_pil, *,\n",
        "                            border_sample_px=2, erode_px=1, dilate_px=2,\n",
        "                            debug=False):\n",
        "    \"\"\"\n",
        "    Build 1024\u00d71024 INSIDE mask with perimeter-based polarity, using the\n",
        "    SAME resize_and_pad as the image to guarantee geometric alignment.\n",
        "    \"\"\"\n",
        "    if mask_aligned_np is None:\n",
        "        return None\n",
        "\n",
        "    # 1) pad the mask to 1024 with the SAME routine as the image\n",
        "    mL = Image.fromarray(mask_aligned_np, mode=\"L\")\n",
        "    m1024L = resize_and_pad(mL, target_size=1024).convert(\"L\")\n",
        "    m1024 = (np.array(m1024L) > 0)\n",
        "\n",
        "    # 2) Perimeter-majority: which value dominates the border?\n",
        "    h, w = m1024.shape\n",
        "    b = max(1, int(border_sample_px))\n",
        "    perim = np.concatenate([m1024[0:b,:].ravel(), m1024[h-b:h,:].ravel(),\n",
        "                            m1024[:,0:b].ravel(), m1024[:,w-b:w].ravel()])\n",
        "    ones = int(perim.sum()); zeros = int(perim.size - perim.sum())\n",
        "    background_is_true = (ones >= zeros)   # majority on border = background\n",
        "    inside = (~m1024) if background_is_true else m1024\n",
        "\n",
        "    # 3) Moprhology for robust gating\n",
        "    if erode_px > 0:\n",
        "        k_e = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_px*2+1, erode_px*2+1))\n",
        "        inside = cv2.erode(inside.astype(np.uint8), k_e, 1).astype(bool)\n",
        "    if dilate_px > 0:\n",
        "        k_d = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_px*2+1, dilate_px*2+1))\n",
        "        inside = cv2.dilate(inside.astype(np.uint8), k_d, 1).astype(bool)\n",
        "\n",
        "    if debug:\n",
        "        bg_txt = \"white/True\" if background_is_true else \"black/False\"\n",
        "        cov = float(inside.mean())\n",
        "        print(f\"[mask1024] perimeter True={ones} False={zeros} \u2192 background={bg_txt}; inside_cov={cov:.3f}\")\n",
        "\n",
        "    return inside\n",
        "\n",
        "\n",
        "def detect_detail_topk7(image_pil: Image.Image,\n",
        "                        detail_type: str,\n",
        "                        *,\n",
        "                        source_prior: dict | None,\n",
        "                        restrict_mask,                 # EITHER aligned np.ndarray OR (mask_full_np, \"FULL\")\n",
        "                        crop_box_on_full=None,         # required if restrict_mask is (\"FULL\")\n",
        "                        threshold: float = 0.05,\n",
        "                        TOP_K: int = 7,\n",
        "                        mirror_ok: bool = True,\n",
        "                        # light mask gates\n",
        "                        min_inside_frac: float = 0.30,\n",
        "                        center_must_be_inside: bool = True,\n",
        "                        erode_px: int = 1,\n",
        "                        dilate_px: int = 2,\n",
        "                        border_sample_px: int = 2,\n",
        "                        # scoring weights\n",
        "                        w_spatial: float = 0.65,\n",
        "                        w_score: float = 0.35,\n",
        "                        rank_weights: list[float] = None,\n",
        "                        debug: bool = False,\n",
        "                        viz: bool = False,\n",
        "                        viz_overlay_mask: bool = True):\n",
        "    \"\"\"\n",
        "    Robust top-7 re-ranking using SAM3 detections and optional mask gates.\n",
        "    Returns (xyxy_on_image, raw_score, mask_on_image or None)\n",
        "    \"\"\"\n",
        "    if rank_weights is None:\n",
        "        rank_weights = [0.92, 1.00, 0.98, 0.97, 0.96, 0.955, 0.95]\n",
        "\n",
        "    W0, H0 = image_pil.size\n",
        "    prompt = (detail_type or \"\").strip() + \".\"\n",
        "\n",
        "    mask_aligned = _ensure_mask_for_image(restrict_mask, image_pil, crop_box_on_full=crop_box_on_full)\n",
        "    mask_bool = (mask_aligned > 0) if mask_aligned is not None else None\n",
        "\n",
        "    preds = _sam3_predict_text(image_pil, prompt, max_dets=max(TOP_K * 3, 12), score_threshold=threshold)\n",
        "    if not preds:\n",
        "        return (None, None, None)\n",
        "\n",
        "    picked = []\n",
        "    for rank, p in enumerate(preds):\n",
        "        if threshold is not None and float(p[\"score\"]) < threshold:\n",
        "            continue\n",
        "        box = _clip_box_to_image(p[\"box\"], W0, H0)\n",
        "        x1, y1, x2, y2 = box\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "\n",
        "        inside_frac = 1.0\n",
        "        center_ok = True\n",
        "        if mask_bool is not None:\n",
        "            crop = mask_bool[y1:y2, x1:x2]\n",
        "            area = max(1, (x2 - x1) * (y2 - y1))\n",
        "            inside_frac = float(crop.sum()) / float(area)\n",
        "            cxp, cyp = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            center_ok = (0 <= cxp < W0 and 0 <= cyp < H0 and bool(mask_bool[cyp, cxp]))\n",
        "            if inside_frac < min_inside_frac or (center_must_be_inside and not center_ok):\n",
        "                continue\n",
        "\n",
        "        picked.append({\n",
        "            \"box\": box,\n",
        "            \"score\": float(p[\"score\"]),\n",
        "            \"rank\": rank,\n",
        "            \"mask\": p[\"mask\"],\n",
        "            \"inside_frac\": inside_frac,\n",
        "        })\n",
        "        if len(picked) >= TOP_K:\n",
        "            break\n",
        "\n",
        "    if not picked:\n",
        "        base = preds[0]\n",
        "        picked = [{\"box\": _clip_box_to_image(base[\"box\"], W0, H0),\n",
        "                   \"score\": float(base[\"score\"]),\n",
        "                   \"rank\": 0,\n",
        "                   \"mask\": base[\"mask\"],\n",
        "                   \"inside_frac\": 0.0}]\n",
        "\n",
        "    s = np.array([p[\"score\"] for p in picked], dtype=np.float32)\n",
        "    s_min, s_max = float(s.min()), float(s.max())\n",
        "    s_norm = np.ones_like(s) * 0.5 if s_max == s_min else (s - s_min) / (s_max - s_min)\n",
        "\n",
        "    best = None\n",
        "    for j, p in enumerate(picked):\n",
        "        rw = rank_weights[p[\"rank\"]] if p[\"rank\"] < len(rank_weights) else rank_weights[-1]\n",
        "        score_normed = float(s_norm[j] * rw)\n",
        "        x1, y1, x2, y2 = p[\"box\"]\n",
        "        area = max(1, (x2 - x1) * (y2 - y1))\n",
        "        cx_n = ((x1 + x2) / 2.0) / max(1.0, W0)\n",
        "        cy_n = ((y1 + y2) / 2.0) / max(1.0, H0)\n",
        "        area_n = area / float(max(1, W0 * H0))\n",
        "        spatial = _spatial_affinity(cx_n, cy_n, area_n, source_prior, mirror_ok=mirror_ok) if source_prior else 0.0\n",
        "        combo = w_spatial * spatial + w_score * score_normed\n",
        "        if best is None or combo > best[\"combo\"]:\n",
        "            best = {**p, \"combo\": float(combo), \"spatial\": float(spatial), \"score_norm\": score_normed}\n",
        "\n",
        "    return best[\"box\"], best[\"score\"], best[\"mask\"]\n",
        "\n",
        "\n",
        "def detect_detail(image_pil: Image.Image,\n",
        "                  detail_type: str,\n",
        "                  threshold: float = 0.05,\n",
        "                  used_boxes=None,\n",
        "                  keep_best: bool = False,\n",
        "                  iou_thr: float = 0.35,\n",
        "                  restrict_mask: np.ndarray | None = None,\n",
        "                  min_inside_frac: float = 0.40,\n",
        "                  max_outside_frac: float = 0.70,\n",
        "                  center_must_be_inside: bool = True,\n",
        "                  erode_px: int = 1,\n",
        "                  dilate_px: int = 2,\n",
        "                  border_sample_px: int = 2,\n",
        "                  debug: bool = False,\n",
        "                  debug_topk: int = 5,\n",
        "                  crop_box_on_full=None):\n",
        "    \"\"\"\n",
        "    Simplified detail locator using SAM3 text grounding.\n",
        "    Returns: (xyxy_on_image, score, mask_on_image)\n",
        "    \"\"\"\n",
        "    used_boxes = used_boxes or []\n",
        "    prompt = (detail_type or \"\").strip() + \".\"\n",
        "    W, H = image_pil.size\n",
        "\n",
        "    mask_aligned = _ensure_mask_for_image(restrict_mask, image_pil, crop_box_on_full=crop_box_on_full)\n",
        "    mask_bool = (mask_aligned > 0) if mask_aligned is not None else None\n",
        "\n",
        "    preds = _sam3_predict_text(image_pil, prompt, max_dets=10, score_threshold=threshold)\n",
        "    if not preds:\n",
        "        return (None, None, None)\n",
        "\n",
        "    def _iou(a, b):\n",
        "        ax1, ay1, ax2, ay2 = a; bx1, by1, bx2, by2 = b\n",
        "        xi1, yi1 = max(ax1, bx1), max(ay1, by1)\n",
        "        xi2, yi2 = min(ax2, bx2), min(ay2, by2)\n",
        "        iw, ih = max(0, xi2 - xi1), max(0, yi2 - yi1)\n",
        "        inter = iw * ih\n",
        "        if inter == 0:\n",
        "            return 0.0\n",
        "        area_a = max(1, (ax2 - ax1) * (ay2 - ay1))\n",
        "        area_b = max(1, (bx2 - bx1) * (by2 - by1))\n",
        "        union = area_a + area_b - inter\n",
        "        return inter / union\n",
        "\n",
        "    best = None\n",
        "    debug_rows = []\n",
        "    for p in preds:\n",
        "        if threshold is not None and float(p[\"score\"]) < threshold:\n",
        "            continue\n",
        "        box = _clip_box_to_image(p[\"box\"], W, H)\n",
        "        x1, y1, x2, y2 = box\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "\n",
        "        if any(_iou(box, ub) > iou_thr for ub in used_boxes):\n",
        "            continue\n",
        "\n",
        "        inside_frac = 1.0\n",
        "        outside_frac = 0.0\n",
        "        center_ok = True\n",
        "        if mask_bool is not None:\n",
        "            crop = mask_bool[y1:y2, x1:x2]\n",
        "            area = max(1, (x2 - x1) * (y2 - y1))\n",
        "            inside_frac = float(crop.sum()) / float(area)\n",
        "            outside_frac = 1.0 - inside_frac\n",
        "            cx_i, cy_i = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            center_ok = (0 <= cx_i < W and 0 <= cy_i < H and bool(mask_bool[cy_i, cx_i])) if center_must_be_inside else True\n",
        "            if not center_ok or inside_frac < min_inside_frac or outside_frac > max_outside_frac:\n",
        "                continue\n",
        "\n",
        "        if best is None or p[\"score\"] > best[\"score\"]:\n",
        "            best = {\"box\": box, \"score\": float(p[\"score\"]), \"mask\": p[\"mask\"], \"inside_frac\": inside_frac}\n",
        "\n",
        "        if debug and len(debug_rows) < debug_topk:\n",
        "            debug_rows.append({\n",
        "                \"score\": float(p[\"score\"]),\n",
        "                \"box\": box,\n",
        "                \"inside\": inside_frac,\n",
        "                \"outside\": outside_frac,\n",
        "                \"center\": center_ok,\n",
        "            })\n",
        "\n",
        "    if best is None:\n",
        "        if keep_best:\n",
        "            base = preds[0]\n",
        "            best = {\"box\": _clip_box_to_image(base[\"box\"], W, H), \"score\": float(base[\"score\"]), \"mask\": base[\"mask\"], \"inside_frac\": 0.0}\n",
        "        else:\n",
        "            if debug:\n",
        "                print(\"[detect_detail] No candidate satisfied mask gates.\")\n",
        "            return (None, None, None)\n",
        "\n",
        "    if debug and debug_rows:\n",
        "        print(\"[detect_detail/debug] top candidates (after score>thr):\")\n",
        "        for row in sorted(debug_rows, key=lambda r: r[\"score\"], reverse=True):\n",
        "            print(f\"  score={row['score']:.3f} inside={row['inside']:.2f} outside={row['outside']:.2f} center={row['center']} box={row['box']}\")\n",
        "\n",
        "    return best[\"box\"], best[\"score\"], best[\"mask\"]\n",
        "\n",
        "\n",
        "def detect_garment_box(img: Image.Image, garment_tag: str, threshold=0.25, restrict_mask: np.ndarray | None = None):\n",
        "    O_W, O_H = img.size\n",
        "    if restrict_mask is not None:\n",
        "        m1024 = resize_and_pad(Image.fromarray(restrict_mask, 'L'), 1024).convert('L')\n",
        "        mask_1024_np = (np.array(m1024) > 127)\n",
        "        ys, xs = np.where(mask_1024_np > 0)\n",
        "        if xs.size == 0 or ys.size == 0:\n",
        "            return None\n",
        "        x1, y1, x2, y2 = [float(xs.min()), float(ys.min()), float(xs.max()), float(ys.max())]\n",
        "        return box_1024_to_original([x1, y1, x2, y2], O_W, O_H)\n",
        "\n",
        "    preds = _sam3_predict_text(img, f\"{garment_tag.strip()} .\", max_dets=6, score_threshold=threshold)\n",
        "    if not preds:\n",
        "        return None\n",
        "\n",
        "    mask_bool = (restrict_mask > 0) if restrict_mask is not None else None\n",
        "    best = None\n",
        "    for p in preds:\n",
        "        if threshold is not None and float(p[\"score\"]) < threshold:\n",
        "            continue\n",
        "        box = _clip_box_to_image(p[\"box\"], O_W, O_H)\n",
        "        if box[2] <= box[0] or box[3] <= box[1]:\n",
        "            continue\n",
        "        if mask_bool is not None:\n",
        "            crop = mask_bool[box[1]:box[3], box[0]:box[2]]\n",
        "            if crop.size == 0 or float(crop.mean()) < 0.05:\n",
        "                continue\n",
        "        if best is None or p[\"score\"] > best[\"score\"]:\n",
        "            best = {\"box\": box, \"score\": float(p[\"score\"])}\n",
        "\n",
        "    return best[\"box\"] if best else None\n",
        "\n",
        "\n",
        "def bbox_to_mask(bb, img_size, pad_px=10):\n",
        "    W, H = img_size\n",
        "    x1, y1, x2, y2 = bb\n",
        "    x1 = max(0, x1 - pad_px); y1 = max(0, y1 - pad_px)\n",
        "    x2 = min(W - 1, x2 + pad_px); y2 = min(H - 1, y2 + pad_px)\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    m[y1:y2, x1:x2] = 255\n",
        "    return m\n",
        "\n",
        "\n",
        "def crop_detail(image_pil, mask_np, bb_xyxy, out_size=1024, pad_px=20):\n",
        "    W, H = image_pil.size\n",
        "    x1, y1, x2, y2 = bb_xyxy\n",
        "    x1 = max(0, x1 - pad_px); y1 = max(0, y1 - pad_px)\n",
        "    x2 = min(W, x2 + pad_px); y2 = min(H, y2 + pad_px)\n",
        "    side = max(x2 - x1, y2 - y1)\n",
        "    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "    lx = max(0, cx - side // 2); rx = lx + side\n",
        "    ty = max(0, cy - side // 2); by = ty + side\n",
        "    if rx > W:\n",
        "        lx -= (rx - W); rx = W\n",
        "    if by > H:\n",
        "        ty -= (by - H); by = H\n",
        "    crop_box = (lx, ty, rx, by)\n",
        "    img_c = image_pil.crop(crop_box).resize((out_size, out_size), Image.Resampling.LANCZOS)\n",
        "    m_c = mask_np[ty:by, lx:rx]\n",
        "    m_c = cv2.resize(m_c, (out_size, out_size), interpolation=cv2.INTER_NEAREST)\n",
        "    return img_c, m_c, crop_box\n",
        "\n",
        "\n",
        "def adaptive_brightness(img, strength_dark=0.15, strength_light=0.03, clip=(0, 245)):\n",
        "    a = np.asarray(img).astype(np.float32)\n",
        "    lum = 0.2126 * a[..., 0] + 0.7152 * a[..., 1] + 0.0722 * a[..., 2]\n",
        "    mean_lum = float(lum.mean() / 255.0)\n",
        "    if mean_lum < 0.5:\n",
        "        factor = 1 + (-strength_dark) * (0.5 - mean_lum) * 2\n",
        "    else:\n",
        "        factor = 1 + (strength_light) * (mean_lum - 0.5) * 2\n",
        "    out = np.clip(a * factor, *clip).astype(np.uint8)\n",
        "    return Image.fromarray(out)\n",
        "\n",
        "\n",
        "def paste_crop_back(full_img: Image.Image, edited_crop: Image.Image, crop_box, crop_mask: np.ndarray,\n",
        "                    expand_px=20, feather_px=10) -> Image.Image:\n",
        "    edited_crop = adaptive_brightness(edited_crop, strength_dark=0.15, strength_light=0.03)\n",
        "    x1, y1, x2, y2 = crop_box\n",
        "    tgt_w, tgt_h = x2 - x1, y2 - y1\n",
        "    edit_rs = edited_crop.resize((tgt_w, tgt_h), Image.Resampling.LANCZOS)\n",
        "    mask_np = cv2.resize(crop_mask, (tgt_w, tgt_h), interpolation=cv2.INTER_NEAREST)\n",
        "    bin_mask = (mask_np > 0).astype(np.uint8)\n",
        "    if expand_px > 0:\n",
        "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (expand_px * 2 + 1, expand_px * 2 + 1))\n",
        "        bin_mask = cv2.dilate(bin_mask, k, iterations=1)\n",
        "    alpha = cv2.GaussianBlur(bin_mask.astype(np.float32) * 255, (0, 0), sigmaX=feather_px, sigmaY=feather_px)\n",
        "    alpha[mask_np > 0] = 255\n",
        "    alpha = alpha.clip(0, 255).astype(np.uint8)\n",
        "    mask_img = Image.fromarray(alpha)\n",
        "\n",
        "    region = full_img.crop((x1, y1, x2, y2))\n",
        "    comp = Image.composite(edit_rs, region, mask_img)\n",
        "    full_img.paste(comp, (x1, y1))\n",
        "    return full_img\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL1y4tUs51S_"
      },
      "outputs": [],
      "source": [
        "# Normalization for detail types from legacy names\n",
        "def _normalize_detail_type(t: str) -> str:\n",
        "    t = (t or \"\").strip().lower()\n",
        "    mapping = {\n",
        "        \"waistband lettering\": \"waist text\",\n",
        "        \"sleeve lettering\": \"sleeve text\",\n",
        "        \"sleeve_text\": \"sleeve text\",\n",
        "        \"waist_text\": \"waist text\",\n",
        "    }\n",
        "    return mapping.get(t, t)\n",
        "\n",
        "def _postprocess_details(payload: dict) -> dict:\n",
        "    details = payload.get(\"details\", [])\n",
        "    fixed = []\n",
        "    for d in details:\n",
        "        typ = _normalize_detail_type(d.get(\"type\"))\n",
        "        col = d.get(\"color\")\n",
        "        if typ in ALLOWED_DETAIL_TYPES:\n",
        "            ent = {\"type\": typ}\n",
        "            if typ != \"sleeve text\" and isinstance(col, str) and col.strip():\n",
        "                ent[\"color\"] = col.strip()\n",
        "            fixed.append(ent)\n",
        "    return {\"details\": fixed}\n",
        "\n",
        "def _try_parse_json(s: str) -> dict | None:\n",
        "    try:\n",
        "        obj = json.loads(s)\n",
        "        if isinstance(obj, dict) and \"details\" in obj:\n",
        "            return obj\n",
        "    except Exception:\n",
        "        pass\n",
        "    # try to extract first {...}\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", s)\n",
        "    if m:\n",
        "        try:\n",
        "            obj = json.loads(m.group(0))\n",
        "            if isinstance(obj, dict) and \"details\" in obj:\n",
        "                return obj\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def read_details_from_metadata(img_path: str) -> dict:\n",
        "    \"\"\"Return {'details':[...]} or {'details':[{'type':'logo'}]} if metadata not found.\"\"\"\n",
        "    try:\n",
        "        im = Image.open(img_path)\n",
        "        # 1) PNG/JPEG info dict\n",
        "        for k, v in (im.info or {}).items():\n",
        "            if isinstance(v, str):\n",
        "                obj = _try_parse_json(v)\n",
        "                if obj:\n",
        "                    return _postprocess_details(obj)\n",
        "        # 2) EXIF: UserComment / XPComment\n",
        "        try:\n",
        "            exif_dict = piexif.load(im.info.get(\"exif\", b\"\") or im.tobytes())\n",
        "        except Exception:\n",
        "            exif_dict = None\n",
        "\n",
        "        def _decode_uc(x):\n",
        "            if isinstance(x, bytes):\n",
        "                for head in [b\"ASCII\\0\\0\\0\", b\"UNICODE\\0\", b\"JIS\\0\\0\\0\"]:\n",
        "                    if x.startswith(head):\n",
        "                        x = x[len(head):]\n",
        "                try:\n",
        "                    return x.decode(\"utf-8\", \"ignore\")\n",
        "                except Exception:\n",
        "                    return x.decode(\"latin-1\", \"ignore\")\n",
        "            if isinstance(x, str):\n",
        "                return x\n",
        "            return None\n",
        "\n",
        "        if exif_dict:\n",
        "            uc = exif_dict.get(\"Exif\", {}).get(piexif.ExifIFD.UserComment, None)\n",
        "            s = _decode_uc(uc)\n",
        "            if s:\n",
        "                obj = _try_parse_json(s)\n",
        "                if obj:\n",
        "                    return _postprocess_details(obj)\n",
        "            xp = exif_dict.get(\"0th\", {}).get(0x9C9C, None)\n",
        "            if xp:\n",
        "                try:\n",
        "                    s = bytes(xp).decode(\"utf-16le\", \"ignore\").rstrip(\"\\x00\")\n",
        "                    obj = _try_parse_json(s)\n",
        "                    if obj:\n",
        "                        return _postprocess_details(obj)\n",
        "                except Exception:\n",
        "                    pass\n",
        "        # 3) XMP sidecar embedded?\n",
        "        if \"XML:com.adobe.xmp\" in (im.info or {}):\n",
        "            obj = _try_parse_json(im.info[\"XML:com.adobe.xmp\"])\n",
        "            if obj:\n",
        "                return _postprocess_details(obj)\n",
        "        # 4) Optional sidecar .json next to image\n",
        "        side = Path(img_path).with_suffix(\".json\")\n",
        "        if side.exists():\n",
        "            try:\n",
        "                obj = json.loads(side.read_text())\n",
        "                if \"details\" in obj:\n",
        "                    return _postprocess_details(obj)\n",
        "            except Exception:\n",
        "                pass\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0\ufe0f metadata read failed for {img_path}: {e}\")\n",
        "\n",
        "    # \ud83d\udc47 Fallback when nothing found\n",
        "    return {\"details\": [{\"type\": \"logo\"}]}\n",
        "\n",
        "\n",
        "# Garment type inference (from path)\n",
        "def extract_garment_type_from_path(image_path: str, allowed_types=ALLOWED_GARMENT_TYPES) -> str:\n",
        "    from pathlib import Path as _P\n",
        "    import re\n",
        "    def singularize(s):\n",
        "        if len(s)>4:\n",
        "            if s.endswith(\"es\"): return s[:-2]\n",
        "            if s.endswith(\"s\"):  return s[:-1]\n",
        "        return s\n",
        "    def normalize_key(s): return singularize(s.replace(\"-\",\"\").replace(\"_\",\"\").lower().strip())\n",
        "    norm_map = {}\n",
        "    for t in allowed_types:\n",
        "        base = normalize_key(t)\n",
        "        norm_map[base]=t\n",
        "        if not base.endswith(\"s\"): norm_map[base+\"s\"]=t\n",
        "        else:\n",
        "            if base.endswith(\"es\"): norm_map[base[:-2]]=t\n",
        "            else: norm_map[base[:-1]]=t\n",
        "    p = _P(image_path)\n",
        "    file_compact = re.sub(r\"[^a-z]+\",\"\", p.stem.lower())\n",
        "    for k,v in norm_map.items():\n",
        "        if k and k in file_compact: return v\n",
        "    # parent folders\n",
        "    for part in reversed(p.parts[:-1]):\n",
        "        if part.startswith(\".\"): continue\n",
        "        toks = [singularize(t) for t in re.split(r\"[^a-z]+\", part.lower()) if t]\n",
        "        for tok in toks:\n",
        "            if tok in norm_map: return norm_map[tok]\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbCd-SBI530x"
      },
      "outputs": [],
      "source": [
        "# === Robust SKU+angle parsing (handles: \"SS-28623_fr (1).png\", \"Copy of SS-12345_bc_lft_v2.png\", \"SS-55555_fr_cl.png\") ===\n",
        "import os, re\n",
        "from pathlib import Path\n",
        "from functools import lru_cache\n",
        "\n",
        "# Reuse your global config: BASE_NAMES, ACCEPTABLE_SUFFIXES, VALID_EXTS, WORKING_DIR\n",
        "\n",
        "_SKU_RE = re.compile(r\"(SS-\\d{3,7})\", re.IGNORECASE)\n",
        "_COPY_RE = re.compile(r\"^(?:copy of\\s+)+\", re.IGNORECASE)\n",
        "\n",
        "def _strip_copy_prefix(s: str) -> str:\n",
        "    return _COPY_RE.sub(\"\", s).strip()\n",
        "\n",
        "def _angle_tokens_desc() -> list[str]:\n",
        "    # Longest-first to prefer 'fr_rght' over 'fr'\n",
        "    return sorted(list(set(BASE_NAMES)), key=len, reverse=True)\n",
        "\n",
        "def _token_delim_search(token: str, text: str) -> re.Match | None:\n",
        "    \"\"\"\n",
        "    Find token delimited by non-alphanumerics (underscore is allowed as a delimiter).\n",
        "    We treat [A-Za-z0-9] as 'wordy'; underscores/spaces/()/- etc. are delimiters.\n",
        "    \"\"\"\n",
        "    # Escape underscores in token for regex\n",
        "    tok = re.escape(token)\n",
        "    pattern = rf\"(?<![A-Za-z0-9]){tok}(?![A-Za-z0-9])\"\n",
        "    return re.search(pattern, text, flags=re.IGNORECASE)\n",
        "\n",
        "def extract_sku_and_angle_from_path(path_like: str) -> tuple[str | None, str | None]:\n",
        "    \"\"\"\n",
        "    Returns (SKU like 'SS-12345', angle_base like 'fr_lft'/'fr').\n",
        "    Strategy:\n",
        "      1) Extract SKU from filename; if not found, try parent dirs.\n",
        "      2) After SKU in the filename, scan the suffix for the LONGEST valid angle token.\n",
        "      3) Fallback to whole filename scan, then parent dirs.\n",
        "    \"\"\"\n",
        "    p = Path(path_like)\n",
        "    name = _strip_copy_prefix(p.name)\n",
        "\n",
        "    # --- 1) SKU from filename, else parents\n",
        "    m = _SKU_RE.search(name)\n",
        "    sku = m.group(1).upper() if m else None\n",
        "    if sku is None:\n",
        "        for part in reversed(p.parts):\n",
        "            mm = _SKU_RE.search(part)\n",
        "            if mm:\n",
        "                sku = mm.group(1).upper()\n",
        "                break\n",
        "\n",
        "    # --- 2) Angle after SKU region\n",
        "    angle = None\n",
        "    tokens = _angle_tokens_desc()\n",
        "    if sku:\n",
        "        mname = _SKU_RE.search(name)\n",
        "        if mname:\n",
        "            suffix = name[mname.end():]  # everything after the SKU\n",
        "            for tok in tokens:\n",
        "                if _token_delim_search(tok, suffix):\n",
        "                    angle = tok\n",
        "                    break\n",
        "\n",
        "    # --- 3) Fallback: whole filename, then parents\n",
        "    if angle is None:\n",
        "        for tok in tokens:\n",
        "            if _token_delim_search(tok, name):\n",
        "                angle = tok\n",
        "                break\n",
        "    if angle is None:\n",
        "        # Look in parent folders\n",
        "        for part in reversed(p.parts[:-1]):\n",
        "            part_clean = _strip_copy_prefix(part)\n",
        "            for tok in tokens:\n",
        "                if _token_delim_search(tok, part_clean):\n",
        "                    angle = tok\n",
        "                    break\n",
        "            if angle:\n",
        "                break\n",
        "\n",
        "    return sku, angle\n",
        "\n",
        "# ===================== Source finding via SKU folder anywhere =====================\n",
        "@lru_cache(maxsize=1024)\n",
        "def _find_sku_folder_anywhere(working_root: str, sku_name: str) -> Path | None:\n",
        "    wr = Path(working_root)\n",
        "    if not wr.exists():\n",
        "        return None\n",
        "    sku_low = sku_name.lower()\n",
        "    best: tuple[int, Path] | None = None\n",
        "    for dirpath, dirnames, _ in os.walk(wr):\n",
        "        leaf = os.path.basename(dirpath)\n",
        "        if leaf.lower() == sku_low:\n",
        "            depth = len(Path(dirpath).parts)\n",
        "            cand = Path(dirpath)\n",
        "            if best is None or depth < best[0]:\n",
        "                best = (depth, cand)\n",
        "    return best[1] if best else None\n",
        "\n",
        "\n",
        "def _list_valid_images(folder: Path) -> list[Path]:\n",
        "    \"\"\"\n",
        "    Return candidate source images in `folder`, excluding:\n",
        "      - any with 'generated', 'inpainted', '_nd', '_no_details', '_processed_by_detailer_'\n",
        "      - any with '_sec' anywhere in the filename (case-insensitive)\n",
        "    \"\"\"\n",
        "    deny_substrings = (\n",
        "        \"generated\",\n",
        "        \"inpainted\",\n",
        "        \"_nd\",\n",
        "        \"_no_details\",\n",
        "        \"_processed_by_detailer_\",\n",
        "        \"_sec\",   # \u2190 NEW: ignore secondary variants\n",
        "    )\n",
        "    out = []\n",
        "    for p in folder.iterdir():\n",
        "        if not (p.is_file() and p.suffix in VALID_EXTS):\n",
        "            continue\n",
        "        name_low = p.name.lower()\n",
        "        if any(s in name_low for s in deny_substrings):\n",
        "            continue\n",
        "        out.append(p)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _rank_exact_angle(norm_stem: str, base: str, acceptable_suffixes: set[str]) -> int | None:\n",
        "    if norm_stem == f\"{base}_cut\": return 1\n",
        "    if norm_stem.startswith(base + \"_\") and norm_stem.endswith(\"_cut\"): return 2\n",
        "    if norm_stem == base: return 3\n",
        "    if norm_stem.startswith(base + \"_\"):\n",
        "        suf = norm_stem[len(base)+1:]\n",
        "        if suf in acceptable_suffixes: return 4\n",
        "    return None\n",
        "\n",
        "def _is_fr_family(base: str | None) -> bool:\n",
        "    if not base: return False\n",
        "    return base in (\"fr\",\"fr_cl\",\"fr_lft\",\"fr_rght\") or base.startswith(\"fr\")\n",
        "\n",
        "def _pick_source_in_dir(angle_base: str, directory: Path) -> Path | None:\n",
        "    entries = _list_valid_images(directory)\n",
        "    if not entries: return None\n",
        "    acceptable = set(ACCEPTABLE_SUFFIXES)\n",
        "\n",
        "    def _norm(p: Path) -> str:\n",
        "        return _strip_copy_prefix(p.stem).lower()\n",
        "\n",
        "    ranked: list[tuple[int,int,Path]] = []\n",
        "    if _is_fr_family(angle_base):\n",
        "        for p in entries:\n",
        "            n = _norm(p)\n",
        "            if n == \"fr_cut\": ranked.append((1,len(p.name),p)); continue\n",
        "            if n.startswith(\"fr_\") and n.endswith(\"_cut\"): ranked.append((2,len(p.name),p)); continue\n",
        "            if n == \"fr\": ranked.append((3,len(p.name),p)); continue\n",
        "            if n.startswith(\"fr_\"):\n",
        "                suf = n[len(\"fr_\"):]\n",
        "                if suf in acceptable: ranked.append((4,len(p.name),p)); continue\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        ranked=[]\n",
        "        for p in entries:\n",
        "            n=_norm(p)\n",
        "            r=_rank_exact_angle(n, angle_base, acceptable)\n",
        "            if r is not None: ranked.append((r,len(p.name),p))\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        return None\n",
        "    else:\n",
        "        for p in entries:\n",
        "            n=_norm(p)\n",
        "            r=_rank_exact_angle(n, angle_base, acceptable)\n",
        "            if r is not None: ranked.append((r,len(p.name),p))\n",
        "        if ranked:\n",
        "            ranked.sort(key=lambda t: (t[0], t[1], t[2].name))\n",
        "            return ranked[0][2]\n",
        "        return None\n",
        "\n",
        "def find_source_via_sku(gen_path: Path | str, working_root: Path | str) -> Path | None:\n",
        "    gen_path = Path(gen_path)\n",
        "    sku, angle_base = extract_sku_and_angle_from_path(str(gen_path))\n",
        "\n",
        "    if not sku:\n",
        "        print(f\"\u274c Could not extract SKU from: {gen_path.name}\")\n",
        "        return None\n",
        "\n",
        "    if not angle_base:\n",
        "        # No noisy warning anymore; we\u2019ll gracefully default.\n",
        "        angle_base = \"fr\"\n",
        "\n",
        "    sku_dir = _find_sku_folder_anywhere(str(working_root), sku)\n",
        "    if not sku_dir:\n",
        "        print(f\"\u274c SKU folder '{sku}' not found anywhere under {working_root}\")\n",
        "        return None\n",
        "\n",
        "    ricardo = sku_dir / \"Ricardo\"\n",
        "    for d in (ricardo, sku_dir):\n",
        "        if d.exists() and d.is_dir():\n",
        "            hit = _pick_source_in_dir(angle_base, d)\n",
        "            if hit: return hit\n",
        "\n",
        "    print(f\"\u26a0\ufe0f No suitable source found in '{sku_dir}' (Ricardo or root) for angle '{angle_base}'\")\n",
        "    return None\n",
        "\n",
        "def build_inpaint_suffix(details: list[dict]) -> str:\n",
        "    def slug(s: str) -> str:\n",
        "        s = s.lower().replace(\" \", \"-\")\n",
        "        return re.sub(r\"[^a-z0-9\\-]+\", \"\", s).strip(\"-\")\n",
        "    parts=[]\n",
        "    for d in details:\n",
        "        t = d[\"type\"]\n",
        "        c = d.get(\"color\",\"\")\n",
        "        if t != \"sleeve text\" and c:\n",
        "            parts.append(slug(f\"{c}-{t}\"))\n",
        "        else:\n",
        "            parts.append(slug(t))\n",
        "    return \"_\".join(parts) if parts else \"none\"\n",
        "\n",
        "# --- Build the required base \"SS-12345-bc_lft\" from the queued filename ---\n",
        "def build_out_base_from_gen(gen_path: str) -> tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Returns (sku_upper, angle_lower, out_base).\n",
        "    out_base is 'SS-12345-bc_lft' (SKU + '-' + angle).\n",
        "    \"\"\"\n",
        "    sku, angle = extract_sku_and_angle_from_path(gen_path)\n",
        "    if not sku:\n",
        "        raise ValueError(f\"Cannot derive SKU from: {gen_path}\")\n",
        "    if not angle:\n",
        "        angle = \"fr\"\n",
        "    sku_up = sku.upper()\n",
        "    angle_lo = angle.lower()\n",
        "    return sku_up, angle_lo, f\"{sku_up}-{angle_lo}\"\n",
        "\n",
        "def target_already_has_inpainted(target_dir: str, sku: str, angle: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check TARGET_DIR for any file starting with 'SS-12345-bc_lft_inpainted'.\n",
        "    Case-insensitive; extension-agnostic.\n",
        "    \"\"\"\n",
        "    td = Path(target_dir)\n",
        "    if not td.exists():\n",
        "        return False\n",
        "    prefix = f\"{sku.upper()}-{angle.lower()}_inpainted\"\n",
        "    prefix_low = prefix.lower()\n",
        "    for p in td.iterdir():\n",
        "        if p.is_file() and p.suffix in VALID_EXTS:\n",
        "            if p.stem.lower().startswith(prefix_low):\n",
        "                return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkjJwDwh558v"
      },
      "outputs": [],
      "source": [
        "def _inpaint_one_detail(gen_full: Image.Image,\n",
        "                        src_full: Image.Image,\n",
        "                        detail_prompt: str,\n",
        "                        *,\n",
        "                        garment_tag: str,\n",
        "                        restrict_mask_full: np.ndarray | None,\n",
        "                        generous_pad_px: int,\n",
        "                        tiny_pad_px: int,\n",
        "                        seed: int,\n",
        "                        visualize: bool) -> tuple[Image.Image, bool]:\n",
        "\n",
        "    _prepare_for_sam3()\n",
        "    modified = False\n",
        "\n",
        "    gen_view_for_sam3 = apply_binary_mask(gen_full, restrict_mask_full) if restrict_mask_full is not None else gen_full\n",
        "\n",
        "    gar_src_bb = detect_garment_box(src_full, garment_tag)\n",
        "    gar_gen_bb = detect_garment_box(gen_view_for_sam3, garment_tag, restrict_mask=restrict_mask_full)\n",
        "    if gar_src_bb is None or gar_gen_bb is None:\n",
        "        print(\"\u274c garment detection failed\"); return gen_full, modified\n",
        "\n",
        "    # square garment crops\n",
        "    def crop_to_square(image: Image.Image, bbox, pad_px=0):\n",
        "        x1,y1,x2,y2 = bbox\n",
        "        w,h = x2-x1, y2-y1\n",
        "        side = max(w,h) + 2*pad_px\n",
        "        cx,cy = (x1+x2)//2, (y1+y2)//2\n",
        "        lx=max(0,cx-side//2); ty=max(0,cy-side//2)\n",
        "        rx=lx+side; by=ty+side\n",
        "        W,H=image.size\n",
        "        if rx>W: lx -= (rx-W); rx=W\n",
        "        if by>H: ty -= (by-H); by=H\n",
        "        crop = image.crop((max(lx,0),max(ty,0),min(rx,W),min(by,H)))\n",
        "        out  = Image.new(\"RGB\",(side,side),(255,255,255))\n",
        "        dx=max(0,-lx); dy=max(0,-ty)\n",
        "        out.paste(crop,(dx,dy))\n",
        "        return out, (lx,ty,rx,by)\n",
        "\n",
        "    src_sq, sq_src = crop_to_square(src_full, gar_src_bb)\n",
        "    gen_sq, sq_gen = crop_to_square(gen_view_for_sam3, gar_gen_bb)\n",
        "\n",
        "    src_garm_sq, sq_coords_src = crop_to_square(src_full, gar_src_bb, pad_px=0)\n",
        "    gen_garm_sq, sq_coords_gen = crop_to_square(gen_view_for_sam3, gar_gen_bb, pad_px=0)\n",
        "\n",
        "    det_src_bb, _, det_src_mask_crop = detect_detail(src_sq, detail_prompt, crop_box_on_full=sq_src)\n",
        "    prior = make_spatial_prior_from_box(det_src_bb, src_garm_sq.size)\n",
        "\n",
        "    det_gen_bb, _, det_gen_mask_crop = detect_detail_topk7(\n",
        "        gen_garm_sq,\n",
        "        detail_prompt,\n",
        "        source_prior=prior,\n",
        "        restrict_mask=(restrict_mask_full, \"FULL\"),  # pass FULL mask\n",
        "        crop_box_on_full=sq_coords_gen,              # the (x1,y1,x2,y2) used to make gen_garm_sq\n",
        "        viz=False, debug=False\n",
        "    )\n",
        "    if det_src_bb is None or det_gen_bb is None:\n",
        "        print(f\"\u274c detail not found: {detail_prompt}\"); return gen_full, modified\n",
        "\n",
        "    # back to full coords\n",
        "    lx_s, ty_s, _, _ = sq_src\n",
        "    lx_g, ty_g, _, _ = sq_gen\n",
        "    src_det_bb = [det_src_bb[0]+lx_s, det_src_bb[1]+ty_s, det_src_bb[2]+lx_s, det_src_bb[3]+ty_s]\n",
        "    gen_det_bb = [det_gen_bb[0]+lx_g, det_gen_bb[1]+ty_g, det_gen_bb[2]+lx_g, det_gen_bb[3]+ty_g]\n",
        "\n",
        "    src_mask_full = _mask_crop_to_full(det_src_mask_crop, sq_src, src_full.size) if det_src_mask_crop is not None else None\n",
        "    gen_mask_full = _mask_crop_to_full(det_gen_mask_crop, sq_coords_gen, gen_full.size) if det_gen_mask_crop is not None else None\n",
        "    if src_mask_full is None:\n",
        "        src_mask_full = bbox_to_mask(src_det_bb, src_full.size, INPAINT_TINY_PAD)\n",
        "    if gen_mask_full is None:\n",
        "        gen_mask_full = bbox_to_mask(gen_det_bb, gen_full.size, INPAINT_TINY_PAD)\n",
        "    else:\n",
        "        gen_mask_full = enlarge_mask(gen_mask_full, scale=1.05)\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"detail on source\", _draw_bbox(src_full, src_det_bb)),\n",
        "            (\"detail on generated (masked)\", _draw_bbox(gen_view_for_sam3, gen_det_bb))\n",
        "        ], cols=2, figsize=(12,8))\n",
        "\n",
        "    # crops for IA\n",
        "    src_crop, src_mask, _   = crop_detail(src_full, src_mask_full, src_det_bb, 1024, 20)\n",
        "    gen_crop, gen_mask, box = crop_detail(gen_full, gen_mask_full, gen_det_bb, 1024, INPAINT_GENEROUS_PAD)\n",
        "\n",
        "    # diptych\n",
        "    src_arr = np.array(src_crop)\n",
        "    masked_src = src_arr  # keep source unmasked for IA\n",
        "\n",
        "    gen_arr = np.array(gen_crop)\n",
        "    gen_msk3 = np.stack([gen_mask]*3, -1)\n",
        "    zeros = np.zeros_like(masked_src)\n",
        "\n",
        "    diptych = np.concatenate([masked_src, gen_arr], axis=1).astype(np.uint8)\n",
        "    dip_mask = np.concatenate([zeros, gen_msk3], axis=1).astype(np.uint8)\n",
        "    dip_mask[dip_mask>0]=255\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"diptych\", Image.fromarray(diptych)),\n",
        "            (\"diptych mask\", Image.fromarray(dip_mask).convert(\"RGB\"))\n",
        "        ], cols=2, figsize=(12,8))\n",
        "\n",
        "    _prepare_for_insert_anything()\n",
        "\n",
        "    prior = redux(Image.fromarray(masked_src))\n",
        "    gen_obj = torch.Generator(IA_DEVICE).manual_seed(seed)\n",
        "    ia_out = pipe(\n",
        "        image=Image.fromarray(diptych),\n",
        "        mask_image=Image.fromarray(dip_mask),\n",
        "        height=1024,\n",
        "        width=2048,\n",
        "        max_sequence_length=512,\n",
        "        num_inference_steps=60,\n",
        "        guidance_scale=30,\n",
        "        generator=gen_obj,\n",
        "        **prior\n",
        "    ).images[0]\n",
        "\n",
        "    right_crop = ia_out.crop((1024,0,2048,1024))\n",
        "    gen_full = paste_crop_back(gen_full, right_crop, box, gen_mask)\n",
        "    modified = True\n",
        "\n",
        "    if visualize:\n",
        "        _show_images([\n",
        "            (\"IA result (2048\u00d71024)\", ia_out),\n",
        "            (\"after this detail\", gen_full)\n",
        "        ], cols=2, figsize=(14,8))\n",
        "\n",
        "    return gen_full, modified\n",
        "\n",
        "def inpaint_with_details_list(generated_path: str,\n",
        "                              source_path: str,\n",
        "                              details: list[dict],\n",
        "                              garment_type: str | None,\n",
        "                              visualize: bool = True) -> tuple[Image.Image, bool]:\n",
        "\n",
        "    gen_full = open_upright(generated_path)\n",
        "    src_full = open_source_with_black_bg(source_path)\n",
        "\n",
        "    restrict_mask_full = load_binary_mask_for_generated(generated_path, source_path, gen_full)\n",
        "\n",
        "    if restrict_mask_full is None:\n",
        "        print(\"\u26a0\ufe0f  No garment mask found \u2014 proceeding without restriction.\")\n",
        "    else:\n",
        "        print(\"\u2705 Garment mask loaded & aligned for\", os.path.basename(generated_path))\n",
        "\n",
        "    if garment_type is None or not garment_type.strip():\n",
        "        garment_type = extract_garment_type_from_path(source_path)\n",
        "    if not garment_type:\n",
        "        garment_type = \"t-shirt\"  # conservative default prompt\n",
        "\n",
        "    # twinset (optional, keep simple)\n",
        "    garment_tags = [garment_type.lower()]\n",
        "    if garment_type.lower() in TWINSET_TYPES:\n",
        "        garment_tags = [TOP_GARMENTS[0], BOTTOM_GARMENTS[0]]\n",
        "\n",
        "    out_img = gen_full.copy()\n",
        "    any_modified = False\n",
        "    for gtag in garment_tags:\n",
        "        for d in details:\n",
        "            d_type = d[\"type\"]\n",
        "            prompt_str = f\"{d_type}\".strip()\n",
        "            print(f\"\ud83d\udd04 Inpainting detail: {prompt_str}  (garment={gtag})\")\n",
        "            out_img, did_modify = _inpaint_one_detail(\n",
        "                out_img, src_full, prompt_str,\n",
        "                garment_tag=gtag,\n",
        "                restrict_mask_full=restrict_mask_full,\n",
        "                generous_pad_px=INPAINT_GENEROUS_PAD,\n",
        "                tiny_pad_px=INPAINT_TINY_PAD,\n",
        "                seed=INPAINT_SEED,\n",
        "                visualize=visualize\n",
        "            )\n",
        "            any_modified = any_modified or did_modify\n",
        "\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return out_img, any_modified\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekO6QtZR59KR"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "def process_detailer_queue():\n",
        "    queue_root = Path(DETAILER_QUEUE_FOLDER)\n",
        "    if not queue_root.exists():\n",
        "        print(f\"\u274c Queue folder does not exist: {queue_root}\")\n",
        "        return\n",
        "\n",
        "    gen_files = [p for p in queue_root.rglob(\"*\") if p.is_file() and p.suffix in VALID_EXTS]\n",
        "    if not gen_files:\n",
        "        print(f\"\u2139\ufe0f No images found in {queue_root}\")\n",
        "        return\n",
        "\n",
        "    processed = skipped = failed = 0\n",
        "\n",
        "    for gen_path in sorted(gen_files, key=lambda p: (str(p.parent), p.name)):\n",
        "        try:\n",
        "            print(\"\\n\" + \"_\"*80)\n",
        "            print(f\"\ud83c\udfaf Queue item: {gen_path}\")\n",
        "\n",
        "            # 1) Read details from metadata\n",
        "            meta = read_details_from_metadata(str(gen_path))\n",
        "            if not meta or not meta.get(\"details\"):\n",
        "                print(\"\u23ed\ufe0f  No details found in metadata \u2014 skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            details = [d for d in meta[\"details\"] if d[\"type\"] in ALLOWED_DETAIL_TYPES]\n",
        "            if not details:\n",
        "                print(\"\u23ed\ufe0f  Details list empty after normalization \u2014 skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # 2) Find source garment near this item\n",
        "            src_p = find_source_via_sku(gen_path, Path(WORKING_DIR))\n",
        "            if not src_p:\n",
        "                print(\"\u23ed\ufe0f  Source garment not found \u2014 skipping\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            source_base = Path(src_p).stem  # e.g. SS-12345_fr\n",
        "            sku_up, angle_lo, out_base = build_out_base_from_gen(str(gen_path))\n",
        "            out_ext = \".png\"\n",
        "\n",
        "            # 3) Skip guard: any prior inpainted for this SKU+angle?\n",
        "            if SKIP_IF_ALREADY_INPAINTED and target_already_has_inpainted(TARGET_DIR, sku_up, angle_lo):\n",
        "              print(f\"\u23ed\ufe0f  Already have inpainted for {out_base} in TARGET_DIR \u2014 skipping\")\n",
        "              skipped += 1\n",
        "              continue\n",
        "\n",
        "            # 4) Inpaint\n",
        "            garment_type = extract_garment_type_from_path(str(src_p))\n",
        "            out_img, modified = inpaint_with_details_list(\n",
        "                str(gen_path),\n",
        "                str(src_p),\n",
        "                details=details,\n",
        "                garment_type=garment_type,\n",
        "                visualize=VISUALIZE\n",
        "            )\n",
        "            if not modified:\n",
        "                print(\"\u23ed\ufe0f  No details applied \u2014 skipping save\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # 5) Build output names (keep source naming; append detail suffixes)\n",
        "            suffix   = build_inpaint_suffix(details)   # unchanged\n",
        "            dst_src  = Path(TARGET_DIR) / f\"{out_base}{out_ext}\"                         # e.g., SS-12345-bc_lft.jpg\n",
        "            dst_ia   = Path(TARGET_DIR) / f\"{out_base}_inpainted_{suffix}{out_ext}\"      # e.g., SS-12345-bc_lft_inpainted_red_logo.jpg\n",
        "\n",
        "            # 6) Save outputs: copy source + save inpainted\n",
        "            #if not dst_src.exists():\n",
        "            #    shutil.copy2(str(src_p), str(dst_src))\n",
        "            #    print(f\"\ud83d\udcce Saved source \u2192 {dst_src.name}\")\n",
        "            #else:\n",
        "            #    print(f\"\ud83d\udcce Source already present in TARGET_DIR \u2192 {dst_src.name}\")\n",
        "\n",
        "            # --- Save inpainted result ---\n",
        "            out_img.save(str(dst_ia))\n",
        "            print(f\"\u2705 Saved inpainted \u2192 {dst_ia.name}\")\n",
        "            processed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Failed on {gen_path.name}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "    print(\"\\n==== SUMMARY ====\")\n",
        "    print(f\"Processed: {processed}  |  Skipped: {skipped}  |  Failed: {failed}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Try-on \u2192 Detailer bridge ---\n",
        "from PIL import Image\n",
        "\n",
        "def _normalize_detail_payload(details_payload):\n",
        "    if not details_payload:\n",
        "        return [{\"type\": t} for t in (DETAILER_ONLY_TYPES or [\"logo\"])]\n",
        "    dets = details_payload.get(\"details\") if isinstance(details_payload, dict) else None\n",
        "    if not dets:\n",
        "        return [{\"type\": t} for t in (DETAILER_ONLY_TYPES or [\"logo\"])]\n",
        "    cleaned = []\n",
        "    for d in dets:\n",
        "        if not isinstance(d, dict):\n",
        "            continue\n",
        "        typ = d.get(\"type\") or \"logo\"\n",
        "        entry = {\"type\": typ}\n",
        "        if d.get(\"color\"):\n",
        "            entry[\"color\"] = d[\"color\"]\n",
        "        cleaned.append(entry)\n",
        "    return cleaned or [{\"type\": \"logo\"}]\n",
        "\n",
        "def run_detailer_logo_cleanup(gen_path: str, source_path: str, angle_code: str, *, details_payload=None):\n",
        "    if not RUN_DETAILER_AFTER_TRYON:\n",
        "        return Image.open(gen_path).convert(\"RGB\"), False\n",
        "    try:\n",
        "        details = _normalize_detail_payload(details_payload)\n",
        "        garment_type = extract_garment_type_from_path(source_path)\n",
        "        out_img, modified = inpaint_with_details_list(\n",
        "            generated_path=gen_path,\n",
        "            source_path=source_path,\n",
        "            details=details,\n",
        "            garment_type=garment_type,\n",
        "            visualize=DETAILER_VISUALIZE,\n",
        "        )\n",
        "        if modified:\n",
        "            print(f\"      \ud83e\uddfc Detailer removed logo(s) on {gen_path}\")\n",
        "        else:\n",
        "            print(f\"      \u2139\ufe0f Detailer found no logo to inpaint on {gen_path}\")\n",
        "        return out_img, modified\n",
        "    except Exception as e:\n",
        "        print(f\"      \u26a0\ufe0f Detailer failed on {gen_path}: {e}\")\n",
        "        try:\n",
        "            return Image.open(gen_path).convert(\"RGB\"), False\n",
        "        except Exception:\n",
        "            return None, False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5VwKPQIody"
      },
      "source": [
        "# BATCH HELPERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQi5CzF2_O92"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Batch processor  ---\n",
        "\n",
        "\n",
        "def process_one_garment_folder(folder_path: str, allowed_angles=None):\n",
        "    allowed_outputs_set = {_norm_angle(a) for a in (allowed_angles or [])}\n",
        "    allowed_outputs = sorted(allowed_outputs_set)\n",
        "    allowed_sources = expand_as_list(allowed_angles) if allowed_angles else None\n",
        "\n",
        "    main_category = _garment_category_from_path(folder_path)\n",
        "    main_class = _classify_garment_category(main_category)\n",
        "    secondary_type = \"bottom\" if main_class == \"top\" else (\"top\" if main_class == \"bottom\" else \"secondary\")\n",
        "\n",
        "    base_subcat_dir = resolve_base_mask_dir(folder_path)\n",
        "    if not base_subcat_dir:\n",
        "        print(f\"\u26a0\ufe0f Cannot resolve base/mask dir for SKU: {folder_path}\")\n",
        "    files_sorted = sorted(os.listdir(folder_path))\n",
        "\n",
        "    main_texture_card = load_texture_reference(folder_path, secondary=False, heading=\"Main texture reference\")\n",
        "    secondary_texture_card = load_texture_reference(folder_path, secondary=True, heading=\"Main texture reference\") if SECONDARY_GARMENT else None\n",
        "\n",
        "    main_prompt_text = build_main_prompt(include_texture=main_texture_card is not None)\n",
        "    secondary_prompt_text = build_secondary_prompt(sec_type=secondary_type, include_texture=secondary_texture_card is not None)\n",
        "\n",
        "    def source_priority(target_angle: str, filename: str) -> int:\n",
        "        stem = os.path.splitext(filename.lower())[0]\n",
        "        if target_angle == \"fr_cl\":\n",
        "            if stem.startswith(\"fr_cl\"):\n",
        "                return 0\n",
        "            if stem.startswith(\"fr_\") and not (stem.startswith(\"fr_rght\") or stem.startswith(\"fr_lft\")):\n",
        "                return 1\n",
        "            if stem.startswith(\"fr_rght\") or stem.startswith(\"fr_lft\"):\n",
        "                return 2\n",
        "        if stem.startswith(target_angle):\n",
        "            return 0\n",
        "        return 3\n",
        "\n",
        "    best_for_target = {}\n",
        "\n",
        "    for file in files_sorted:\n",
        "        low = file.lower()\n",
        "\n",
        "        if \"_sec\" in low:\n",
        "          # Ignore secondary garments in primary detection\n",
        "          continue\n",
        "\n",
        "        if allowed_sources and not any(low.startswith(src) for src in allowed_sources):\n",
        "            continue\n",
        "        if SKIP_FILENAME_TOKENS and any(tok in low for tok in SKIP_FILENAME_TOKENS):\n",
        "            continue\n",
        "        if REQUIRE_CUT_IN_FILENAME and (\"cut\" not in low):\n",
        "            continue\n",
        "        if not _valid_ext(file):\n",
        "            continue\n",
        "\n",
        "        matching_sources = [src for src in (allowed_sources or []) if low.startswith(src)] if allowed_sources else [_norm_angle(os.path.splitext(file)[0])]\n",
        "        if allowed_sources and not matching_sources:\n",
        "            continue\n",
        "\n",
        "        target_candidates = set()\n",
        "        for src in matching_sources:\n",
        "            norm_src = _norm_angle(src)\n",
        "            for target in (allowed_outputs or [norm_src]):\n",
        "                fam = {_norm_angle(x) for x in expand_allowed_angles([target])}\n",
        "                fam.add(_norm_angle(target))\n",
        "                if norm_src in fam:\n",
        "                    target_candidates.add(_norm_angle(target))\n",
        "\n",
        "        if allowed_outputs and not target_candidates:\n",
        "            continue\n",
        "\n",
        "        for target_angle in sorted(target_candidates):\n",
        "            base_img_path = _find_image_with_stem_and_suffix(base_subcat_dir, target_angle)\n",
        "            if not base_img_path:\n",
        "                print(f\"\u26a0\ufe0f Missing BASE for target '{target_angle}' \u2192 skipping that target for {file}\")\n",
        "                continue\n",
        "\n",
        "            mask_path = find_mask_path(base_subcat_dir, target_angle)\n",
        "            if not mask_path:\n",
        "                print(f\"\u2139\ufe0f No local mask for target '{target_angle}', will request SAM3 segmentation.\")\n",
        "\n",
        "            priority = source_priority(target_angle, low)\n",
        "            current = best_for_target.get(target_angle)\n",
        "            if current and priority >= current[\"priority\"]:\n",
        "                continue\n",
        "\n",
        "            best_for_target[target_angle] = {\n",
        "                \"priority\": priority,\n",
        "                \"file\": file,\n",
        "                \"base_img_path\": base_img_path,\n",
        "                \"mask_path\": mask_path,\n",
        "            }\n",
        "\n",
        "    worklist = [\n",
        "        (data[\"file\"], target_angle, data[\"base_img_path\"], data[\"mask_path\"])\n",
        "        for target_angle, data in best_for_target.items()\n",
        "    ]\n",
        "    worklist.sort(key=lambda x: x[1])\n",
        "\n",
        "    def find_existing_output_local(target_colab_path: str):\n",
        "        stem, _ = os.path.splitext(target_colab_path)\n",
        "        for ext in (\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\"):\n",
        "            cand = f\"{stem}{ext}\"\n",
        "            if os.path.exists(cand):\n",
        "                return cand\n",
        "        return None\n",
        "\n",
        "    sku_name = os.path.basename(folder_path)\n",
        "    if allowed_sources:\n",
        "        print(f\"\u25b6\ufe0f  {sku_name}: {len(worklist)} image(s) to generate (outputs={sorted(list(allowed_outputs_set))}, sources={sorted(list(set(allowed_sources)))})\")\n",
        "    else:\n",
        "        print(f\"\u25b6\ufe0f  {sku_name}: {len(worklist)} image(s) to generate\")\n",
        "\n",
        "    if not worklist:\n",
        "        return\n",
        "\n",
        "    for idx, (file, target_angle, base_img_path, mask_path) in enumerate(worklist, start=1):\n",
        "        print(f\"   {idx:>3}/{len(worklist):<3}  {file}  | USING STRICT base/mask='{target_angle}'\")\n",
        "        garment_path = os.path.join(folder_path, file)\n",
        "\n",
        "        sku_name = os.path.basename(folder_path)\n",
        "        angle_code = _norm_angle(target_angle)\n",
        "        main_suffix = \"_onlymain\" if SECONDARY_GARMENT else \"\"\n",
        "        main_out_name = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=main_suffix)\n",
        "        final_out_name = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=\"_both\") if SECONDARY_GARMENT else None\n",
        "\n",
        "        main_colab_path = os.path.join(OUTPUT_DIR, main_out_name)\n",
        "        final_colab_path = os.path.join(OUTPUT_DIR, final_out_name) if final_out_name else None\n",
        "\n",
        "        main_exists = drive_file_exists_any_ext_at_colab_path(main_colab_path)\n",
        "        final_exists = final_colab_path and drive_file_exists_any_ext_at_colab_path(final_colab_path)\n",
        "\n",
        "        reuse_main_img = None\n",
        "        sec_garment_override = None\n",
        "\n",
        "        if not SECONDARY_GARMENT:\n",
        "            if main_exists:\n",
        "                print(f\"      \u23ed\ufe0f  Skip: {main_out_name} already exists in {OUTPUT_DIR} (main target)\")\n",
        "                continue\n",
        "        else:\n",
        "            if final_exists:\n",
        "                print(f\"      \u23ed\ufe0f  Skip: {final_out_name} already exists in {OUTPUT_DIR} (secondary target)\")\n",
        "                continue\n",
        "\n",
        "            if main_exists:\n",
        "                sec_garment_override = find_secondary_garment_path(folder_path, file)\n",
        "                if not sec_garment_override:\n",
        "                    print(f\"      \u23ed\ufe0f  Skip: {main_out_name} exists but no secondary garment found in {folder_path}\")\n",
        "                    continue\n",
        "\n",
        "                existing_main_path = find_existing_output_local(main_colab_path)\n",
        "                if not existing_main_path:\n",
        "                    print(f\"      \u23ed\ufe0f  Skip: {main_out_name} exists in Drive but not on disk \u2192 cannot reuse without regenerating main\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    reuse_main_img = Image.open(existing_main_path).convert(\"RGB\")\n",
        "                    print(f\"      \u25b6\ufe0f  Reusing existing main output '{os.path.basename(existing_main_path)}' for secondary stage\")\n",
        "                except Exception as reuse_err:\n",
        "                    print(f\"      \u274c Unable to reuse existing main output '{existing_main_path}': {reuse_err}\")\n",
        "                    continue\n",
        "\n",
        "        try:\n",
        "            mask_dir = base_subcat_dir\n",
        "\n",
        "            def perform_tryon_stage(stage_base_full, stage_mask_img, stage_garment_img, suffix, stage_label, mask_label, prompt_text=None, texture_card=None, texture_label=None, detailer_source_path=None):\n",
        "                show_gallery(\n",
        "                    [stage_garment_img, stage_base_full, stage_mask_img.convert(\"RGB\")],\n",
        "                    [f\"Source garment (white BG) [{stage_label}]\", f\"Base photo [{angle_code}] [{stage_label}]\", f\"Mask [{mask_label}]\"]\n",
        "                )\n",
        "\n",
        "                upper_padding = UPPER_PADDING if (stage_label == \"secondary\") else (UPPER_PADDING + 100)\n",
        "\n",
        "                bbox = find_aspect_bbox(\n",
        "                    stage_mask_img,\n",
        "                    aspect=TARGET_ASPECT,\n",
        "                    padding=CROP_PADDING,\n",
        "                    upper_padding=upper_padding,\n",
        "                    horiz_padding=HORIZ_PADDING,\n",
        "                    min_margin=CROP_MIN_MARGIN,\n",
        "                    allow_padding=(stage_label != \"secondary\"),\n",
        "                )\n",
        "                base_crop = crop_with_padding(stage_base_full, bbox, fill=WHITE_RGB)\n",
        "                mask_crop = crop_with_padding(stage_mask_img.convert(\"L\"), bbox, fill=0)\n",
        "                if texture_card is not None:\n",
        "                    crop_thumb = texture_card\n",
        "                    crop_title = texture_label or \"Texture reference\"\n",
        "                else:\n",
        "                    crop_thumb = build_no_texture_card(stage_garment_img.size)\n",
        "                    crop_title = \"No texture file found\"\n",
        "                show_gallery(\n",
        "                    [base_crop, mask_crop.convert(\"RGB\"), crop_thumb],\n",
        "                    [f\"Cropped base (1:1) [{stage_label}]\", \"Cropped mask\", crop_title],\n",
        "                )\n",
        "\n",
        "                extra_images = None\n",
        "                if texture_card is not None:\n",
        "                    label = texture_label or \"Texture reference\"\n",
        "                    extra_images = [f\"{label}:\", texture_card.convert(\"RGB\")]\n",
        "\n",
        "\n",
        "                print(\"\ud83c\udf4c started...\")\n",
        "                tryon_gen = run_nanobanana_tryon(\n",
        "                    model_image=base_crop,\n",
        "                    garment_image=stage_garment_img,\n",
        "                    aspect_ratio=GEN_ASPECT_RATIO,\n",
        "                    image_size=GEN_IMAGE_SIZE,\n",
        "                    prompt=prompt_text or TRYON_PROMPT,\n",
        "                    extra_images=extra_images,\n",
        "                )\n",
        "\n",
        "                if tryon_gen.size != base_crop.size:\n",
        "                    if tryon_gen.width != tryon_gen.height:\n",
        "                        print(f\"      \u26a0\ufe0f Generator returned non-square image {tryon_gen.size}; resizing to {base_crop.size}.\")\n",
        "                    tryon_sq = tryon_gen.resize(base_crop.size, Image.Resampling.LANCZOS)\n",
        "                else:\n",
        "                    tryon_sq = tryon_gen\n",
        "\n",
        "                final_img_local, alpha_dbg = paste_crop_back_debug(\n",
        "                    full_img   = stage_base_full.copy(),\n",
        "                    edited_crop= tryon_sq,\n",
        "                    crop_box   = bbox,\n",
        "                    crop_mask  = np.array(mask_crop),\n",
        "                    solid_expand_px = max(5, MASK_EXPAND_PX // 4),\n",
        "                    halo_px         = MASK_EXPAND_PX,\n",
        "                    feather_px      = MASK_FEATHER_PX,\n",
        "                    edge_feather_px = 15,   # tweak to taste\n",
        "                )\n",
        "\n",
        "                show_gallery(\n",
        "                    [tryon_sq, alpha_dbg, final_img_local],\n",
        "                    [\"Try-on crop\", \"Alpha (debug)\", \"Final paste-back\"],\n",
        "                )\n",
        "\n",
        "                out_name_local = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=suffix)\n",
        "                tmp_path_local = os.path.join(\"/tmp\", out_name_local)\n",
        "\n",
        "                detailer_source = detailer_source_path or garment_path\n",
        "                detailer_payload = {\"details\": [{\"type\": t} for t in (DETAILER_ONLY_TYPES or [\"logo\"])]}\n",
        "                save_png_with_metadata(final_img_local, tmp_path_local, details_payload=detailer_payload)\n",
        "\n",
        "                if RUN_DETAILER_AFTER_TRYON:\n",
        "                    cleaned_img, cleaned = run_detailer_logo_cleanup(\n",
        "                        tmp_path_local,\n",
        "                        detailer_source,\n",
        "                        angle_code,\n",
        "                        details_payload=detailer_payload,\n",
        "                    )\n",
        "                    if cleaned and cleaned_img is not None:\n",
        "                        final_img_local = cleaned_img\n",
        "                        save_png_with_metadata(final_img_local, tmp_path_local, details_payload=detailer_payload)\n",
        "\n",
        "                target_path_for_drive = os.path.join(OUTPUT_DIR, out_name_local)\n",
        "\n",
        "                info = upload_file_and_append_to_sheet(\n",
        "                    local_path       = tmp_path_local,\n",
        "                    target_colab_path= target_path_for_drive,\n",
        "                    sku_name         = sku_name,\n",
        "                    angle            = angle_code,\n",
        "                    spreadsheet_id   = SPREADSHEET_ID,\n",
        "                    worksheet_name   = GEN_LOG_SHEET,\n",
        "                )\n",
        "                print(f\"      \u2705 Uploaded [{stage_label}] \u2192 {info['file_url']}\")\n",
        "                return final_img_local\n",
        "\n",
        "            main_result = reuse_main_img\n",
        "            skipped_main = reuse_main_img is not None\n",
        "\n",
        "            if not skipped_main:\n",
        "                garment_img = flatten_alpha_to_white(open_upright(garment_path))\n",
        "                base_full   = Image.open(base_img_path).convert(\"RGB\")\n",
        "                mask_label  = None\n",
        "\n",
        "                try:\n",
        "                    mask_full, mask_label = generate_mask_with_gemini(base_img_path, folder_path)\n",
        "                except Exception as mask_err:\n",
        "                    if mask_path:\n",
        "                        print(f\"      \u26a0\ufe0f SAM3 mask failed for '{target_angle}', using disk mask instead: {mask_err}\")\n",
        "                        mask_full = Image.open(mask_path).convert(\"L\")\n",
        "                        mask_label = os.path.basename(mask_path)\n",
        "                        mask_dir = os.path.dirname(mask_path)\n",
        "                    else:\n",
        "                        print(f\"      \u274c SAM3 mask failed and no local mask for '{target_angle}': {mask_err}\")\n",
        "                        continue\n",
        "\n",
        "                main_result = perform_tryon_stage(\n",
        "                    stage_base_full=base_full,\n",
        "                    stage_mask_img=mask_full,\n",
        "                    stage_garment_img=garment_img,\n",
        "                    suffix=main_suffix,\n",
        "                    prompt_text=main_prompt_text,\n",
        "                    stage_label=\"main\",\n",
        "                    mask_label=mask_label or \"gemini-mask\",\n",
        "                    texture_card=main_texture_card,\n",
        "                    texture_label=\"Main texture reference\",\n",
        "                    detailer_source_path=garment_path,\n",
        "                )\n",
        "\n",
        "            if SECONDARY_GARMENT:\n",
        "                sec_mask_path = find_mask_path(mask_dir, f\"{target_angle}_sec\")\n",
        "\n",
        "                sec_garment_path = sec_garment_override or find_secondary_garment_path(folder_path, file)\n",
        "                if not sec_garment_path:\n",
        "                    print(f\"      \u26a0\ufe0f Secondary garment missing for '{target_angle}' \u2192 kept main-only output.\")\n",
        "                    continue\n",
        "\n",
        "                if main_result is None:\n",
        "                    print(f\"      \u274c Cannot run secondary stage for '{target_angle}' without a main result.\")\n",
        "                    continue\n",
        "\n",
        "                sec_mask_full = None\n",
        "                sec_mask_label = None\n",
        "                try:\n",
        "                    sec_mask_full, sec_mask_label = generate_mask_with_gemini(\n",
        "                        base_img_path,\n",
        "                        folder_path,\n",
        "                        mask_variant=f\"{target_angle}_sec\",\n",
        "                    )\n",
        "                except Exception as sec_mask_err:\n",
        "                    if sec_mask_path:\n",
        "                        print(f\"      \u26a0\ufe0f Secondary SAM3 mask failed for '{target_angle}', using disk mask instead: {sec_mask_err}\")\n",
        "                        sec_mask_full = Image.open(sec_mask_path).convert(\"L\")\n",
        "                        sec_mask_label = os.path.basename(sec_mask_path)\n",
        "                    else:\n",
        "                        print(f\"      \u274c Secondary SAM3 mask failed and no local mask for '{target_angle}': {sec_mask_err}\")\n",
        "                        continue\n",
        "\n",
        "                if sec_mask_full is None:\n",
        "                    if sec_mask_path:\n",
        "                        sec_mask_full = Image.open(sec_mask_path).convert(\"L\")\n",
        "                        sec_mask_label = os.path.basename(sec_mask_path)\n",
        "                    else:\n",
        "                        print(f\"      \u26a0\ufe0f Secondary mask missing for '{target_angle}' \u2192 kept main-only output.\")\n",
        "                        continue\n",
        "\n",
        "                sec_garment_img = flatten_alpha_to_white(open_upright(sec_garment_path))\n",
        "\n",
        "                perform_tryon_stage(\n",
        "                    stage_base_full=main_result,\n",
        "                    prompt_text=secondary_prompt_text,\n",
        "                    stage_mask_img=sec_mask_full,\n",
        "                    stage_garment_img=sec_garment_img,\n",
        "                    suffix=\"_both\",\n",
        "                    stage_label=\"secondary\",\n",
        "                    mask_label=sec_mask_label or (os.path.basename(sec_mask_path) if sec_mask_path else \"gemini-mask\"),\n",
        "                    texture_card=secondary_texture_card,\n",
        "                    texture_label=\"Main texture reference\",\n",
        "                    detailer_source_path=sec_garment_path,\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      \u274c Error: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzFKYPQO_RPb"
      },
      "outputs": [],
      "source": [
        "# --- Sheet-driven angle selection + runners ---\n",
        "\n",
        "def build_sku_folder_index(garments_root: str):\n",
        "    return { _norm_sku(os.path.basename(p)) : p for p in iter_sku_folders(garments_root) }\n",
        "\n",
        "def run_list():\n",
        "    targets, unmatched = resolve_targets(SKU_CSV, GARMENTS_ROOT)\n",
        "    if not targets:\n",
        "        print(\"\u26a0\ufe0f No matching SKU folders found.\")\n",
        "        if unmatched: print(\"Unmatched:\", \", \".join(unmatched))\n",
        "        return\n",
        "    print(f\"\u27a1\ufe0f  Will process {len(targets)} SKU(s).\")\n",
        "    for i, p in enumerate(targets, start=1):\n",
        "        name = os.path.basename(p)\n",
        "        print(f\"\\nSKU {i}/{len(targets)} \u25b6\ufe0f  {name}\")\n",
        "        try:\n",
        "            process_one_garment_folder(p, allowed_angles=ALLOWED_BASES)\n",
        "            print(f\"\u2705 Finished: {name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error in {name}: {e}\")\n",
        "    if unmatched:\n",
        "        print(\"\\n\u2139\ufe0f  Unmatched identifiers:\")\n",
        "        for u in unmatched: print(\"   -\", u)\n",
        "    print(\"\\n\ud83c\udfc1 List run complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sinwLlWu_aCm"
      },
      "source": [
        "# DISPATCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJAcEUnW_Y7f"
      },
      "outputs": [],
      "source": [
        "# Dispatch\n",
        "run_list()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK_cKHr9Uutd"
      },
      "source": [
        "#UNASSIGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXlc2wlNyNDm"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "O4KzsXGV_ee1",
        "umaizfLYv7ww",
        "D7pcfKd0_iB_",
        "w3WTzeGw_nEv",
        "HFMF2dYwIlyZ",
        "IU5VwKPQIody"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}