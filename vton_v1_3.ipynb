{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4KzsXGV_ee1"
   },
   "source": [
    "# SETUP (restart after this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7ieaWBKfOOB"
   },
   "outputs": [],
   "source": [
    "!pip install piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3aXFfY54iAH"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Setup: Google auth + Drive + NanoBanana Pro deps ---\n",
    "\n",
    "import sys, os, subprocess, textwrap, importlib\n",
    "\n",
    "from google.colab import auth, drive\n",
    "auth.authenticate_user()\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install -U \"google-genai>=1.40.0\" pillow numpy opencv-python-headless matplotlib gspread google-auth google-auth-oauthlib google-api-python-client piexif tqdm torch torchvision torchaudio transformers timm\n",
    "\n",
    "print(\"\u2705 Setup done for NanoBanana Pro.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umaizfLYv7ww"
   },
   "source": [
    "# Select angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4VplVzrviJT"
   },
   "outputs": [],
   "source": [
    "fr_lft = True #@param {type:\"boolean\"}\n",
    "fr_rght = True #@param {type:\"boolean\"}\n",
    "fr_cl = True #@param {type:\"boolean\"}\n",
    "bc_lft = True #@param {type:\"boolean\"}\n",
    "bc_rght = True #@param {type:\"boolean\"}\n",
    "lft = True #@param {type:\"boolean\"}\n",
    "rght = True #@param {type:\"boolean\"}\n",
    "bc_ = True #@param {type:\"boolean\"}\n",
    "fr_ = True #@param {type:\"boolean\"}\n",
    "fr_cl_btm = False #@param {type:\"boolean\"}\n",
    "fr_cl_tp = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "names = [\"fr_lft\",\"fr_rght\",\"fr_cl\",\"bc_lft\",\"bc_rght\",\"lft\",\"rght\",\"bc_\",\"fr_\",\"fr_cl_btm\",\"fr_cl_tp\"]\n",
    "ALLOWED_BASES = [n for n in names if locals()[n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7pcfKd0_iB_"
   },
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq87guNN-V3D"
   },
   "outputs": [],
   "source": [
    "# --- Unified CONFIG ---\n",
    "\n",
    "# Selection mode: list only\n",
    "RUN_MODE = \"sku_list\"     #@param [\"sku_list\"]\n",
    "\n",
    "# For RUN_MODE == \"sku_list\"\n",
    "SKU_CSV = \"28920, 28747, 29018, 29095, 29094, 28746, 28745\"  #@param {type:\"string\"}\n",
    "\n",
    "# Paths\n",
    "BASE_PHOTOS_ROOT  = \"/content/drive/MyDrive/Dazzl/SikSilk/SKSLK_MODELS/\"\n",
    "GARMENTS_ROOT     = \"/content/drive/MyDrive/Dazzl/SikSilk/AlexGens/SikSilk/\"\n",
    "\n",
    "\n",
    "# Filename/dir policy\n",
    "VALID_EXTENSIONS  = (\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\")\n",
    "IGNORE_DIRS       = {\"old\", \"__MACOSX\", \".ds_store\", \"Ricardo\", \"toweling\"}\n",
    "SKIP_FILENAME_TOKENS_CSV   = \"mask, generated, freelance, _sec, _backup\"   # substrings to skip\n",
    "SKIP_BASENAME_SUFFIXES_CSV = \"_sec\"                             # stem endings to skip\n",
    "REQUIRE_CUT_IN_FILENAME    = False   #@param {type:\"boolean\"}\n",
    "PREFER_AGNOSTIC_MASKS = True #@param {type:\"boolean\"}\n",
    "secondary_garment = True #@param {type:\"boolean\"}\n",
    "SECONDARY_GARMENT = secondary_garment\n",
    "\n",
    "# Cropping / paste-back (square 1:1, generous garment margin)\n",
    "CROP_PADDING      = 100        # px padding around garment when building crop\n",
    "UPPER_PADDING     = 100        # extra padding above garment\n",
    "HORIZ_PADDING     = 100        # horizontal padding\n",
    "MASK_EXPAND_PX    = 200        # outward growth before feather (legacy, left for compatibility)\n",
    "MASK_FEATHER_PX   = 50         # Gaussian sigma for feathering / paste-back taper\n",
    "CROP_MIN_MARGIN   = 0        # minimum margin even if mask touches edge\n",
    "\n",
    "TARGET_ASPECT = (1, 1)         # enforce square crops for 1:1 generations\n",
    "\n",
    "# DINOv3 garment localisation\n",
    "DINO_MODEL_ID         = \"facebook/dinov3-vits16-pretrain-lvd1689m\"\n",
    "DINO_BOX_PERCENTILE   = 82     # percentile for cls-attn heatmap threshold (lower = larger crop)\n",
    "\n",
    "# NanoBanana Pro (Google GenAI)\n",
    "NANOBANANA_MODEL_ID = \"gemini-3-pro-image-preview\"\n",
    "GEN_ASPECT_RATIO    = \"1:1\"\n",
    "GEN_IMAGE_SIZE      = \"4K\"\n",
    "TRYON_PROMPT = \"\"\"You are an expert virtual try-on AI. You will be given a 'model image' and a 'garment image'. Your task is to create a new photorealistic image where the person from the 'model image' is wearing the clothing from the 'garment image'.\n",
    "\n",
    "**Crucial Rules:**\n",
    "1.  **Complete Garment Replacement:** You MUST completely REMOVE and REPLACE the clothing item worn by the person in the 'model image' with the new garment. No part of the original clothing (e.g., collars, sleeves, patterns) should be visible in the final image.\n",
    "2.  **Preserve the Model:** The person's face, hair, tattoos (if any), body shape, and pose from the 'model image' MUST remain unchanged, pixel-for-pixel.\n",
    "3.  **Preserve the Background:** The entire background from the 'model image' MUST be preserved perfectly, pixel-for-pixel. Do not change the background color.\n",
    "4.  **Apply the Garment:** Realistically fit the new garment onto the person. It should adapt to their pose with natural folds, shadows, and lighting consistent with the original scene.\n",
    "5.  **Output:** Return ONLY the final, edited image. Do not include any text.\n",
    "6.  **Bespoke quality:** the garment should be ironed (if applicable) and sit perfectly well \u2014 this is a professional fashion product photoshoot.\"\"\"\n",
    "\n",
    "# Sheet-related (Ops removed) kept only for Gen Log appends\n",
    "SPREADSHEET_ID = \"1Kbq9__sEUQiuDPuza5Xy_hRyIn8pUvmfFj6vhPBrp8Y\"\n",
    "GEN_LOG_SHEET  = \"Gen Log\"\n",
    "\n",
    "# Misc\n",
    "SHOW_VISUALS = True\n",
    "TIMEZONE     = \"Europe/Lisbon\"\n",
    "OPERATOR     = \"Ivan\"\n",
    "OUTPUT_DIR   = \"/content/drive/MyDrive/Dazzl/SikSilk/SS_OUTPUT_FOLDER/v1-3/\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "# === Garment/type taxonomy (kept) ===\n",
    "ALLOWED_GARMENT_TYPES = [\n",
    "    \"hoodie\",\"jeans\",\"joggers\",\"shorts\",\"sweater\",\"swimwear\",\n",
    "    \"t-shirt\",\"shirts\",\"track top\",\"trousers\",\"twinset\",\"polo\",\"vests\",\"shirts\"\n",
    "]\n",
    "TOP_GARMENTS    = [\"t-shirt\",\"shirt\",\"sweater\",\"hoodie\",\"track top\",\"vest\"]\n",
    "BOTTOM_GARMENTS = [\"shorts\",\"jogger-trousers\",\"trousers\",\"jeans\",\"swimwear\"]\n",
    "TWINSET_TYPES   = [\"twinset\"]\n",
    "\n",
    "# === Details tokens ===\n",
    "ALLOWED_DETAIL_TYPES = [\"crest\",\"logo\",\"patch\"]\n",
    "\n",
    "# Angle sheet tokens (kept for compatibility, not used in v1.3)\n",
    "ANGLE_NEEDS_REGENERATE_TOKEN = \"Regenerate\"\n",
    "ENFORCE_BAN_SUBSTRINGS     = True\n",
    "BANNED_SUBSTRINGS_CSV      = \"wrong, pair, combo\"\n",
    "ENFORCE_REQUIRE_SUBSTRINGS = False\n",
    "REQUIRED_SUBSTRINGS_CSV    = \"\"\n",
    "REQUIRED_SUBSTRINGS_MODE   = \"ANY\"   # \"ANY\" | \"ALL\"\n",
    "\n",
    "print(\"\u2705 Config ready for NanoBanana Pro v1.3 (DINOv3 garment localisation)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3WTzeGw_nEv"
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAeR9BUW-8Lp"
   },
   "outputs": [],
   "source": [
    "# --- Core utilities: normalization, angles, walking, DINOv3 garment localisation ---\n",
    "\n",
    "import os, re, fnmatch, math, uuid, pytz, random, gc, tempfile, traceback\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageChops, ImageFilter, ImageDraw\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "def normalize_sku_list(sku_csv: str) -> str:\n",
    "    skus = []\n",
    "    for raw in sku_csv.split(','):\n",
    "        sku = raw.strip().upper()\n",
    "        match = re.search(r'(\\d+)', sku)\n",
    "        if match:\n",
    "            sku_number = match.group(1)\n",
    "            skus.append(f\"SS-{sku_number}\")\n",
    "    # Return as CSV string\n",
    "    return \", \".join(skus)\n",
    "\n",
    "SKU_CSV = normalize_sku_list(SKU_CSV)\n",
    "\n",
    "# Parsers\n",
    "def _parse_csv_list(s):  return [x.strip().casefold() for x in (s or \"\").split(\",\") if x.strip()]\n",
    "BANNED_SUBSTRINGS       = _parse_csv_list(BANNED_SUBSTRINGS_CSV)\n",
    "REQUIRED_SUBSTRINGS     = _parse_csv_list(REQUIRED_SUBSTRINGS_CSV)\n",
    "SKIP_FILENAME_TOKENS    = set(_parse_csv_list(SKIP_FILENAME_TOKENS_CSV))\n",
    "SKIP_BASENAME_SUFFIXES  = tuple(_parse_csv_list(SKIP_BASENAME_SUFFIXES_CSV))\n",
    "\n",
    "# Normalizers\n",
    "def _norm_sku(s):\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).replace(\"\\u00A0\",\" \")\n",
    "    s = \" \".join(s.split())\n",
    "    return s.casefold()\n",
    "\n",
    "def _norm_angle(s):\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return s.strip(\"_ \").replace(\"-\", \"_\")\n",
    "\n",
    "# Angle aliases\n",
    "ANGLE_ALIASES = {\n",
    "    \"fr_cl\":   [\"fr\", \"fr_\"],\n",
    "    \"fr\":      [\"fr_cl\"],\n",
    "    \"bc_lft\":  [\"bc\", \"bc_\"],\n",
    "    \"bc_rght\": [\"bc\", \"bc_\"],\n",
    "}\n",
    "\n",
    "\n",
    "# --- Helpers to keep outputs strict, sources flexible ---\n",
    "def expand_as_list(angles):\n",
    "    exp = list(expand_allowed_angles(angles))\n",
    "    exp = [_norm_angle(a) for a in exp]\n",
    "    exp.sort(key=len, reverse=True)  # prefer 'fr_cl' over 'fr'\n",
    "    return exp\n",
    "\n",
    "def pick_target_angle(source_angle: str, allowed_outputs: set) -> str | None:\n",
    "    s = _norm_angle(source_angle)\n",
    "    for target in allowed_outputs:\n",
    "        fam = {_norm_angle(x) for x in expand_allowed_angles([target])}\n",
    "        if s in fam:\n",
    "            return _norm_angle(target)\n",
    "    return None\n",
    "\n",
    "\n",
    "def expand_allowed_angles(angles):\n",
    "    expanded = set()\n",
    "    for a in (angles or []):\n",
    "        a_norm = _norm_angle(a)\n",
    "        expanded.add(a_norm)\n",
    "        for alt in ANGLE_ALIASES.get(a_norm, []):\n",
    "            expanded.add(_norm_angle(alt))\n",
    "    return expanded\n",
    "\n",
    "# Ignore set\n",
    "IGNORE_DIRS = {d.lower() for d in IGNORE_DIRS}\n",
    "\n",
    "# Walkers\n",
    "def _is_sku_folder(path: str) -> bool:\n",
    "    if os.path.basename(os.path.normpath(path)).lower() in IGNORE_DIRS:\n",
    "        return False\n",
    "    try:\n",
    "        for f in os.listdir(path):\n",
    "            if os.path.isfile(os.path.join(path, f)) and f.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS)):\n",
    "                return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def iter_sku_folders(root: str):\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        dirnames[:] = [d for d in dirnames if d.lower() not in IGNORE_DIRS]\n",
    "        if any(f.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS)) for f in filenames):\n",
    "            yield dirpath\n",
    "\n",
    "def resolve_targets(idents_csv: str, garments_root: str):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      \u2022 Plain SKU names, relative paths (Category/Subcategory/SKU), or absolute dirs\n",
    "      \u2022 Glob patterns (e.g., 'Hoodies/*' or 'SKSLK_12*')\n",
    "      \u2022 Directories that are NOT SKU leaves \u2192 expand to all descendant SKU leaves\n",
    "    \"\"\"\n",
    "    idents = [s.strip() for s in idents_csv.replace(\"\\n\", \",\").split(\",\") if s.strip()]\n",
    "    if not idents: return [], []\n",
    "\n",
    "    all_sku_dirs = list(iter_sku_folders(garments_root))\n",
    "    rel_map = {p: os.path.relpath(p, garments_root) for p in all_sku_dirs}\n",
    "    base_map = {p: os.path.basename(p) for p in all_sku_dirs}\n",
    "\n",
    "    seen, out, unmatched = set(), [], []\n",
    "    def add_path(p):\n",
    "        ap = os.path.abspath(p)\n",
    "        if os.path.isdir(ap):\n",
    "            if _is_sku_folder(ap):\n",
    "                if ap not in seen:\n",
    "                    seen.add(ap); out.append(ap)\n",
    "            else:\n",
    "                # Expand directory to all descendant SKU leaves\n",
    "                for leaf in iter_sku_folders(ap):\n",
    "                    a = os.path.abspath(leaf)\n",
    "                    if a not in seen:\n",
    "                        seen.add(a); out.append(a)\n",
    "\n",
    "    for ident in idents:\n",
    "        before = len(out)\n",
    "        # Absolute directory or SKU path\n",
    "        if os.path.isabs(ident) and os.path.isdir(ident):\n",
    "            add_path(ident)\n",
    "\n",
    "        # Relative under garments root (dir or SKU)\n",
    "        rel_candidate = os.path.join(garments_root, ident)\n",
    "        if os.path.exists(rel_candidate):\n",
    "            add_path(rel_candidate)\n",
    "\n",
    "        # Glob/pattern over known SKU leaves (by basename or relative path)\n",
    "        for p in all_sku_dirs:\n",
    "            if fnmatch.fnmatch(base_map[p], ident) or fnmatch.fnmatch(rel_map[p], ident):\n",
    "                add_path(p)\n",
    "\n",
    "        if len(out) == before:\n",
    "            unmatched.append(ident)\n",
    "\n",
    "    out.sort()\n",
    "    return out, unmatched\n",
    "\n",
    "# Base/mask location resolution\n",
    "def resolve_base_mask_dir(sku_folder: str,\n",
    "                          garments_root: str = GARMENTS_ROOT,\n",
    "                          base_root: str = BASE_PHOTOS_ROOT):\n",
    "    \"\"\"\n",
    "    Map .../GARMENTS_ROOT/Category/Subcategory/SKU \u2192 .../BASE_ROOT/Category/Subcategory\n",
    "    With robust fallbacks.\n",
    "    \"\"\"\n",
    "    abs_sku = os.path.abspath(sku_folder)\n",
    "    abs_gar = os.path.abspath(garments_root)\n",
    "    try:\n",
    "        rel = os.path.relpath(abs_sku, abs_gar)\n",
    "    except Exception:\n",
    "        rel = None\n",
    "\n",
    "    if rel and not rel.startswith(\"..\"):\n",
    "        rel_parent = os.path.dirname(rel)\n",
    "        cand = os.path.join(base_root, rel_parent)\n",
    "        if os.path.isdir(cand): return cand\n",
    "\n",
    "    subcat = os.path.basename(os.path.dirname(abs_sku))\n",
    "    cat    = os.path.basename(os.path.dirname(os.path.dirname(abs_sku)))\n",
    "    cand2  = os.path.join(base_root, cat, subcat)\n",
    "    if os.path.isdir(cand2): return cand2\n",
    "\n",
    "    cand3  = os.path.join(base_root, subcat)\n",
    "    if os.path.isdir(cand3): return cand3\n",
    "    return None\n",
    "\n",
    "def _valid_ext(fname): return fname.lower().endswith(tuple(e.lower() for e in VALID_EXTENSIONS))\n",
    "\n",
    "def _file_prefix_or_none(filename: str):\n",
    "    low = filename.lower()\n",
    "    for base in ALLOWED_BASES:\n",
    "        if low.startswith(base): return base\n",
    "    return None\n",
    "\n",
    "def _find_image_with_stem_and_suffix(directory, stem, suffix=\"\"):\n",
    "    if not directory or not os.path.isdir(directory):\n",
    "        return None\n",
    "    stem = stem.lower()\n",
    "    for file in os.listdir(directory):\n",
    "        fname, fext = os.path.splitext(file)\n",
    "        if fext.lower() in (\".png\",\".jpg\",\".jpeg\") and fname.lower() == f\"{stem}{suffix}\":\n",
    "            return os.path.join(directory, file)\n",
    "    return None\n",
    "\n",
    "# --- Existence check in Google Drive by Colab-style path ---\n",
    "def drive_file_exists_any_ext_at_colab_path(target_colab_path: str,\n",
    "                                            exts=(\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\")) -> bool:\n",
    "    \"\"\"\n",
    "    Given a Colab-style *file* path (incl. a filename with any extension),\n",
    "    checks if a file with the SAME stem exists in the same folder with any of the allowed extensions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parent_id, desired_name = _resolve_parent_id_and_filename_from_colab_path(target_colab_path)\n",
    "        stem, _ = os.path.splitext(desired_name)\n",
    "        files = _list_children(parent_id, q_extra=\"\")  # list once; filter locally\n",
    "        allowed = {e.lower() for e in exts}\n",
    "        for f in files:\n",
    "            fname = f.get(\"name\", \"\")\n",
    "            s, e = os.path.splitext(fname)\n",
    "            if s == stem and e.lower() in allowed:\n",
    "                return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f Ext-agnostic existence check failed for {target_colab_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# === NEW: mask finding with AGNOSTIC priority ===\n",
    "def find_mask_path(base_subcat_dir: str, stem_no_cut: str):\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "      1) {stem}_mask_agnostic.(png|jpg|jpeg)\n",
    "      2) {stem}_mask.(png|jpg|jpeg)\n",
    "    \"\"\"\n",
    "    if not base_subcat_dir or not os.path.isdir(base_subcat_dir):\n",
    "        return None\n",
    "\n",
    "    candidates = []\n",
    "    if PREFER_AGNOSTIC_MASKS:\n",
    "      for ext in (\".png\",\".jpg\",\".jpeg\",\".PNG\",\".JPG\",\".JPEG\"):\n",
    "          candidates.append(os.path.join(base_subcat_dir, f\"{stem_no_cut}_mask_agnostic{ext}\"))\n",
    "    for ext in (\".png\",\".jpg\",\".jpeg\",\".PNG\",\".JPG\",\".JPEG\"):\n",
    "        candidates.append(os.path.join(base_subcat_dir, f\"{stem_no_cut}_mask{ext}\"))\n",
    "\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_secondary_garment_path(folder_path: str, main_filename: str):\n",
    "    \"\"\"\n",
    "    Locate the secondary garment paired with a primary garment file.\n",
    "    Example: main 'bc_lft_cut.png' -> looks for 'bc_lft_sec_cut.(png|jpg)'.\n",
    "    Falls back to a non-cut variant when REQUIRE_CUT_IN_FILENAME is False.\n",
    "    \"\"\"\n",
    "    stem, _ = os.path.splitext(main_filename)\n",
    "    has_cut = stem.endswith(\"_cut\")\n",
    "    core = stem[:-4] if has_cut else stem\n",
    "\n",
    "    candidates = [f\"{core}_sec_cut\"]\n",
    "    if not REQUIRE_CUT_IN_FILENAME:\n",
    "        candidates.append(f\"{core}_sec\")\n",
    "    if not has_cut:\n",
    "        candidates.append(f\"{stem}_sec_cut\")\n",
    "\n",
    "    seen = set()\n",
    "    for cand in candidates:\n",
    "        if cand in seen:\n",
    "            continue\n",
    "        seen.add(cand)\n",
    "        for ext in VALID_EXTENSIONS:\n",
    "            path = os.path.join(folder_path, f\"{cand}{ext}\")\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "    return None\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# --- Aspect-ratio bbox (legacy) ---\n",
    "\n",
    "\n",
    "def find_aspect_bbox(\n",
    "    mask: Image.Image,\n",
    "    aspect: tuple[int,int] = (1,1),   # width:height, e.g. (1280,1600)\n",
    "    padding: int = 40,\n",
    "    upper_padding: int | None = None,\n",
    "    horiz_padding: int = 0,\n",
    "    min_margin: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Return a rectangular bbox [x0, y0, x1, y1] that fully contains the mask + padding\n",
    "    and matches the requested aspect ratio by expanding outward only.\n",
    "    \"\"\"\n",
    "    if min_margin is None:\n",
    "        try:\n",
    "            min_margin = int(MASK_EXPAND_PX + 3 * MASK_FEATHER_PX + 5)\n",
    "        except Exception:\n",
    "            min_margin = 40\n",
    "\n",
    "    m = np.array(mask.convert(\"L\"))\n",
    "    h, w = m.shape\n",
    "    ys, xs = np.where(m > 128)\n",
    "    if xs.size == 0:\n",
    "        raise ValueError(\"Mask has no white pixels!\")\n",
    "\n",
    "    x_min, x_max = int(xs.min()), int(xs.max())\n",
    "    y_min, y_max = int(ys.min()), int(ys.max())\n",
    "\n",
    "    if upper_padding is None:\n",
    "        upper_padding = padding\n",
    "\n",
    "    # Initial padded bbox\n",
    "    x0 = max(0, x_min - horiz_padding - min_margin)\n",
    "    x1 = min(w, x_max + horiz_padding + min_margin)\n",
    "    y0 = max(0, y_min - upper_padding - min_margin)\n",
    "    y1 = min(h, y_max + padding + min_margin)\n",
    "\n",
    "    bw, bh = (x1 - x0), (y1 - y0)\n",
    "    # Desired aspect as float\n",
    "    aw, ah = aspect\n",
    "    target_ar = float(aw) / float(max(1, ah))\n",
    "\n",
    "    # First pass: try to match aspect by expanding one dimension only\n",
    "    def expand_to_aspect(x0, y0, x1, y1):\n",
    "        bw = x1 - x0; bh = y1 - y0\n",
    "        cur_ar = bw / float(max(1, bh))\n",
    "        if cur_ar < target_ar:\n",
    "            # too tall \u2192 need wider\n",
    "            need_w = int(np.ceil(target_ar * bh))\n",
    "            grow = max(0, need_w - bw)\n",
    "            left_grow  = min(x0, grow // 2)\n",
    "            right_grow = min(w - x1, grow - left_grow)\n",
    "            x0 -= left_grow; x1 += right_grow\n",
    "        elif cur_ar > target_ar:\n",
    "            # too wide \u2192 need taller\n",
    "            need_h = int(np.ceil(bw / target_ar))\n",
    "            grow = max(0, need_h - bh)\n",
    "            top_grow    = min(y0, grow // 2)\n",
    "            bottom_grow = min(h - y1, grow - top_grow)\n",
    "            y0 -= top_grow; y1 += bottom_grow\n",
    "        return max(0,x0), max(0,y0), min(w,x1), min(h,y1)\n",
    "\n",
    "    x0, y0, x1, y1 = expand_to_aspect(x0, y0, x1, y1)\n",
    "\n",
    "    # Second pass: if a border capped us, re-try by expanding the other dimension\n",
    "    bw, bh = (x1 - x0), (y1 - y0)\n",
    "    cur_ar = bw / float(max(1, bh))\n",
    "    if abs(cur_ar - target_ar) > 1e-3:\n",
    "        if cur_ar < target_ar:\n",
    "            # could not widen enough \u2192 try to grow height\n",
    "            need_h = int(np.ceil(bw / target_ar))\n",
    "            grow = max(0, need_h - bh)\n",
    "            top_grow    = min(y0, grow // 2)\n",
    "            bottom_grow = min(h - y1, grow - top_grow)\n",
    "            y0 -= top_grow; y1 += bottom_grow\n",
    "        else:\n",
    "            # could not heighten enough \u2192 try to grow width\n",
    "            need_w = int(np.ceil(target_ar * bh))\n",
    "            grow = max(0, need_w - bw)\n",
    "            left_grow  = min(x0, grow // 2)\n",
    "            right_grow = min(w - x1, grow - left_grow)\n",
    "            x0 -= left_grow; x1 += right_grow\n",
    "\n",
    "    # Final clamp\n",
    "    x0, y0 = max(0, int(x0)), max(0, int(y0))\n",
    "    x1, y1 = min(w, int(x1)), min(h, int(y1))\n",
    "    return [x0, y0, x1, y1]\n",
    "\n",
    "\n",
    "# Alpha/white utilities for garment panel\n",
    "WHITE_RGB = (255,255,255)\n",
    "def flatten_alpha_to_white(img: Image.Image) -> Image.Image:\n",
    "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
    "        bg = Image.new(\"RGB\", img.size, WHITE_RGB)\n",
    "        bg.paste(img, mask=img.split()[-1])\n",
    "        return bg\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "def _tight_bbox_nonwhite_or_opaque(img: Image.Image):\n",
    "    if img.mode in (\"RGBA\",\"LA\") or (\"transparency\" in img.info):\n",
    "        arr = np.asarray(img.convert(\"RGBA\"))\n",
    "        alpha = arr[...,3]\n",
    "        fg = alpha > 0\n",
    "    else:\n",
    "        arr = np.asarray(img.convert(\"RGB\"))\n",
    "        fg = ~((arr[...,0]==255)&(arr[...,1]==255)&(arr[...,2]==255))\n",
    "    if not np.any(fg): return None\n",
    "    ys, xs = np.where(fg)\n",
    "    x0, x1 = int(xs.min()), int(xs.max())+1\n",
    "    y0, y1 = int(ys.min()), int(ys.max())+1\n",
    "    return (x0,y0,x1,y1)\n",
    "\n",
    "def crop_garment_keep_aspect(img: Image.Image) -> Image.Image:\n",
    "    bbox = _tight_bbox_nonwhite_or_opaque(img)\n",
    "    base = flatten_alpha_to_white(img)\n",
    "    if bbox is None: return base\n",
    "    full_bbox = (0,0,base.width,base.height)\n",
    "    if bbox == full_bbox: return base\n",
    "    return base.crop(bbox)\n",
    "\n",
    "def to_centered_square(gar: Image.Image, fill=WHITE_RGB) -> Image.Image:\n",
    "    w,h = gar.size; side = max(w,h)\n",
    "    sq = Image.new(\"RGB\", (side, side), fill)\n",
    "    ox, oy = (side-w)//2, (side-h)//2\n",
    "    sq.paste(gar, (ox,oy)); return sq\n",
    "\n",
    "# --- DINOv3 garment localisation\n",
    "from dino import (\n",
    "    detect_garment_region_with_dinov3,\n",
    "    heatmap_to_pil,\n",
    "    draw_bbox,\n",
    "    infer_garment_type_from_path,\n",
    "    garment_position_hint,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbJ9VKUEzhaP"
   },
   "outputs": [],
   "source": [
    "# --- Visualisation helpers (restored) ---\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "def open_upright(path) -> Image.Image:\n",
    "    # EXIF-aware loader (same as before)\n",
    "    with Image.open(path) as im:\n",
    "        return ImageOps.exif_transpose(im)\n",
    "\n",
    "def show_gallery(img_list, titles=None, cols=3, w=4):\n",
    "    \"\"\"\n",
    "    Display PIL images in a flexible grid (identical behaviour to your original).\n",
    "    Only renders if SHOW_VISUALS is True.\n",
    "    \"\"\"\n",
    "    if not globals().get(\"SHOW_VISUALS\", False):\n",
    "        return\n",
    "\n",
    "    n = len(img_list)\n",
    "    rows = math.ceil(n / cols)\n",
    "    plt.figure(figsize=(cols * w, rows * w))\n",
    "\n",
    "    for i, img in enumerate(img_list):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        # Accept PIL, torch tensors or numpy arrays (4-D batch \u21d2 pick first)\n",
    "        if isinstance(img, np.ndarray) and img.ndim == 4:\n",
    "            img = img[0]  # (B,H,W,C) \u2192 (H,W,C)\n",
    "        # Torch tensors are printed via duck-typing check to avoid hard import\n",
    "        if \"Tensor\" in str(type(img)):\n",
    "            img = img.detach().cpu().permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        if titles and i < len(titles):\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOhtSL7B-_-f"
   },
   "outputs": [],
   "source": [
    "# --- Paste-back (square with padding + feather) ---\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def build_square_feather_mask(size, feather_px: int):\n",
    "    w, h = size\n",
    "    xx = np.tile(np.arange(w)[None, :], (h, 1))\n",
    "    yy = np.tile(np.arange(h)[:, None], (1, w))\n",
    "    dist_edge = np.minimum.reduce([xx, w - 1 - xx, yy, h - 1 - yy]).astype(np.float32)\n",
    "    alpha = np.ones((h, w), np.float32) * 255.0\n",
    "    if feather_px > 0:\n",
    "        band = dist_edge < float(feather_px)\n",
    "        alpha[band] = (dist_edge[band] / float(feather_px)) * 255.0\n",
    "    return Image.fromarray(alpha.clip(0, 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "\n",
    "def make_square_crop_with_padding(full_img: Image.Image, bbox, fill=WHITE_RGB):\n",
    "    \"\"\"Return (square_crop, square_box) where square_box can extend outside the image.\n",
    "    Missing areas are padded with `fill` so the crop we feed to NanoBanana is always 1:1.\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = map(int, bbox)\n",
    "    bw, bh = x1 - x0, y1 - y0\n",
    "    side = max(bw, bh, 1)\n",
    "\n",
    "    extra_w = side - bw\n",
    "    extra_h = side - bh\n",
    "    sq_x0 = x0 - extra_w // 2\n",
    "    sq_y0 = y0 - extra_h // 2\n",
    "    sq_x1 = sq_x0 + side\n",
    "    sq_y1 = sq_y0 + side\n",
    "\n",
    "    # Clamp the part we can actually copy from the original image\n",
    "    img_w, img_h = full_img.size\n",
    "    src_x0 = max(0, sq_x0)\n",
    "    src_y0 = max(0, sq_y0)\n",
    "    src_x1 = min(img_w, sq_x1)\n",
    "    src_y1 = min(img_h, sq_y1)\n",
    "\n",
    "    crop = full_img.crop((src_x0, src_y0, src_x1, src_y1))\n",
    "    canvas = Image.new(\"RGB\", (side, side), fill)\n",
    "    paste_x = src_x0 - sq_x0\n",
    "    paste_y = src_y0 - sq_y0\n",
    "    canvas.paste(crop, (paste_x, paste_y))\n",
    "\n",
    "    square_box = [sq_x0, sq_y0, sq_x1, sq_y1]\n",
    "    return canvas, square_box\n",
    "\n",
    "\n",
    "def paste_crop_back_square(\n",
    "    full_img: Image.Image,\n",
    "    edited_crop: Image.Image,\n",
    "    crop_box,\n",
    "    feather_px: int = 30,\n",
    "):\n",
    "    \"\"\"Paste a (possibly padded) square crop back into the original frame.\n",
    "    crop_box may extend beyond the source image; we only blend the overlapping region.\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = map(int, crop_box)\n",
    "    side = x1 - x0\n",
    "    if side <= 0:\n",
    "        return full_img\n",
    "\n",
    "    edit_sq = edited_crop.resize((side, side), Image.Resampling.LANCZOS)\n",
    "    mask_sq = build_square_feather_mask((side, side), feather_px)\n",
    "\n",
    "    # Overlap region between crop_box and the base image\n",
    "    img_w, img_h = full_img.size\n",
    "    ix0, iy0 = max(0, x0), max(0, y0)\n",
    "    ix1, iy1 = min(img_w, x1), min(img_h, y1)\n",
    "    if ix0 >= ix1 or iy0 >= iy1:\n",
    "        return full_img\n",
    "\n",
    "    # Corresponding region inside the square crop\n",
    "    cx0 = ix0 - x0\n",
    "    cy0 = iy0 - y0\n",
    "    cx1 = cx0 + (ix1 - ix0)\n",
    "    cy1 = cy0 + (iy1 - iy0)\n",
    "\n",
    "    edit_region = edit_sq.crop((cx0, cy0, cx1, cy1))\n",
    "    mask_region = mask_sq.crop((cx0, cy0, cx1, cy1))\n",
    "    base_region = full_img.crop((ix0, iy0, ix1, iy1))\n",
    "\n",
    "    comp = Image.composite(edit_region, base_region, mask_region)\n",
    "    full_img.paste(comp, (ix0, iy0))\n",
    "    return full_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Br9dskEm_CBL"
   },
   "outputs": [],
   "source": [
    "# --- NanoBanana Pro try-on (Google Cloud GenAI) ---\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "\n",
    "def _load_gemini_api_key():\n",
    "    key = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GEMINI_APIKEY\")\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        key = key or userdata.get(\"GEMINI_API_KEY\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not key:\n",
    "        raise ValueError(\"Set GEMINI_API_KEY in environment or Colab userdata.\")\n",
    "    return key\n",
    "\n",
    "genai_client = genai.Client(api_key=_load_gemini_api_key())\n",
    "\n",
    "def _extract_first_image(resp):\n",
    "    import io\n",
    "    parts = []\n",
    "    if hasattr(resp, \"parts\"):\n",
    "        parts.extend(resp.parts)\n",
    "    for cand in getattr(resp, \"candidates\", []):\n",
    "        parts.extend(getattr(getattr(cand, \"content\", None), \"parts\", []) or [])\n",
    "\n",
    "    for part in parts:\n",
    "        if isinstance(part, Image.Image):\n",
    "            return part\n",
    "        as_image = getattr(part, \"as_image\", None)\n",
    "        if callable(as_image):\n",
    "            img = as_image()\n",
    "            if isinstance(img, Image.Image):\n",
    "                return img\n",
    "        inline = getattr(part, \"inline_data\", None)\n",
    "        if inline and getattr(inline, \"data\", None):\n",
    "            return Image.open(io.BytesIO(inline.data)).convert(\"RGB\")\n",
    "    raise ValueError(\"No image returned from NanoBanana Pro response.\")\n",
    "\n",
    "\n",
    "def run_nanobanana_tryon(model_image: Image.Image, garment_image: Image.Image,\n",
    "                         *, aspect_ratio: str = GEN_ASPECT_RATIO,\n",
    "                         image_size: str = GEN_IMAGE_SIZE,\n",
    "                         prompt: str | None = None):\n",
    "    prompt_text = prompt or TRYON_PROMPT\n",
    "    resp = genai_client.models.generate_content(\n",
    "        model=NANOBANANA_MODEL_ID,\n",
    "        contents=[\n",
    "            prompt_text,\n",
    "            \"Model image:\",\n",
    "            model_image.convert(\"RGB\"),\n",
    "            \"Garment image:\",\n",
    "            garment_image.convert(\"RGB\"),\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"IMAGE\"],\n",
    "            image_config=types.ImageConfig(\n",
    "                aspect_ratio=aspect_ratio,\n",
    "                image_size=image_size,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    img = _extract_first_image(resp)\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "print(\"\u2705 NanoBanana Pro client ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfNf3NHxjMaj"
   },
   "outputs": [],
   "source": [
    "# Colab cell \u2014 output routing + metadata helpers\n",
    "import os, json\n",
    "from PIL import PngImagePlugin\n",
    "\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "def build_output_filename(sku_name: str, angle_code: str, ext=\".png\", suffix=\"\") -> str:\n",
    "    # Examples: SS-12345-fr_rght or SS-12345-bc_lft\n",
    "    angle_clean = _norm_angle(angle_code)\n",
    "    suffix = suffix or \"\"\n",
    "    return f\"{sku_name}-{angle_clean}{suffix}{ext}\"\n",
    "\n",
    "\n",
    "import json, piexif\n",
    "from PIL import Image\n",
    "\n",
    "def save_png_with_metadata(img, out_path, details_payload=None, quality=95):\n",
    "    if details_payload:\n",
    "        # Encode JSON as UTF-8 with an ASCII prefix per EXIF spec for UserComment\n",
    "        payload = json.dumps(details_payload, ensure_ascii=False).encode(\"utf-8\")\n",
    "        user_comment = b\"ASCII\\x00\\x00\\x00\" + payload  # indicates undefined/UTF-8\n",
    "        exif_dict = {\"0th\": {}, \"Exif\": {piexif.ExifIFD.UserComment: user_comment}, \"1st\": {}, \"GPS\": {}, \"Interop\": {}}\n",
    "        exif_bytes = piexif.dump(exif_dict)\n",
    "        img.save(out_path, format=\"PNG\", exif=exif_bytes)\n",
    "    else:\n",
    "        img.save(out_path, format=\"PNG\")\n",
    "\n",
    "import json, piexif\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBN_kgOo_GRI"
   },
   "outputs": [],
   "source": [
    "# --- Google APIs: gspread + Drive upload (Operations sync removed) ---\n",
    "\n",
    "import google.auth\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive\", \"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "creds, _ = google.auth.default(scopes=SCOPES)\n",
    "\n",
    "import gspread\n",
    "gs = gspread.authorize(creds)\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "drive_svc = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "FOLDER_MIME   = \"application/vnd.google-apps.folder\"\n",
    "SHORTCUT_MIME = \"application/vnd.google-apps.shortcut\"\n",
    "PATH_PREFIX   = \"/content/drive/MyDrive/\"\n",
    "\n",
    "def _escape_name(name: str) -> str: return name.replace(\"'\", r\"'\")\n",
    "\n",
    "def _maybe_follow_shortcut(file_obj):\n",
    "    if file_obj.get(\"mimeType\") == SHORTCUT_MIME:\n",
    "        sd = file_obj.get(\"shortcutDetails\", {}) or {}\n",
    "        return sd.get(\"targetId\"), sd.get(\"targetMimeType\")\n",
    "    return file_obj.get(\"id\"), file_obj.get(\"mimeType\")\n",
    "\n",
    "def _list_children(parent_id: str, q_extra: str, page_size: int = 1000):\n",
    "    q = f\"'{parent_id}' in parents and trashed = false\"\n",
    "    if q_extra: q += f\" and ({q_extra})\"\n",
    "    resp = drive_svc.files().list(\n",
    "        q=q, spaces=\"drive\", pageSize=page_size,\n",
    "        fields=\"files(id,name,mimeType,shortcutDetails)\",\n",
    "        includeItemsFromAllDrives=True, supportsAllDrives=True,\n",
    "    ).execute()\n",
    "    return resp.get(\"files\", [])\n",
    "\n",
    "def _find_folder_id(parent_id: str, name: str):\n",
    "    files = _list_children(\n",
    "        parent_id,\n",
    "        q_extra=(\n",
    "            f\"name = '{_escape_name(name)}' and \"\n",
    "            f\"(mimeType = '{FOLDER_MIME}' or mimeType = '{SHORTCUT_MIME}')\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Direct folder match\n",
    "    for f in files:\n",
    "        if f[\"mimeType\"] == FOLDER_MIME:\n",
    "            return f[\"id\"]\n",
    "\n",
    "    # Shortcut to folder\n",
    "    for f in files:\n",
    "        if f[\"mimeType\"] == SHORTCUT_MIME:\n",
    "            tid, tmime = _maybe_follow_shortcut(f)\n",
    "            if tmime == FOLDER_MIME:\n",
    "                return tid\n",
    "\n",
    "    # Fallback: match by case-insensitive name\n",
    "    files = _list_children(\n",
    "        parent_id,\n",
    "        q_extra=(\n",
    "            f\"(mimeType = '{FOLDER_MIME}' or mimeType = '{SHORTCUT_MIME}')\"\n",
    "        ),\n",
    "    )\n",
    "    needle = name.strip().casefold()\n",
    "\n",
    "    for f in files:\n",
    "        if f.get(\"name\", \"\").strip().casefold() == needle:\n",
    "            tid, tmime = _maybe_follow_shortcut(f)\n",
    "            if tmime == FOLDER_MIME:\n",
    "                return tid\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _resolve_parent_id_and_filename_from_colab_path(colab_path: str):\n",
    "    if not colab_path.startswith(PATH_PREFIX):\n",
    "        raise ValueError(\n",
    "            f\"This helper supports only '{PATH_PREFIX}...'. Got: {colab_path}\"\n",
    "        )\n",
    "\n",
    "    parts = colab_path[len(PATH_PREFIX):].strip(\"/\").split(\"/\")\n",
    "    if not parts:\n",
    "        raise ValueError(\"Path must include a file name.\")\n",
    "\n",
    "    parent_id = \"root\"\n",
    "\n",
    "    for part in parts[:-1]:\n",
    "        next_id = _find_folder_id(parent_id, part)\n",
    "        if not next_id:\n",
    "            raise FileNotFoundError(f\"Folder not found in path: '{part}'\")\n",
    "        parent_id = next_id\n",
    "\n",
    "    desired_name = parts[-1]\n",
    "    return parent_id, desired_name\n",
    "\n",
    "\n",
    "def upload_to_drive_folder(\n",
    "    local_path: str,\n",
    "    parent_folder_id: str,\n",
    "    desired_name: str | None = None\n",
    "):\n",
    "    media = MediaFileUpload(local_path, resumable=True)\n",
    "    body = {\n",
    "        \"name\": desired_name or os.path.basename(local_path),\n",
    "        \"parents\": [parent_folder_id],\n",
    "    }\n",
    "\n",
    "    file = (\n",
    "        drive_svc.files()\n",
    "        .create(\n",
    "            body=body,\n",
    "            media_body=media,\n",
    "            fields=\"id, webViewLink, name, parents\",\n",
    "            supportsAllDrives=True,\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    drive_svc.permissions().create(\n",
    "        fileId=file[\"id\"],\n",
    "        body={\"type\": \"anyone\", \"role\": \"reader\"},\n",
    "        fields=\"id\",\n",
    "        supportsAllDrives=True,\n",
    "    ).execute()\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "def upload_file_and_append_to_sheet(\n",
    "    local_path: str,\n",
    "    target_colab_path: str,\n",
    "    sku_name: str,\n",
    "    angle: str,\n",
    "    spreadsheet_id: str | None,\n",
    "    worksheet_name: str | None,\n",
    "):\n",
    "    parent_id, desired_name = _resolve_parent_id_and_filename_from_colab_path(\n",
    "        target_colab_path\n",
    "    )\n",
    "\n",
    "    uploaded = upload_to_drive_folder(local_path, parent_id, desired_name)\n",
    "    file_id = uploaded[\"id\"]\n",
    "\n",
    "    file_url = (\n",
    "        uploaded.get(\"webViewLink\")\n",
    "        or f\"https://drive.google.com/file/d/{file_id}/view?usp=sharing\"\n",
    "    )\n",
    "    folder_url = f\"https://drive.google.com/drive/folders/{parent_id}\"\n",
    "\n",
    "    if spreadsheet_id and worksheet_name:\n",
    "        ts = datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%m-%d %H:%M:%S\")\n",
    "        uid = str(uuid.uuid4())\n",
    "\n",
    "        sh = gs.open_by_key(spreadsheet_id)\n",
    "        ws = sh.worksheet(worksheet_name)\n",
    "\n",
    "        sku_cell = f'=HYPERLINK(\"{folder_url}\"; \"{sku_name}\")'\n",
    "\n",
    "        ws.append_row(\n",
    "            [\n",
    "                sku_cell,\n",
    "                angle,\n",
    "                ts,\n",
    "                file_url,\n",
    "                uid,\n",
    "                \"Girls need to check\",\n",
    "                OPERATOR,\n",
    "            ],\n",
    "            value_input_option=\"USER_ENTERED\",\n",
    "        )\n",
    "\n",
    "    return {\"file_url\": file_url}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IU5VwKPQIody"
   },
   "source": [
    "# BATCH HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQi5CzF2_O92"
   },
   "outputs": [],
   "source": [
    "# --- Batch processor  ---\n",
    "\n",
    "\n",
    "def process_one_garment_folder(folder_path: str, allowed_angles=None):\n",
    "    allowed_outputs_set = {_norm_angle(a) for a in (allowed_angles or [])}\n",
    "    allowed_outputs = sorted(allowed_outputs_set)\n",
    "    allowed_sources = expand_as_list(allowed_angles) if allowed_angles else None\n",
    "\n",
    "    base_subcat_dir = resolve_base_mask_dir(folder_path)\n",
    "    if not base_subcat_dir:\n",
    "        print(f\"\u26a0\ufe0f Cannot resolve base dir for SKU: {folder_path}\")\n",
    "    files_sorted = sorted(os.listdir(folder_path))\n",
    "\n",
    "    garment_type = infer_garment_type_from_path(folder_path) or \"garment\"\n",
    "\n",
    "    worklist = []\n",
    "    for file in files_sorted:\n",
    "        low = file.lower()\n",
    "\n",
    "        if allowed_sources and not any(low.startswith(src) for src in allowed_sources):\n",
    "            continue\n",
    "        if SKIP_FILENAME_TOKENS and any(tok in low for tok in SKIP_FILENAME_TOKENS):\n",
    "            continue\n",
    "        if REQUIRE_CUT_IN_FILENAME and (\"cut\" not in low):\n",
    "            continue\n",
    "        if not _valid_ext(file):\n",
    "            continue\n",
    "\n",
    "        matching_sources = [src for src in (allowed_sources or []) if low.startswith(src)] if allowed_sources else [_norm_angle(os.path.splitext(file)[0])]\n",
    "        if allowed_sources and not matching_sources:\n",
    "            continue\n",
    "\n",
    "        target_candidates = set()\n",
    "        for src in matching_sources:\n",
    "            norm_src = _norm_angle(src)\n",
    "            for target in (allowed_outputs or [norm_src]):\n",
    "                fam = {_norm_angle(x) for x in expand_allowed_angles([target])}\n",
    "                fam.add(_norm_angle(target))\n",
    "                if norm_src in fam:\n",
    "                    target_candidates.add(_norm_angle(target))\n",
    "\n",
    "        if allowed_outputs and not target_candidates:\n",
    "            continue\n",
    "\n",
    "        for target_angle in sorted(target_candidates):\n",
    "            base_img_path = _find_image_with_stem_and_suffix(base_subcat_dir, target_angle)\n",
    "            if not base_img_path:\n",
    "                print(f\"\u26a0\ufe0f Missing BASE for target '{target_angle}' \u2192 skipping {file}\")\n",
    "                continue\n",
    "\n",
    "            worklist.append((file, target_angle, base_img_path))\n",
    "\n",
    "    sku_name = os.path.basename(folder_path)\n",
    "    if allowed_sources:\n",
    "        print(f\"\u25b6\ufe0f  {sku_name}: {len(worklist)} image(s) to generate (outputs={sorted(list(allowed_outputs_set))}, sources={sorted(list(set(allowed_sources)))})\")\n",
    "    else:\n",
    "        print(f\"\u25b6\ufe0f  {sku_name}: {len(worklist)} image(s) to generate\")\n",
    "    print(f\"   Garment type guess (from path): {garment_type}\")\n",
    "\n",
    "    if not worklist:\n",
    "        return\n",
    "\n",
    "    for idx, (file, target_angle, base_img_path) in enumerate(worklist, start=1):\n",
    "        print(f\"   {idx:>3}/{len(worklist):<3}  {file}  | base='{target_angle}' via DINOv3\")\n",
    "        garment_path = os.path.join(folder_path, file)\n",
    "\n",
    "        sku_name = os.path.basename(folder_path)\n",
    "        angle_code = _norm_angle(target_angle)\n",
    "        main_suffix = \"_onlymain\" if SECONDARY_GARMENT else \"\"\n",
    "        final_out_name = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=\"_both\") if SECONDARY_GARMENT else None\n",
    "        main_out_name = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=main_suffix)\n",
    "        skip_name = final_out_name or main_out_name\n",
    "        dest_check = os.path.join(OUTPUT_DIR, skip_name)\n",
    "\n",
    "        if drive_file_exists_any_ext_at_colab_path(dest_check):\n",
    "            stage_label = \"secondary\" if final_out_name else \"main\"\n",
    "            print(f\"      \u23ed\ufe0f  Skip: {skip_name} already exists in {OUTPUT_DIR} ({stage_label} target)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            garment_img = flatten_alpha_to_white(open_upright(garment_path))\n",
    "            base_full   = Image.open(base_img_path).convert(\"RGB\")\n",
    "\n",
    "            def perform_tryon_stage(stage_base_full, stage_garment_img, suffix, stage_label):\n",
    "                bbox, heatmap = detect_garment_region_with_dinov3(\n",
    "                    stage_base_full,\n",
    "                    garment_hint=garment_type,\n",
    "                    score_percentile=DINO_BOX_PERCENTILE,\n",
    "                    padding=CROP_PADDING,\n",
    "                )\n",
    "                bbox_preview = draw_bbox(stage_base_full, bbox, color=(255, 99, 71), width=12)\n",
    "                heat_viz = heatmap_to_pil(heatmap)\n",
    "\n",
    "                square_crop, square_box = make_square_crop_with_padding(stage_base_full, bbox, fill=WHITE_RGB)\n",
    "\n",
    "                show_gallery(\n",
    "                    [bbox_preview, heat_viz, square_crop, stage_garment_img],\n",
    "                    [f\"DINOv3 region [{stage_label}]\", \"DINO heatmap\", \"Square crop (padded)\", \"Garment (white BG)\"]\n",
    "                )\n",
    "\n",
    "                tryon_gen = run_nanobanana_tryon(\n",
    "                    model_image=square_crop,\n",
    "                    garment_image=stage_garment_img,\n",
    "                    aspect_ratio=\"1:1\",\n",
    "                    image_size=GEN_IMAGE_SIZE,\n",
    "                    prompt=TRYON_PROMPT,\n",
    "                )\n",
    "\n",
    "                # Ensure the generated image matches the square crop size (even if model made it larger)\n",
    "                side = square_crop.size[0]\n",
    "                tryon_sq = tryon_gen.resize((side, side), Image.Resampling.LANCZOS)\n",
    "\n",
    "                final_img_local = paste_crop_back_square(\n",
    "                    full_img   = stage_base_full.copy(),\n",
    "                    edited_crop= tryon_sq,\n",
    "                    crop_box   = square_box,\n",
    "                    feather_px = MASK_FEATHER_PX\n",
    "                )\n",
    "                show_gallery([tryon_gen, final_img_local], [f\"Generated try-on [{stage_label}]\", f\"Final paste-back [{stage_label}]\"])\n",
    "\n",
    "                out_name_local = build_output_filename(sku_name, angle_code, ext=\".png\", suffix=suffix)\n",
    "                tmp_path_local = os.path.join(\"/tmp\", out_name_local)\n",
    "\n",
    "                save_png_with_metadata(final_img_local, tmp_path_local, details_payload=None)\n",
    "                target_path_for_drive = os.path.join(OUTPUT_DIR, out_name_local)\n",
    "\n",
    "                info = upload_file_and_append_to_sheet(\n",
    "                    local_path       = tmp_path_local,\n",
    "                    target_colab_path= target_path_for_drive,\n",
    "                    sku_name         = sku_name,\n",
    "                    angle            = angle_code,\n",
    "                    spreadsheet_id   = SPREADSHEET_ID,\n",
    "                    worksheet_name   = GEN_LOG_SHEET,\n",
    "                )\n",
    "                print(f\"      \u2705 Uploaded [{stage_label}] \u2192 {info['file_url']}\")\n",
    "                return final_img_local\n",
    "\n",
    "            main_result = perform_tryon_stage(\n",
    "                stage_base_full=base_full,\n",
    "                stage_garment_img=garment_img,\n",
    "                suffix=main_suffix,\n",
    "                stage_label=\"main\",\n",
    "            )\n",
    "\n",
    "            if SECONDARY_GARMENT:\n",
    "                sec_garment_path = find_secondary_garment_path(folder_path, file)\n",
    "                if not sec_garment_path:\n",
    "                    print(f\"      \u26a0\ufe0f Secondary garment missing for '{target_angle}' \u2192 kept main-only output.\")\n",
    "                    continue\n",
    "\n",
    "                sec_garment_img = flatten_alpha_to_white(open_upright(sec_garment_path))\n",
    "\n",
    "                perform_tryon_stage(\n",
    "                    stage_base_full=main_result,\n",
    "                    stage_garment_img=sec_garment_img,\n",
    "                    suffix=\"_both\",\n",
    "                    stage_label=\"secondary\",\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      \u274c Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzFKYPQO_RPb"
   },
   "outputs": [],
   "source": [
    "# --- Sheet-driven angle selection + runners ---\n",
    "\n",
    "def build_sku_folder_index(garments_root: str):\n",
    "    return { _norm_sku(os.path.basename(p)) : p for p in iter_sku_folders(garments_root) }\n",
    "\n",
    "def run_list():\n",
    "    targets, unmatched = resolve_targets(SKU_CSV, GARMENTS_ROOT)\n",
    "    if not targets:\n",
    "        print(\"\u26a0\ufe0f No matching SKU folders found.\")\n",
    "        if unmatched: print(\"Unmatched:\", \", \".join(unmatched))\n",
    "        return\n",
    "    print(f\"\u27a1\ufe0f  Will process {len(targets)} SKU(s).\")\n",
    "    for i, p in enumerate(targets, start=1):\n",
    "        name = os.path.basename(p)\n",
    "        print(f\"\\nSKU {i}/{len(targets)} \u25b6\ufe0f  {name}\")\n",
    "        try:\n",
    "            process_one_garment_folder(p, allowed_angles=ALLOWED_BASES)\n",
    "            print(f\"\u2705 Finished: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error in {name}: {e}\")\n",
    "    if unmatched:\n",
    "        print(\"\\n\u2139\ufe0f  Unmatched identifiers:\")\n",
    "        for u in unmatched: print(\"   -\", u)\n",
    "    print(\"\\n\ud83c\udfc1 List run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sinwLlWu_aCm"
   },
   "source": [
    "# DISPATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJAcEUnW_Y7f"
   },
   "outputs": [],
   "source": [
    "# Dispatch\n",
    "run_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CK_cKHr9Uutd"
   },
   "source": [
    "#UNASSIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXlc2wlNyNDm"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "O4KzsXGV_ee1",
    "umaizfLYv7ww",
    "D7pcfKd0_iB_",
    "w3WTzeGw_nEv",
    "HFMF2dYwIlyZ",
    "IU5VwKPQIody"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}